{"id": "govreport_0", "report": "In our prior work, we have found that technological innovation involves not only creating new ideas but also translating those ideas into a new product or service. Innovation, and the research driving it, is inherently risky because the likelihood that research can be translated into a product or service and the ultimate value of that product or service are unknown. The Department of Commerce\u2019s National Institute of Standards and Technology describes the path from innovation to commercialization as comprised of three overarching stages: inventing, transitioning to making, and selling. (See fig. 1 for a description of the path from innovation to commercialization.) FDA and USDA have responsibility for overseeing the safety of the food supply. In general, FDA is responsible for ensuring the safety of virtually all domestic and imported food products except those regulated by USDA. USDA is responsible for ensuring the safety of meat, poultry, processed egg products, and catfish. FDA and USDA cooperate with states, tribes, and local food safety and public health agencies to carry out their federal responsibilities. FDA and USDA carry out their responsibilities in part through inspections of facilities where food is produced. The frequency of inspections the agencies conduct varies, as follows: FDA. FDA\u2019s authority requires a risk-based approach, in which inspection rates vary depending on the level of risk associated with a food product. FDA conducts risk-based inspections of high-risk and non-high-risk food facilities. For example, the FDA Food Safety Modernization Act, signed into law in 2011, specified that FDA had to inspect all high-risk domestic facilities at least every 3 years. USDA. Depending on the type of facility, USDA conducts inspections at least once per operating shift or maintains a constant presence. Specifically, USDA conducts carcass-by-carcass inspection at all federally inspected meat and poultry slaughter facilities and verifies that these establishments follow all food safety and humane handling requirements. At facilities that process meat and poultry products, USDA conducts inspections at least once per production shift, following the agency\u2019s longstanding interpretation of its statutes requiring it to do so. Among other things, the Federal Food, Drug, and Cosmetic Act requires that food additives be approved by FDA before they can be lawfully used in foods. Substances added to food are considered unsafe unless the agency establishes that the use of the food additive, under specific conditions for use, will be safe, or unless the substance is generally recognized as safe (GRAS) under the conditions of its intended use among qualified experts. As we reported in 2010, the Federal Food, Drug, and Cosmetic Act exempts GRAS substances from the act\u2019s general requirement that companies obtain FDA approval before marketing food containing a new additive. GRAS substances include hundreds of spices and artificial flavors, emulsifiers and binders, vitamins and minerals, and preservatives that manufacturers add to enhance a food\u2019s taste, texture, nutritional content, or shelf life. The GRAS exemption allows companies, without notice to or approval from FDA, to determine whether there is enough support to claim a substance is GRAS. For a company to claim a substance is GRAS, it must conclude that there is common knowledge about the safety of the substance among experts qualified by scientific training and experience to evaluate its safety. In addition, as part of their oversight of the food supply, FDA and USDA oversee food labeling of the products under their respective jurisdictions. USDA, by statute, is charged with assuring that products under its jurisdiction, including meat, poultry, and catfish, in interstate or foreign commerce are properly marked, labeled, and packaged. USDA develops and applies the labeling requirements for these products, and food manufacturers are responsible for complying with the USDA labeling rules and adhering to the process maintained by USDA for the evaluation and approval of these product labels. Consistent with its statutes, USDA requires preapproval of all labels before manufacturers can market their products. The Federal Food, Drug, and Cosmetic Act prohibits the misbranding of food, which includes food labeling that is false or misleading. Consistent with its statutes, FDA ensures that foods within its jurisdiction are not misbranded by focusing on the labels of products already in the market. FDA establishes regulations for the enforcement of these provisions and issues guidance. Food manufacturers are responsible for compliance with misbranding provisions in the Federal Food, Drug, and Cosmetic Act and its implementing regulations. From time to time, new technologies, such as those used to make cell- cultured meat, generate challenges for FDA\u2019s and USDA\u2019s regulatory structure. Other examples of new food technologies to which federal agencies have needed to adapt include the genetic modification of plants and irradiation of foods. In the case of genetically modified plants, there are no specific regulations addressing products resulting from the manipulation of the genetic material of living seeds. However, under FDA policy, new genetically engineered crop varieties are treated like other foods (including their conventional counterparts) under the Federal Food Drug and Cosmetic Act and may not contain either unapproved food additives or contaminants that would adulterate the food. In 1995, FDA established a voluntary pre-market consultation process through which companies are encouraged to notify the agency before marketing a food produced from a genetically modified crop and voluntarily submit a summary of the developer-performed safety assessment. FDA evaluates the safety assessment for any issues that need to be addressed and works with the developer to resolve those issues. In the case of irradiated foods, companies seeking approval for a source of radiation used to treat a food may submit a food additive petition to FDA demonstrating the safety of the proposed use. FDA grants approval only after agency scientists have determined that the proposed use is safe, then the process can be employed commercially. General information about the process of making cell-cultured meat is available, but specific information about the technology being used and the eventual commercial production methods as well as the final products is not yet known. While firms may vary in how they make cell-cultured meat, the general process they use can be described in five phases. However, the technology and methods to commercially produce cell- cultured meat are still in development, and producers, regulators, and consumers do not yet have clarity on what these will entail. The composition of the final product is also not yet known. The general process for making cell-cultured meat contains five phases: biopsy, cell banking, growth, harvest, and food processing. (See fig. 2.) The five-phase process is generally as follows: 1. Biopsy. A biopsy is taken by collecting rice-sized tissue samples from an animal, such as livestock, chicken, or fish. During this and subsequent phases, specific laboratory sanitation procedures are followed, and antibiotics may be used in order to avoid or minimize contamination from bacteria. Growth Media According to researchers and representatives from cell-cultured meat firms, the growth media for cell-cultured meat often contains fetal bovine serum, which is obtained from blood drawn from a bovine fetus at slaughter. However, researchers and representatives from cell-culturing firms we spoke with said they are working to develop growth media that do not contain fetal bovine serum. Representatives from some of these firms also told us that the composition of the growth media, including the exact ingredients and their proportions, can vary based on the specific needs of the cells and the variety of serum used. For example, cell-cultured seafood may have different growth media and environmental requirements than cell-cultured livestock and poultry. 2. Cell banking. Biopsied cells with the most desirable traits are selected and either used immediately for cell growth or frozen to create a cell bank for later use. These desirable traits can be obtained by either selecting existing cells or using genetic engineering methods to insert, delete, or edit the DNA to target desired traits in cells. Examples of desirable traits may include cells that divide quickly, cells that divide a greater number of times, cells that result in a reduced cholesterol or fat content or other desirable nutritional traits, or cells that are more resilient to environmental factors, such as temperature, than other cells. According to agency officials and representatives from cell-cultured meat firms, this phase represents an important opportunity to ensure that the source cells used to initiate commercial production are free of pathogens or other contaminants. 3. Growth. During the cell growth phase, cells are placed in a bioreactor and begin to divide and differentiate. A bioreactor is a container that creates an environment that can sustain the growth of cells and includes the ability to control factors such as temperature, pH, and oxygen and carbon dioxide concentrations. Bioreactors can vary in size, including microwave-sized and refrigerator-sized units, but could be as large as 20 to 30 feet tall in commercial production. Bioreactors contain a growth medium, which may include ingredients such as glucose, amino acids, hormones and other growth factors, and other basic nutrients that cells need to consume in order to thrive. In addition to the medium needed for growth, the cells may need to be attached to a structure, referred to as a scaffold, to properly develop into cell-cultured meat. 4. Harvest. Once the cells have divided to form a sufficiently large amount of cell-cultured meat, producers remove\u2014or harvest\u2014it from the growth medium and bioreactor. If a scaffold was used to provide a structure for cells to grow on, then the cell-cultured meat would either be separated from the scaffold during harvesting or left attached to an edible scaffold. 5. Food processing. The harvested cell-cultured meat is then prepared into a product such as meatballs or chicken nuggets. In the future, products similar to intact cuts of meat such as steak or chicken breast may be produced. The technology to produce cell-cultured meat at a commercial scale is still in development, and information about the methods to be used for commercial production and the composition of the final product are not yet known. In the continuum of moving a technology from innovation to commercialization, cell-cultured meat firms are in the middle stage of building and testing their prototypes, based on our discussions with representatives from these firms. Consequently, they have not finalized aspects of the technology and eventual commercial production methods to be used or the composition of the final product. As a result, certain information is not yet available to stakeholders\u2014including cell-cultured meat firms themselves, regulators, and the public\u2014about specific aspects of the technology and commercial production methods that will be used, such as the composition of the growth medium and of the final products. In addition to technology development, the scarcity of publicly available research on cell-cultured meat production limits information available to agency officials and the public. Each cell-cultured meat firm is developing detailed information on its own eventual commercial production methods for making cell-cultured meat. However, the firms, similar to other technology start-ups, are reluctant to disclose intellectual property and business-sensitive information due to concerns about competition. For example, one firm told us that they can reverse engineer parts of another company\u2019s commercial production method by seeing pictures of the equipment the other company is using. In addition, cell-cultured meat firms compete with other firms for funding from sources such as venture capitalists, foreign governments, and conventional meat companies. This competition for funding contributes to firms being reluctant to share information they consider important intellectual property, such as parts of their production processes. As a result, agency officials and other stakeholders told us that they must largely rely on whatever information the cell-cultured meat firms are willing to provide to understand details of the companies\u2019 prototype processes and products. This limitation can affect agencies\u2019 ability to make regulatory and other decisions. Specifically, FDA and USDA officials said they have limited information on cell-cultured meat production methods and products and need more in order to regulate this new food. One USDA official explained that the agency cannot establish labeling requirements if the agency does not know the nutritional profile of the final product. For example, if the scaffold on which the cell-cultured meat is grown is not edible, the agencies may require firms to disclose certain aspects of their commercial production methods, such as how they removed the cell- cultured meat from the scaffold. However, if the scaffold is edible, it will affect the final composition of the product, which may require different labeling than a product that was developed without edible scaffolding. This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products. Among other things, this lack of information creates challenges for industry and federal regulatory agencies as cell-cultured meat nears commercialization. The sources we reviewed and stakeholders we talked to identified a number of open questions, including the following: Tissue collection. How often will producers need to collect biopsy samples from animals, and what animals will be used? Some stakeholders have stated concerns about whether, and how, regulators will ensure that biopsies are collected from healthy animals. For example, one cell-cultured meat firm stated that tissue samples would be taken from slaughtered donor animals that met federal standards for conventional processing at the time of slaughter. However, USDA and FDA have not indicated whether they would require cell-cultured meat firms to do so. Additionally, representatives from cell-cultured meat firms stated that they did not yet know how frequently they would need to collect biopsies from animals for commercial-level production. Additionally, according to researchers, there are too many unknowns to accurately estimate how much cell- cultured meat could be produced from a single biopsy of animal tissue. Genetic engineering. Will commercial production methods involve genetic engineering? Some stakeholders expressed concern that the use of genetic engineering in cell-cultured meat production could cause the product to experience a lengthy wait for regulatory approval, similar to that for genetically engineered salmon, which took approximately 20 years. One representative from a cell-cultured meat firm noted that uncertainty about pending government regulations could negatively affect firms\u2019 ability to attract and retain investors. Representatives from some firms said understanding what regulatory requirements will look like might influence which scientific pathways they pursue as they continue to develop their commercial production methods. According to FDA officials and representatives from one cell-cultured meat firm, it is likely that some firms will use genetic engineering in their commercial cell-cultured meat production methods. However, representatives from two other cell-cultured meat firms told us they were undecided as to whether they would use genetic engineering in their commercial production methods. Antibiotics. Will antibiotics be used to make cell-cultured meat, and will residues be present in the final product? According to agency officials, the presence of antibiotics in commercial production and the potential for residues in the resulting product would represent a significant potential concern for food safety and public health. Officials stated that they would not expect antibiotics to be used past the cell- banking phase. Representatives from cell-cultured meat firms we spoke to differed on whether they planned to use antibiotics in their commercial production process, but they had not finalized their decisions. According to one firm, if antibiotics are used, the use would be limited both in quantity and duration. Growth medium. What type of growth medium will producers use, and how might variations in the media affect the final product? According to agency officials and other stakeholders, the ingredients used in the growth medium could affect the end product\u2019s composition and raise potential safety concerns. For example, FDA officials stated that residual growth factors, such as hormones, in the final product would be something they would likely evaluate in premarket consultations. However, representatives from cell-cultured meat firms stated that their firms have not finalized the medium they plan to use. In addition, the formulation of the medium firms use could be an important piece of intellectual property or confidential business information. Scaffold. What type of scaffold will producers use, if any, and will it be edible or inedible? The use of edible or food-grade scaffolds, where they are used, will affect the composition of the product and may need to be evaluated by federal agencies for safety. According to USDA officials, the composition of edible scaffolding may also create labeling and jurisdictional concerns. For example, USDA officials stated that the addition of edible scaffolding may require significant additional aspects of production to be subject to USDA jurisdiction. Additionally, researchers have commented that a chemical separation technique needed to separate some inedible scaffolds may also need to be evaluated for potential safety concerns. Point of harvest. How will FDA and USDA define the point of harvest? The point of harvest is the point at which FDA will transfer oversight responsibilities, including inspections, to USDA. Stakeholders have raised concerns that not having a clear definition of the point of harvest could lead to challenges such as overlapping inspection requirements or a gap in inspection. Representatives from several cell-cultured meat firms we spoke to in the spring of 2019 said it was ambiguous how FDA and USDA intended to define the point of harvest. These representatives also said it is unclear how often each agency plans to conduct inspections during the phases for which it is responsible. Agency officials stated that they are working to develop a detailed process for the transfer of jurisdiction, including defining the point of harvest. Scaling up production. How will firms scale up production to commercial levels? One 2018 study conducted by researchers in the United Kingdom stated that to produce one pound of cell-cultured meat, firms would need bioreactors at least 2 1/2 times larger than what is currently available. Similarly, a senior FDA official stated that the capacity of existing production equipment is a challenge for firms seeking to produce cell-cultured meat products at a commercial scale. As a result, the firms themselves may have to develop the equipment or custom order such equipment. Representatives from one cell- cultured meat firm told us that they are interacting with equipment providers to identify commercial-scale production equipment. Production cost. How will firms sell their product at a price point that is both profitable to the firms and affordable to the consumer? Some studies and stakeholders we interviewed, including representatives from cell-cultured meat firms, said that the high production cost of cell- cultured meat is a key industry challenge. For example, in the last two years, one firm reported that it cost $600 to make a cell-cultured meat hamburger patty and reported that it cost about $1,200 to produce a single cell-cultured meatball. One of the biggest cost drivers in the production of cell-cultured meat is the growth medium, according to some studies and some cell-cultured meat firms. To address issues of cost and scale, some firms may develop their own, less expensive growth media. Safety considerations. Are potential safety hazards in commercial production methods for cell-cultured meat different from those for conventional meat, and how will eventual commercial production methods affect the overall safety of the product? According to agency officials, cell-cultured meat may present different safety challenges compared to conventional meat. For example, according to agency officials, residues and constituents in harvested cell-cultured meat would be expected to be different from those in conventional meat, depending on the details of the production process. Representatives from one cell-cultured meat firm told us that they likely will use food processing techniques similar to those used for conventional meat, abide by similar health and safety standards, and possibly share food processing facilities. However, because specific information about commercial production methods and final products is not yet known, it is unclear whether cell-cultured meat produced on a commercial scale will pose any hazards not present in conventional meat. Product composition. What will be the composition of any eventual products? Agency officials told us that without knowing the composition of a cell-cultured meat product, it is impossible to predict how food safety and labeling requirements will apply. According to representatives from some cell-cultured meat firms, initial cell-cultured meat products most likely will not be composed entirely of cell- cultured meat but, rather, a mixture of cell-cultured meat and other ingredients such as binding, flavoring ingredients, and plant-based materials used in conventional food products. Some firms have developed prototypes of cell-cultured meat products as part of their research and development. In April 2019, representatives from one firm told us that their prototype included about 90 percent plant-based ingredients and 10 percent cell-cultured meat. However, representatives from cell-cultured meat firms stated that they aim to produce products that contain more cell-cultured meat than other ingredients. For example, some cell-cultured meat firms have stated that a long-term goal is to commercially produce cell-cultured meat products that are similar to intact cuts of meat, such as steaks. As of December 2019, these firms had not provided regulators with specific information detailing the composition of their cell-cultured meat prototypes, according to FDA and USDA officials. Environmental, animal welfare, and health impacts. How will cell- cultured meat impact the environment, animal welfare, or human health, if at all? Cell-cultured meat firms and researchers have made various claims about the potential environmental, animal welfare, and health advantages of cell-cultured meat over conventionally produced meat. For example, some cell-cultured meat firms have claimed that cell-cultured meat production would use less water and emit less greenhouse gases than conventional meat production. Some cell- cultured meat firms have also claimed that cell-cultured meat will improve animal welfare because slaughter will be unnecessary. Additionally, some stakeholders stated that because there is less opportunity for contamination from animal feces\u2014a potential source of contamination for conventional meat\u2014cell-cultured meat would be less likely than conventional meat to contain foodborne pathogens. However, there are disagreements regarding the accuracy of these claims. Stakeholders told us that until commercial production methods and final products are established, these claims about impacts on the environment, animal welfare, and human health will remain unsubstantiated. Timeline to market. When will cell-cultured meat products reach consumers? As of December 2019, no cell-cultured meat products were available for retail sale in the United States. Stakeholders give varying estimates for when cell-cultured meat may be commercially available. Some estimates suggest that firms may be able to commercially produce some form of cell-cultured meat product as soon as 2020, while others estimate that such products may not be available for 2 to 4 years. Labeling. How will cell-cultured meat be labeled? Labeling was an area of concern for representatives from both conventional and cell- cultured meat firms who explained that the specific terminology, such as \u201cclean meat\u201d or \u201clab-grown meat,\u201d can sometimes reflect bias for, or against, certain products, potentially affecting consumer acceptance of these products. Additionally, stakeholders, as well as agency officials, have emphasized the importance of labeling to ensure consumers have accurate information about what they are buying. For example, in February 2018 the United States Cattlemen\u2019s Association submitted a petition to USDA requesting that the agency limit the term \u201cbeef\u201d to products \u201cborn, raised, and harvested in a traditional manner\u201d and \u201cmeat\u201d to mean the \u201ctissue or flesh of animals that have been harvested in the traditional manner.\u201d USDA received over 6,000 comments on the petition, and the agency had not responded to the petition as of December 2019. However, according to agency officials, USDA has committed to a public process, likely rulemaking, for the development of labeling requirements for cell- cultured meat and poultry. In addition, in recent years, a number of states have passed laws that could affect the labeling of cell-cultured meat when it comes to market. For example, in 2018, Missouri enacted a law to prohibit plant-based products and cell-cultured meat from being labeled as \u201cmeat.\u201d Consumer Acceptance How will consumers respond to cell-cultured meat? It remains unclear whether consumers will embrace and purchase cell-cultured meat products. Stakeholders we interviewed and studies we reviewed cited consumer acceptance as a challenge for commercializing cell-cultured meat. One study noted that consumers have both positive and negative views toward cell-cultured meat, which could impact their willingness to purchase and consume such products. FDA and USDA have established multiple mechanisms to collaborate on regulatory oversight of cell-cultured meat. Specifically, the agencies have collaborated through a joint public meeting, an interagency agreement, and three working groups. However, the interagency agreement and working groups, which are ongoing mechanisms, do not fully incorporate leading practices for interagency collaboration. In addition, FDA and USDA have not documented which agency will oversee cell-cultured seafood not covered by the interagency agreement. In 2018, FDA and USDA began taking steps to collaborate on the regulatory oversight of cell-cultured meat through several mechanisms: a joint public meeting, an interagency agreement, and three working groups. The agencies held the joint meeting in October 2018 to discuss the use of cell-culture technology to develop products derived from livestock and poultry, and topics included potential hazards, oversight considerations, and labeling. As part of this meeting, FDA and USDA held an open public comment period from September through December 2018, gathered 315 written comments, and offered interested parties the opportunity to offer comments in person. The agencies received public comments from members of the public, as well as from representatives from cell-cultured meat and conventional meat industries, food and consumer safety groups, animal welfare groups, and environmental organizations, among others. The written comments the agencies received focused on such topics as environmental considerations, labeling, potential health and safety implications, and potential regulatory and inspection processes. Stakeholders also presented multiple perspectives on these issues at the meeting. For example, stakeholders expressed different views as to whether cell-cultured meat should be regulated as a food additive, considered a GRAS substance, or whether new regulations were needed. In March 2019, FDA and USDA issued a formal interagency agreement that describes the intended roles and responsibilities of each agency in overseeing cell-cultured meat. The agreement establishes the following: Oversight. FDA will oversee the early phases of growing cell-cultured meat through the point of harvest. During harvest, FDA will work with USDA to transfer regulatory oversight to USDA. USDA will then assume oversight of cell-cultured meat through the food processing phase, including labeling, as shown in figure 3. Types of meat covered. The agreement covers cell-cultured meat derived from species overseen by USDA, such as livestock, poultry, and catfish. Future actions. The agreement also details future actions the agencies plan to take, such as developing a more detailed regulatory framework or standard operating procedures and developing joint principles for product labeling. Reviewing and updating the agreement. The agreement states that the agencies have the ability to modify it as needed and will review the agreement every 3 years to determine whether they should modify or terminate it. In June 2019, FDA and USDA created three working groups to carry out the terms of the interagency agreement. The working groups are comprised of FDA and USDA officials and operate independently, though some individuals are members of multiple groups. The groups are as follows: Pre-market assessment working group. Led by FDA, this group was created to clarify the process FDA will use for pre-market reviews of cell-cultured meat. Labeling working group. Led by USDA, this group will focus on developing joint principles for product labeling and claims. Transfer of jurisdiction working group. Co-led by FDA and USDA, this group will develop procedures for the transfer of inspection at harvest, among other things. According to agency officials, the working groups are still in the initial phases of development, though some have progressed further than others. For example, as of December 2019, the pre-market assessment and labeling groups had met and begun to address various areas, while the transfer of jurisdiction working group was still in discussions to outline the roles, responsibilities, and outcomes for the group and had not held a formal meeting. FDA and USDA could more fully incorporate leading practices for collaboration in their interagency agreement and working groups. We have previously reported that interagency mechanisms or strategies to coordinate programs that address crosscutting issues may reduce potentially duplicative, overlapping, and fragmented efforts. In addition, while collaborative mechanisms may differ in complexity and scope, they all benefit from certain leading practices, which raise issues to consider when implementing these mechanisms. We compared the agencies\u2019 interagency agreement and working groups with the seven leading practices to enhance and sustain interagency collaboration that we previously identified. These leading practices, and examples of the associated issues to consider, are as follows: Defining outcomes and monitoring accountability. Is there a way to track and monitor progress toward short-term and long-term outcomes? Do participating agencies have collaboration-related competencies or performance standards against which individual performance can be evaluated? Bridging organizational cultures. What are the commonalities between the participating agencies\u2019 missions and cultures, and what are some potential challenges? Have participating agencies developed ways for operating across agency boundaries? Have participating agencies agreed on common terminology and definitions? Identifying and sustaining leadership. How will leadership be sustained over the long term? If leadership is shared, have roles and responsibilities been clearly identified and agreed upon? Clarifying roles and responsibilities. Have participating agencies clarified roles and responsibilities? Have participating agencies articulated and agreed to a process for making and enforcing decisions? Including relevant participants. Have all relevant participants been included? Do participants have appropriate knowledge, skills, and abilities to contribute? Identifying and leveraging resources. How will the collaborative mechanism be funded and staffed? Developing and updating written guidance and agreements. If appropriate, have the participating agencies documented their agreement regarding how they will collaborate? (A written document can incorporate agreements reached in any or all of the following areas: leadership, accountability, roles and responsibilities, and resources.) Have participating agencies developed ways to continually update or monitor written agreements? See appendix II for a full list of the associated issues to consider for each leading practice. We found that the interagency agreement for oversight of cell-cultured meat partially incorporates all seven leading practices for collaboration. For example: Defining outcomes and monitoring accountability. The interagency agreement partially incorporates the leading practice of defining outcomes and monitoring progress toward these outcomes. Specifically, the agreement identifies broad outcomes such as the development of labeling principles. However, the agreement does not describe how the agencies will track and monitor progress toward outcomes. Identifying and sustaining leadership. The agreement partially incorporates the leading practice of clarifying leadership structures. For example, it assigns each agency as the lead, or designates shared leadership, for different phases of the cell-cultured meat production process. However, the interagency agreement does not identify how the agencies will sustain leadership over the long term, including through succession planning. We have previously reported that given the importance of leadership to any collaborative effort, transitions and inconsistent leadership can weaken the effectiveness of any collaborative mechanism. Developing and updating written guidance and agreements. The agreement partially incorporates the leading practice of documenting how the agencies will collaborate. For example, the agreement includes a method for updating the document by including a provision that requires a review of the document every 3 years. This is consistent with our leading collaboration practice to continually update or monitor written agreements. However, the interagency agreement does not document how the agencies will track and monitor progress toward short-term and long-term outcomes. Table 1 provides more detail about the agencies\u2019 incorporation of these leading collaboration practices in their interagency agreement. FDA and USDA officials told us that the interagency agreement was intended to be an initial, general outline for their collaboration. They also said that as the technology to produce cell-cultured meat develops and they implement the agreement, including developing the content of a regulatory program, they will consider incorporating leading practices for interagency collaboration. For example: Clarifying roles and responsibilities. FDA and USDA officials said in December 2019 that through the working groups the agencies would continue to explore and define the specific details of how they will manage their shared oversight responsibility. Including relevant participants. FDA officials said in December 2019 that the agency would like to engage many more stakeholders as it continues to develop its oversight of cell-cultured meat. Identifying and leveraging resources. As of December 2019, the pre-market assessment working group and the labeling working group were working to identify any human resources, physical, or financial resources they might need, according to FDA and USDA officials. The federal food safety system is on our High Risk List due to concerns about fragmentation, which we have reported has caused inconsistent oversight, ineffective coordination, and inefficient use of resources. As the agencies continue to collaborate on their shared oversight of cell- cultured meat, by more fully incorporating all seven leading practices for collaboration into their interagency agreement, they will be better positioned to address potential fragmentation in their efforts to ensure the safety of the food supply as cell-cultured meat products near commercialization and entry into the marketplace. We found that the pre-market assessment, labeling, and transfer of jurisdiction working groups that FDA and USDA created to carry out the terms of the interagency agreement either partially incorporate or do not incorporate the seven leading practices for interagency collaboration. Specifically, all three working groups have partially incorporated three of the seven leading practices for collaboration, but none of the working groups have incorporated the four remaining leading practices. For example: Defining outcomes and monitoring accountability. The working groups have all defined and agreed upon their general purposes. However, FDA and USDA have not established methods, such as milestones and metrics, to evaluate the progress of any of the working groups. For example, FDA officials said in December 2019 that their next steps are to conduct a general and qualitative risk assessment of animal cell culture food technology to systematically identify particular areas of interest from a food safety perspective and prepare detailed procedural guidelines for cell-cultured meat firms to follow. However, the officials did not have time frames or a method to evaluate progress towards completing these actions. Including relevant participants. While the working groups have included relevant FDA and USDA officials, none of the groups have included state or tribal officials in initial discussions and planning. According to the state officials we spoke with, being excluded from these federal-level discussions may hinder their ability to align their safety and labeling requirements, among other things, with federal standards. Developing and updating written guidance and agreements. None of the working groups have documented how they will collaborate. For example, the working groups have not documented leadership, accountability, roles and responsibilities, or resources needed for working groups. Table 2 provides more detail about FDA and USDA\u2019s incorporation of leading collaboration practices in the three working groups. In December 2019, FDA and USDA officials said that as they continued to stand up these working groups, they were considering leading practices for collaboration. For example: Defining outcomes and monitoring accountability. FDA and USDA officials said they were considering means to monitor, evaluate, or report on the results of the pre-market assessment working group. Including relevant participants. FDA and USDA officials said that they were working to determine what knowledge participants in the pre-market assessment working group and the labeling working group needed to perform the work of the working group. Developing and updating written guidance and agreements. FDA and USDA officials said they were considering documenting how they will collaborate in the pre-market assessment working group, including potentially creating a charter for the working group. We have previously reported that fragmentation has caused inconsistent oversight and inefficient use of resources in the federal food safety oversight system. The agencies\u2019 2019 agreement to share oversight of cell-cultured meat creates a new relationship between FDA and USDA, since the agencies will oversee different stages of the production of the same food and hand off oversight at a certain point in that production. These factors contribute to an already complicated system in which the two agencies must coordinate on food safety oversight. In this context, some industry representatives and other stakeholders have expressed concerns about potential fragmentation or overlap in oversight of cell-cultured meat, such as could occur during the harvest phase of cell-cultured meat production when FDA hands off its oversight to USDA. Additionally, representatives from one cell-cultured meat firm stated that avoiding overlap in federal oversight whenever possible was important to them. For example, representatives from one firm pointed to inspection, record-keeping requirements, and regulations as potential areas at risk of overlap. They stated that potential overlap would add unnecessary, burdensome requirements and create an uneven playing field with the conventional meat industry. By more fully incorporating all seven leading practices for interagency collaboration early in the development of the three working groups, FDA and USDA could proactively minimize potential fragmentation and overlap in their oversight of cell-cultured meat, ensure consistency and efficient use of resources, and provide clarity to key stakeholders. While FDA and USDA officials told us they have decided who will oversee cell-cultured seafood, they have not formally announced or documented this decision, and some stakeholders have reported confusion or ambiguity about which agency will oversee cell-cultured seafood other than catfish. Specifically, FDA and USDA\u2019s interagency agreement regarding cell-cultured meat states that it covers all cell-cultured meat derived from USDA-amenable species required to bear a USDA mark of inspection, which in the agreement includes livestock, poultry, and catfish. However, the agreement does not mention cell-cultured meat made from the cells of other fish, such as tuna and shellfish. FDA and USDA officials told us that FDA will have sole oversight responsibility for cell-cultured seafood other than catfish. According to FDA officials, they have verbally communicated this decision in various meetings with stakeholders. However, FDA and USDA officials told us that formally documenting FDA\u2019s sole oversight of most cell- cultured seafood in their interagency agreement was unnecessary because FDA currently oversees most conventional seafood. According to cell-cultured meat firms, some firms are working on developing cell- cultured versions of seafood, such as bluefin tuna. However, stakeholders from two cell-cultured meat firms, including representatives of a cell- cultured seafood firm we spoke with in April 2019, stated that they did not know who in the federal government would oversee cell-cultured seafood. Representatives from one cell-cultured seafood firm said that not being able to rule out oversight by USDA prevented them from making key decisions regarding what direction to pursue in developing their commercial production method. While FDA and USDA officials told us they had agreed that FDA would oversee cell-cultured seafood other than catfish, as of December 2019, the agencies had not formally announced or documented this agreement. Developing and updating written guidance and agreements is a leading practice for collaboration, as we have previously reported. In addition, standards for internal control in the federal government state that agency management should externally communicate the necessary quality information to achieve its objectives and should select appropriate methods of communication, such as a written document or a face-to-face meeting. Management should also periodically evaluate the entity\u2019s methods of communication so that the organization has the appropriate tools to communicate quality information throughout and outside of the entity on a timely basis. While FDA and USDA officials have informally communicated to some stakeholders that FDA will have sole oversight of most cell-cultured seafood, FDA has not communicated this information formally or in a method readily available to all relevant stakeholders, such as in their interagency agreement or other publicly available written document. FDA and USDA officials told us that they wanted to communicate this information through outreach to individual firms, but FDA or USDA officials said they did not think that revising their interagency agreement was necessary. By taking steps to document which agency will oversee cell-cultured seafood other than catfish, FDA and USDA will better ensure the public, including key stakeholders such as cell-cultured meat firms, have clarity about the agencies\u2019 oversight responsibilities in this area. Cell-cultured meat is a new food product that raises many questions. FDA and USDA\u2019s shared oversight of cell-cultured meat poses various challenges for these agencies, as well as stakeholders such as industry. Compounding this challenge is that specific information about key aspects of cell-cultured meat, such as the technology and production methods to be used as well as the composition of the products, is not yet known. FDA and USDA have taken steps to collaborate on their shared regulatory oversight of cell-cultured meat, including establishing an interagency agreement and three working groups. However, the interagency agreement only partially incorporates the seven leading collaboration practices that can enhance and sustain agencies\u2019 collaborative efforts, and the working groups either partially incorporate or do not incorporate these leading practices, which has raised concerns about potential fragmentation or overlap in oversight. By more fully incorporating all seven leading practices for collaboration into their interagency agreement, FDA and USDA could build on their existing efforts and be better positioned to sustain and enhance their collaborative efforts. Moreover, by more fully incorporating all seven leading practices for interagency collaboration early in the development of the working groups, FDA and USDA could proactively minimize potential fragmentation and overlap in their oversight of cell-cultured meat and ensure they are utilizing resources efficiently or effectively. Furthermore, the interagency agreement states that it covers USDA- amenable species required to bear a USDA mark of inspection, which in the agreement includes livestock, poultry, and catfish but does not include cell-cultured seafood other than catfish. FDA and USDA officials told us they have decided FDA will oversee most cell-cultured seafood, but the agencies have not formally documented this decision. By taking steps to document in their interagency agreement, or other publicly available document, which agency will oversee cell-cultured seafood other than catfish, FDA and USDA could better ensure that members of the public and other key stakeholders such as cell-cultured meat firms have clarity about the agencies\u2019 oversight responsibilities in this area. We are making a total of six recommendations, three to FDA and three to USDA: The Commissioner of the Food and Drug Administration, in coordination with the Secretary of Agriculture, should more fully incorporate the seven leading practices for effective collaboration in the agencies\u2019 interagency agreement for the joint oversight of cell-cultured meat. (Recommendation 1) The Secretary of Agriculture, in coordination with the Commissioner of the Food and Drug Administration, should more fully incorporate the seven leading practices for effective collaboration in the agencies\u2019 interagency agreement for the joint oversight of cell-cultured meat. (Recommendation 2) As the three cell-cultured meat working groups move forward, the Commissioner of the Food and Drug Administration, in coordination with the Secretary of Agriculture, should more fully incorporate the seven leading practices for effective collaboration, such as identifying specific outcomes and a way to monitor and evaluate progress toward outcomes. (Recommendation 3) As the three cell-cultured meat working groups move forward, the Secretary of Agriculture, in coordination with the Commissioner of the Food and Drug Administration, should more fully incorporate the seven leading practices for effective collaboration, such as identifying specific outcomes and a way to monitor and evaluate progress toward outcomes. (Recommendation 4) The Commissioner of the Food and Drug Administration, in coordination with the Secretary of Agriculture, should clearly document in their interagency agreement, or other publicly available document, which agency will oversee cell-cultured seafood other than catfish. (Recommendation 5) The Secretary of Agriculture, in coordination with the Commissioner of the Food and Drug Administration, should clearly document in their interagency agreement, or other publicly available document, which agency will oversee cell-cultured seafood other than catfish. (Recommendation 6) We provided a draft of this report to the Department of Health and Human Services\u2019 (HHS) Food and Drug Administration (FDA) and the U.S. Department of Agriculture (USDA) for review and comment. In FDA\u2019s comments, reproduced in appendix III, the agency stated that it values GAO\u2019s recognition of the importance of collaborative mechanisms that facilitate coordination and affirmed its commitment to coordinate closely with USDA to ensure the regulatory framework for cell-cultured meat is clear and transparent to stakeholders. In USDA\u2019s comments, reproduced in appendix IV, the department stated that the report put too much focus on best practices for interagency collaboration and not enough emphasis on industry\u2019s role in providing the agencies with the information they need to move their processes forward to effectively regulate cell-cultured meat. USDA stated that it is difficult to review a developing technology and its future regulatory oversight when so little detailed information about the technology is known. We agree that the technology to produce cell-cultured meat is still in development and that information about the commercial production methods and composition of the final product are not yet known, as we state in our report. We also acknowledge in our report that having limited information can affect the agencies\u2019 ability to make regulatory and other decisions. We recognize that cell-cultured meat is a new food product that raises many new questions and that specific information about key aspects of cell-cultured meat is not yet known. In light of this challenging context, it is all the more important that FDA and USDA more fully incorporate leading practices for collaboration into their joint efforts in order to ensure they are in the best possible position to oversee this new food product. FDA concurred with two recommendations and partially concurred with one. USDA also concurred with two recommendations and partially concurred with one. Specifically, both agencies agreed with our recommendations regarding (1) more fully incorporating the seven leading practices for effective collaboration in the three cell-cultured meat working groups as they move forward and (2) clearly documenting which agency will oversee cell-cultured seafood other than catfish. FDA and USDA partially concurred with our recommendation, directed to each agency, to more fully incorporate the seven leading practices for effective collaboration into the agencies\u2019 interagency agreement for the joint oversight of cell-cultured meat. FDA stated that it concurred with the intent of incorporating the seven leading practices into the interagency agreement, and both agencies said that they are open to incorporating the practices into their development of the structure for joint oversight of cell-cultured meat. However, the agencies stated that they did not agree to revise the agreement at this time. FDA and USDA stated that the agreement is a general framework and that incorporating the leading practices would constitute an inappropriate level of detail. Instead, the agencies stated that they believe it would be most valuable to incorporate the leading practices into a more detailed joint framework or standard operating procedure they plan to issue. We appreciate the agencies\u2019 willingness to incorporate the leading practices for effective collaboration into their efforts. The March 2019 interagency agreement states that the agencies have the ability to modify it as needed and will review the agreement every 3 years to determine whether they should modify or terminate it. Therefore, the agencies are due to revisit the agreement in March 2022, if not sooner. Regarding the agencies\u2019 concern that incorporating the leading practices in the interagency agreement would add an inappropriate level of detail, we note that, as we state in our report, the existing agreement already partially incorporates each of the seven leading practices. We continue to believe that FDA and USDA should more fully incorporate the seven leading practices for effective collaboration into their interagency agreement for the joint oversight of cell-cultured meat. Developing a more detailed joint framework or standard operating procedure in accordance with the existing interagency agreement that incorporates those leading practices would meet the intent of our recommendation to improve the effectiveness of the agencies\u2019 collaboration. FDA and USDA also provided technical comments, which we incorporated as appropriate. As agreed with your office, unless you publicly announce its contents earlier, we plan no further distribution of this report until 30 days from its issue date. At that time, we will send copies of this report to the appropriate congressional committees, the Secretary of Health and Human Services, the Secretary of Agriculture, and other interested parties. In addition, the report is available at no charge on the GAO website at http://www.gao.gov. If you or your staff members have any questions regarding this report, please contact me at (202) 512-3841 or morriss@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix V. Our report (1) describes what is known about methods for commercially producing cell-cultured meat and (2) examines the extent to which the Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) are collaborating to provide regulatory oversight of cell-cultured meat. For both objectives, we conducted a literature review of journal and media articles from 2016 through 2019 to inform our understanding of cell- cultured meat, as well as regulatory activity related to cell-cultured meat in the United States and in other countries. Specifically, we conducted a review of scholarly and trade news from 2016 through July 2019 for specific terms related to cell-cultured meat and regulatory approaches. We conducted searches in more than 30 different academic and trade databases\u2014such as SCOPUS, Foodline, and ProQuest\u2019s Environmental Science Collection\u2014and identified studies relevant to our research objectives. In addition to these formal literature searches, we also asked agency officials and stakeholders to refer us to research articles and publications on cell-cultured meat. We also reviewed documentation from FDA and USDA, including the 2019 interagency agreement, existing memoranda of understanding between the two agencies, Federal Register notices about relevant public meetings, and press releases. We also reviewed documentation such as letters to regulators, presentation slides, and information on organizations\u2019 websites from the cell-cultured meat industry, conventional meat industry, and consumer safety groups, among others. We also interviewed officials from FDA and USDA and representatives of stakeholders from the cell-cultured meat industry and industry associations, conventional meat firms and industry associations, academia, food and consumer safety groups, and state and tribal public health associations, among others. We identified stakeholders to interview through consultation with agency officials and nonfederal stakeholders and through our review of literature. We conducted 17 interviews with representatives or researchers from: six cell-cultured meat firms or industry associations, four conventional meat firms or industry associations, two food and consumer safety groups, one state and tribal public health association, and one food law policy firm. Because this is a nongeneralizable sample, the results of these interviews do not represent the views of all stakeholders involved in or with an interest in the cell-cultured or conventional meat industries or federal regulation of cell-cultured meat. However, they illustrate the range of perspectives on these topics. We also attended public meetings and conferences and conducted site visits to several locations. Specifically, we attended FDA and USDA\u2019s public meeting in October 2018 and four conferences in 2019 that included content pertaining to food safety or cell-cultured meat. We conducted site visits to two conventional meat-processing facilities in Georgia, three cell-cultured meat firms in California, an academic cell- culturing laboratory in California, and a medical cell-culturing facility in Maryland. We identified facilities and laboratories to visit through our literature review, online research, and the assistance of agency officials and stakeholders, such as representatives from the cell-cultured meat and conventional meat industry. To describe what is known about the process for producing cell-cultured meat and potential commercial production methods, we also reviewed two sets of public comments submitted to FDA and USDA in association with the two 2018 public meetings pertaining to cell-cultured meat. These meetings were \u201cFoods Produced Using Animal Cell Culture Technology\u201d in July 2018 and \u201cUse of Cell Culture Technology to Develop Products Derived from Livestock and Poultry\u201d in October 2018. Public comments were submitted by members of the public; representatives from cell- cultured meat firms and industry associations, conventional meat companies and industry associations, food and consumer safety groups, and animal welfare groups; and environmental organizations, among others. We reviewed and analyzed all comments submitted to (1) FDA related to the July 2018 meeting and (2) FDA and USDA related to the October 2018 meeting. We also attended the October 2018 meeting and listened to agency officials\u2019 presentations and oral remarks made by stakeholders and members of the public. We shared our description of the process for making cell-cultured meat, and associated questions, with representatives from three cell-cultured meat firms and academic researchers at two universities for their technical review and incorporated revisions as appropriate. To examine the extent to which FDA and USDA are coordinating to provide regulatory oversight of cell-cultured meat, we identified actions they took to coordinate from July 2018 through April 2020. To identify these actions, we interviewed agency officials, emailed agency officials written questions, reviewed agency documentation and public announcements, and attended public events such as the October 2018 public meeting. We compared the agencies\u2019 interagency agreement and working groups with seven leading practices to enhance and sustain interagency collaboration. Specifically, two independent GAO reviewers assessed the degree to which agencies\u2019 actions incorporated these leading practices. A description of these leading practices and the associated issues to consider is in appendix II. We also assessed the agencies\u2019 actions against standards for internal control in the federal government, including standards related to communicating quality information. In this report, and in our past work, we define collaboration as any joint activity that is intended to produce more public value than could be produced when organizations act alone. We use the terms \u201ccoordination\u201d and \u201ccollaboration\u201d interchangeably in this report. For the purposes of our report, we define cell-cultured meat as food derived from animal cells that were grown in a controlled environment outside of the animal. We define cell-cultured seafood as a subcategory of cell-cultured meat. When referencing conventional meat, we are referring to food produced from the traditional method of slaughtering an animal, such as a cow, hog, chicken, or fish. When referencing seafood, we are referring to shellfish, sea fish, and freshwater fish served as food. We conducted this performance audit from October 2018 to April 2020 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. Appendix II: Key Issues to Consider for Implementing Interagency Collaborative Mechanisms Issues to consider Have short-term and long-term outcomes been clearly defined? Is there a way to track and monitor progress toward the short-term and long-term outcomes? Do participating agencies have collaboration-related competencies or performance standards against which individual performance can be evaluated? Do participating agencies have the means to recognize and reward accomplishments related to collaboration? What are the missions and organizational cultures of the participating agencies? What are the commonalities between the participating agencies\u2019 missions and cultures and what are some potential challenges? Have participating agencies developed ways for operating across agency boundaries? Have participating agencies agreed on common terminology and definitions? Has a lead agency or individual been identified? If leadership will be shared between one or more agencies, have roles and responsibilities been clearly identified and agreed upon? How will leadership be sustained over the long term? Have participating agencies clarified the roles and responsibilities of the participants? Have participating agencies articulated and agreed to a process for making and enforcing decisions? Have all relevant participants been included? Do the participants have: Full knowledge of the relevant resources in their agency? The ability to commit these resources? The ability to regularly attend activities of the collaborative mechanism? The appropriate knowledge, skills, and abilities to contribute? Developing and updating written guidance and agreements How will the collaborative mechanism be funded? If interagency funding is needed, is it permitted? If interagency funding is needed and permitted, is there a means to track funds in a standardized manner? How will the collaborative mechanism be staffed? Are there incentives available to encourage staff or agencies to participate? If relevant, do agencies have compatible technological systems? Have participating agencies developed online tools or other resources that facilitate joint interactions? If appropriate, have the participating agencies documented their agreement regarding how they will be collaborating? A written document can incorporate agreements reached in any or all of the following areas: Leadership Accountability Roles and responsibilities Resources Have participating agencies developed ways to continually update or monitor written agreements? Steve D. Morris, (202) 512-3841 or morriss@gao.gov In addition to the contact named above, Nico Sloss (Assistant Director), Angela Miles (Analyst-in-Charge), Sahar Angadjivand, Tim Bober, Kevin Bray, Colleen Candrl, Pin En Annie Chou, Tara Congdon, Heather Dowey, Kim Gianopoulos, Gina Hoover, Hayden Huang, Robert Lepzler, Serena Lo, David Lysy, Marc Meyer, Michael Polak, Danny Royer, Sara Sullivan, and Sarah Veale made key contributions to this report.", "summary": "Multiple firms have produced cell-cultured meat as part of their research and development. These products appear likely to become available to consumers in coming years. FDA and USDA are the primary agencies responsible for overseeing the safety of the nation's food supply. However, some stakeholders have expressed concern about the agencies' oversight of cell-cultured meat amidst a fragmented federal food safety oversight system. GAO was asked to review federal oversight of cell-cultured meat. This report (1) describes what is known about methods for commercially producing cell-cultured meat, and (2) examines the extent to which FDA and USDA are collaborating to provide regulatory oversight of cell-cultured meat. GAO conducted a literature review; reviewed documentation from FDA, USDA, and stakeholder groups; analyzed public comments submitted to the agencies; compared agency efforts with leading practices for interagency collaboration; and conducted site visits to selected cell-cultured meat firms. General information about the process of making cell-cultured meat\u2014food products grown from the cells of livestock, poultry, and seafood\u2014is available. However, no company is commercially producing cell-cultured meat. Specific information about the technology being used, eventual commercial production methods, and composition of the final products is not yet known. The general process contains five phases: biopsy, cell banking, growth, harvest, and food processing (see figure). The technology and methods to be used for commercial production are still in development, and producers, regulators, and consumers do not have clarity about many specifics about the process and final product. For example, it is unclear whether production methods and products will use or contain genetically-engineered cells or medications such as antibiotics. The Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) have begun collaborating on regulatory oversight of cell-cultured meat. For example, in 2019, the agencies signed an interagency agreement and created three working groups to carry out the terms of the agreement. However, the agreement and working groups could more fully incorporate practices to enhance and sustain collaboration, such as defining outcomes. For example, the agreement identifies the development of labeling principles as an outcome, but does not describe how the agencies will track and monitor progress toward this outcome, and the working groups identify a lead agency but not members' roles. Also, agency officials said they decided FDA would oversee cell-cultured seafood other than catfish, but they have not formally announced or documented this decision. Developing and updating written guidance and agreements is also a leading practice for interagency collaboration. By fully incorporating leading practices into their efforts to collaborate, the agencies could minimize potential overlap and fragmentation, use resources in a more efficient manner, and better ensure the public and other key stakeholders have clarity about the agencies' oversight responsibilities. GAO recommends that FDA and USDA more fully incorporate leading practices for effective collaboration in the agencies' interagency agreement. FDA and USDA partially concurred and indicated a willingness to incorporate these practices in a more detailed agreement, which would also meet the intent of the recommendations. The agencies concurred with the four other recommendations."}
{"id": "govreport_1", "report": "A variety of federal laws, regulations, and policies establish requirements and guidance for EPA to follow when appointing members to serve on advisory committees. For example, one purpose of FACA is to ensure that uniform procedures govern the establishment and operation of advisory committees. Also under FACA, an agency establishing an advisory committee must, among other things, require the committee\u2019s membership to be balanced in terms of the points of view represented and the functions to be performed by the committee. In addition, federal ethics regulations establish when and how federal officials should review financial disclosure forms to identify and prevent conflicts of interest prohibited by federal law for any prospective committee members required to file these forms in connection with their appointments to advisory committees. GSA has provided additional guidance regarding the implementation of ethics requirements under FACA. Various EPA offices and officials are responsible for helping the agency follow these requirements. For example, EPA\u2019s Federal Advisory Committee Management Division\u2014which has overall responsibility for committee management and ensuring that EPA\u2019s advisory committees comply with FACA\u2014developed the Federal Advisory Committee Handbook to clarify roles and responsibilities for complying with relevant requirements. The handbook was written primarily for EPA employees assigned as designated federal officers for committees. These officers are responsible for the day-to-day management of advisory committees and play a central role in identifying and recommending candidates who can help the committees meet their goals. EPA employees assigned as designated federal officers also are responsible for maintaining committee records. According to EPA\u2019s Federal Advisory Committee Handbook, one of the primary reasons that Congress passed FACA was to ensure public access to the records and documents of advisory committees, and that this fosters greater transparency and accountability of agencies\u2019 use of advisory committees. EPA\u2019s Ethics Office is responsible for helping the agency follow federal ethics requirements. Housed within the agency\u2019s Office of General Counsel in headquarters, the Ethics Office oversees all aspects of the agency\u2019s ethics program, including financial disclosure reporting. The Designated Agency Ethics Official coordinates and manages the program. The Designated Agency Ethics Official delegates authority to more than 100 deputy ethics officials located throughout the agency\u2014 including in headquarters and regional offices\u2014to carry out most elements of EPA\u2019s ethics program. For example, deputy ethics officials are to review financial disclosure reports for prospective committee members to identify and prevent conflicts of interest. Deputy assistant administrators, deputy regional administrators, office directors, and other EPA managers may be appointed to serve as deputy ethics officials for their offices as ancillary duties to their other responsibilities. EPA can establish two kinds of advisory committees\u2014non-discretionary and discretionary committees. The agency establishes non- discretionary committees when required to by statute or directed to by the President. For example, the Clean Air Act requires EPA to establish an advisory committee to, among other things, help EPA review standards for national ambient air quality every 5 years. EPA also can establish discretionary committees at the Administrator\u2019s direction if, for example, these committees provide an important and unique perspective on EPA programs or operations. An example of a discretionary committee is the Pesticide Program Dialogue Committee, which was formed to help EPA perform its duties under the Federal Insecticide, Fungicide and Rodenticide Act and related laws. See appendix II for a list of EPA\u2019s 22 advisory committees as of March 31, 2018. EPA must approve the establishment of any subcommittees formed to assist committees with their work. EPA also can appoint different types of members to its advisory committees, depending on the needs of its committees and other considerations. For instance, EPA may appoint a committee member as a federal government employee under an appropriate hiring authority. If EPA expects a federal employee to serve no more than 130 days in any 365-day period, guidance from the U.S. Office of Government Ethics (OGE), which oversees the executive branch\u2019s ethics program, states that the employee should be designated as a special government employee (SGE). If EPA decides not to appoint the committee member as a federal employee, that committee member would be a non-employee representative. EPA decides whether to appoint committee members as federal employees. To help federal agencies such as EPA determine whether to designate committee members as SGEs or representatives, OGE has developed guidance on factors to consider when agencies make these determinations. For example, OGE guidance states that SGEs are expected to provide independent expert advice and provide their best judgment free from conflicts of interest. They are generally subject to federal ethics regulations placed on other federal employees\u2014including the requirement to file financial disclosure forms. In addition, OGE guidance states that representatives serve as the voice of groups or entities with a financial or other stake in a particular matter before an advisory committee. Federal ethics regulations generally do not apply to representative members on FACA committees. GSA has certain government-wide responsibilities for implementing FACA, including maintaining the government-wide FACA database that tracks certain characteristics of advisory committees. Specifically, FACA requires GSA to comprehensively review the activities and responsibilities of each advisory committee annually, including the committees for which EPA officials are responsible. In turn, GSA requires federal agencies responsible for advisory committees to enter data about those committees into the database. GSA and the responsible agency (e.g., EPA) review the data on a fiscal year basis for accuracy and completeness. These reviews are typically completed by February or March of the following year. GSA\u2019s database is accessible by the general public. It includes data on committee members and committee activities from more than 50 agencies going back to 1997. The information on EPA committees includes: whether a committee member is designated as an SGE or representative; the occupation or affiliation of a committee member; state or other geographic information associated with a committee member\u2019s occupation or affiliation; the appointment\u2019s start and end date for each committee member; and the dates that committees held meetings. Based on our review of EPA\u2019s Federal Advisory Committee Handbook, the agency\u2019s established process for appointing advisory committee members includes three main phases. These phases are soliciting nominations, evaluating candidates, and obtaining approvals from relevant EPA offices, such as the Federal Advisory Committee Management Division, before the Administrator or Deputy Administrator makes final appointment decisions. As shown in figure 1, each of the three main phases in EPA\u2019s process involves several smaller steps. Unless noted otherwise, explanations of these steps can be found in the handbook, which documents the agency\u2019s established process. Soliciting nominations involves six basic steps, which are carried out by a committee\u2019s designated federal officer. The steps are as follows: Develop selection criteria. This step involves identifying the specific perspectives or points of view that should be represented by members on the committee, such as specific scientific perspectives or understandings of environmental justice. This step applies to both discretionary and non-discretionary committees. In addition, federal laws establish membership requirements for the agency\u2019s non- discretionary committees that designated federal officers must consider when developing selection criteria. For example, the Clean Air Act requires EPA to appoint seven members\u2014including at least one member of the National Academy of Sciences, one physician, and one person representing state air-pollution control agencies\u2014to an independent scientific advisory committee, known as CASAC. The selection criteria developed in this step should be reflected in the notice soliciting nominations. Develop an outreach plan. This plan should: (1) describe in detail how committees intend to solicit a diverse set of nominees and (2) discuss the specific forms of solicitation. For example, one outreach plan we reviewed specified that EPA staff would solicit nominations from the American Academy of Pediatrics, American Chemical Society, and other organizations that can help EPA review the quality, relevance, and performance of its research programs. Develop membership balance plans for discretionary committees. GSA guidance states that membership balance plans for discretionary committees should describe the process used to ensure that committee membership is balanced in terms of the points of view represented and functions to be performed by the committee. For example, one membership balance plan we reviewed stated that EPA staff would consider candidates from farm worker organizations; pesticide industry and trade associations; state, local and tribal governments; and public health and other organizations. According to that membership balance plan, EPA staff also would consider prospective committee members\u2019 geographic location to help achieve balanced membership. Solicit nominations. During this step, the designated federal officer can solicit nominations via Federal Register notices and other means, such as emails to professional associations and specific EPA email distribution lists. In response to these notices, organizations can nominate individuals, or individuals can nominate themselves or other individuals. Contact nominees after receiving nominations. During this step, the designated federal officer confirms nominees\u2019 qualifications and experience as well as their interest in and availability to serve on the committee. Assess the diversity of the pool of nominees and conduct additional outreach, if needed, to increase the diversity of the pool. EPA\u2019s Federal Advisory Committee Handbook provides illustrative examples of how to follow this step. In one example, the handbook explains that a committee needs a representative from local government. For the past several years, the position has been filled by someone from an affluent suburban county. To increase diversity, the handbook recommends that the designated federal officer broaden outreach to other parts of the country, especially local governments that serve low-income, rural, urban, medically underserved, or vulnerable populations. Evaluating candidates similarly involves several steps. The committee\u2019s designated federal officer is primarily responsible for taking these steps for his or her assigned committee. In addition, a deputy ethics official is to review financial disclosure forms for any prospective members who are required to file these forms. In general, the steps for evaluating candidates are as follows: Evaluate candidates against selection criteria. During this step, the designated federal officer identifies the specific point of view that each candidate would bring to the committee\u2014as well as each candidate\u2019s ability to meet the selection criteria after interviewing candidates and reviewing their curriculum vitae, publications, and other relevant information. EPA\u2019s Federal Advisory Committee Handbook notes that having the best people who represent key interests and balanced viewpoints enables the committee to provide EPA with recommendations that the agency can rely on as collective advice representing diverse stakeholder views. Identifying the best candidates may involve reviewing many more nominees than can be appointed. For example, EPA received approximately 100 nominations for 18 positions on the Science Advisory Committee on Chemicals in fiscal year 2017. Prepare a draft membership grid document with staff- recommended candidates and alternates. After evaluating individual candidates, the handbook directs the designated federal officer to recommend at least one primary and alternate candidate for each point of view and consolidate his or her short-list of recommended candidates into a draft membership grid document. The handbook indicates that this is a key step in the agency\u2019s appointment process. It is intended to help designated federal officers identify gaps as they seek to meet FACA requirements for balanced committee membership. The handbook also directs the designated federal officer to submit the draft membership grid to EPA\u2019s Federal Advisory Committee Management Division, EPA\u2019s Office of General Counsel, and the Assistant Administrator for review and approval before submitting final recommendations to the Administrator. Therefore, the draft membership grid, which documents EPA staff\u2019s rationale for recommending specific candidates, is intended to serve as the basis for discussions with EPA management as final decisions about the committee\u2019s composition are made, according to EPA\u2019s Federal Advisory Committee Handbook. Recommending at least one alternate for each point of view is intended to provide the EPA Administrator or Deputy Administrator\u2014who officially selects committee members based on staff recommendations\u2014with flexibility in appointing members, according to the handbook. Review financial disclosure forms for conformance with applicable conflict-of-interest statutes, regulations issued by OGE including any supplemental agency requirements, and other federal ethics rules, which state, among other things, that: SGEs appointed to serve on federal advisory committees generally must file financial disclosure forms within 30 days of assuming their new positions and either before providing advice to the agency or before the first committee meeting if they are eligible to file confidentially. The designated ethics official from each executive branch agency generally is to review financial disclosure reports within 60 days after receiving them and is to certify by signature and date that the filer is in compliance with federal ethics rules, and this official generally may delegate this responsibility. Obtaining approvals involves several steps and numerous EPA officials. The steps for obtaining approvals generally are as follows: EPA\u2019s Federal Advisory Committee Management Division reviews the proposed membership for balance. EPA guidance states that designated federal officers are to obtain written concurrence from the division before preparing the final membership package for the Administrator to sign. EPA\u2019s Office of General Counsel conducts a legal review of the proposed membership. EPA guidance states that designated federal officers are to obtain written concurrence from the Office of General Counsel prior to appointment. Assistant Administrator or Regional Administrator approves the list of recommended candidates that will be presented to the Administrator\u2019s office. Administrator or Deputy Administrator makes final appointment decisions and signs appointment letters. From fiscal year 2017 through the first two quarters of fiscal year 2018, EPA generally followed its established process for most advisory committees; however, in fiscal year 2018, EPA did not follow a key step in its process for appointing 20 committee members to the SAB and CASAC. SAB is the agency\u2019s largest committee and CASAC is responsible for, among other things, reviewing national ambient air-quality standards. In addition, when reviewing the step in EPA\u2019s appointment process related specifically to financial disclosure reporting, we found that EPA did not consistently ensure that SGEs appointed to advisory committees met federal financial disclosure requirements. Our review of agency documents that supported appointment decisions for the 17 committees that appointed or reappointed committee members from fiscal year 2017 through the first two quarters of fiscal year 2018 found that EPA generally followed its process for most committees. All 14 of the discretionary committees that appointed or reappointed members during this time period developed membership balance plans, as required by GSA\u2019s FACA regulations. In addition, 15 committees followed the step in EPA\u2019s appointment process related to draft membership grid documents. That is, 20 of the 22 appointment packets we reviewed had draft membership grid documents reflecting EPA staff input on the best qualified and most appropriate candidates for achieving balanced committee membership. Additionally, 21 of the 22 appointment packets we reviewed contained documentation showing that EPA\u2019s Office of General Counsel reviewed the proposed membership prior to appointment, as recommended by EPA\u2019s Federal Advisory Committee Handbook. Figure 2 shows EPA\u2019s established process and the steps we reviewed. For additional information about the extent to which EPA followed its process for appointing committee members, see appendix III. However, EPA did not follow a key step in its established process for appointing 20 members in fiscal year 2018 to the SAB and CASAC, which advise the agency on environmental regulatory matters, among other things. Specifically, the fiscal year 2018 appointment packets for the SAB and CASAC did not include draft membership grid documents reflecting EPA staff rationales for recommending the candidates EPA\u2019s staff deem best qualified and most appropriate for achieving balanced committee membership. EPA officials told us in March 2019 that they did not prepare draft membership grids, as recommended by EPA\u2019s Federal Advisory Committee Handbook, because EPA management requested a series of briefings instead. EPA officials also told us that during these briefings, EPA staff presented options for management to consider that reflected staff evaluations and summaries of public comments on candidates. EPA management then decided whom to appoint after reviewing the entire list of personnel nominated for membership\u2014not a short-list of staff-recommended candidates, as called for by EPA\u2019s handbook. During previous appointment cycles, EPA documents indicate and officials told us that EPA followed its established process when appointing committee members to SAB and CASAC. Specifically, documents from SAB\u2019s and CASAC\u2019s fiscal year 2017 appointment cycles indicate that both committees prepared draft membership grids in fiscal year 2017 in accordance with EPA\u2019s established process. In addition, SAB and CASAC staff we interviewed told us that the process they used for filling vacancies prior to the fiscal year 2018 appointments involved vetting candidates before documenting in draft membership grids the candidates they deemed best qualified and most appropriate for achieving balanced committees. EPA officials stated that the briefing process they used in fiscal year 2018 was considered better than the use of draft membership grids, as it allowed EPA management to have in-depth discussions with SAB staff, resulting in better knowledge and a greater understanding of the SAB\u2019s and CASAC\u2019s membership needs. In written comments on the draft report, EPA stated that the vetting of candidates for SAB and CASAC occurred in a different manner than in previous years with a process more robust than membership grids. In addition, EPA stated that the public comment process was more robust, going beyond what was prescribed in the traditional membership process. There may be benefits to such discussions and solicitation of input. However, under EPA\u2019s established process, agency staff are to document in draft membership grids and include in appointment packets their rationales for recommending the candidates they deem best qualified and most appropriate for achieving balanced committees. EPA developed guidance to implement FACA, one purpose of which is to encourage the establishment of uniform committee appointment and administration procedures. In written comments on the draft report, EPA noted that agency staff documented evaluations of advisory committee candidates in briefing documents. However, EPA did not provide these documents along with its comments. Moreover, neither these evaluations nor summaries of public comments were included in the packets that EPA\u2019s Federal Advisory Committee Handbook indicates are to contain committee appointment information, impeding EPA\u2019s ability to ensure that it consistently meets\u2014across all of its advisory committees\u2014FACA\u2019s purpose of encouraging uniform committee appointment procedures. In addition, Federal Standards for Internal Control call for management to design control activities to achieve objectives and respond to risks, such as by clearly documenting all transactions and other significant events in a manner that allows the documentation to be readily available for examination. By directing officials responsible for appointing committee members to follow a key step in EPA\u2019s appointment process\u2014developing draft membership grids to document staff rationales for proposed membership\u2014the agency would also have better assurance that it could show how it made appointment decisions to achieve the best qualified and most appropriate candidates for balanced membership. When reviewing the steps in EPA\u2019s appointment process related specifically to financial disclosure reporting, we found that from fiscal year 2017 through the first two quarters of fiscal year 2018, EPA did not consistently ensure that 74 SGEs appointed or reappointed to serve on EPA advisory committees met federal financial-disclosure requirements. Of the 74 disclosure forms we reviewed, an ethics official signed and dated that the filer was in compliance with federal ethics rules for 77 percent, or 57 of the forms. However, for about 23 percent, or 17 of the 74 financial disclosure forms we reviewed, an ethics official had not signed and dated that the filer was in compliance with federal ethics rules. In addition, for about 57 percent, or 42 of the 74 forms we reviewed, we were unable to determine whether an ethics official had reviewed the financial disclosure forms within 60 days after they were filed because the forms did not indicate when EPA had received them. Table 1 illustrates the extent to which EPA took steps to ensure compliance with federal financial-disclosure-reporting requirements relevant to SGEs during this time period. In 2017, OGE found similar weaknesses in EPA\u2019s ethics program. For example, when OGE reviewed a sample of EPA advisory committees\u2019 ethics documents from 2015, it found that none of the financial disclosure forms for one committee had been reviewed\u2014or signed and dated\u2014by an ethics official to indicate that filers were in conformance with federal ethics rules. For two other committees, OGE found that EPA had not received in 2015 certain financial-disclosure forms that were due that year. We also found that EPA\u2019s Ethics Office had not periodically evaluated, through audits or spot-checks, the quality of financial disclosure reviews conducted by its deputy ethics officials for SGEs appointed to advisory committees, as part of the periodic review of its ethics program called for by OGE regulations. An official we interviewed from EPA\u2019s Ethics Office told us that the office did not have the staffing levels necessary to audit or spot-check financial disclosure reviews for SGEs. In addition, in a June 2018 correspondence to OGE about OGE\u2019s review of EPA\u2019s ethics program, EPA\u2019s Designated Agency Ethics Official stated that EPA\u2019s Ethics Office had fewer than three full-time equivalent positions at times during 2017. The correspondence also stated that the agency\u2019s Office of General Counsel is committed to doubling the Ethics Office\u2019s staffing levels in the future to increase oversight of its deputy ethics officials. Federal regulations and guidance specify that EPA has certain oversight responsibilities for its programs\u2014including its ethics program. For example, OGE regulations: state that designated agency ethics officials, acting directly or through other officials, are responsible for carrying out effective financial disclosure programs by, among other things, using information in financial disclosure reports to prevent and resolve potential conflicts of interest; specify actions the official must take if the reviewing official concludes that information disclosed in the report may reveal a violation of applicable laws and regulations; and state that designated agency ethics officials are responsible for periodically evaluating their agencies\u2019 ethics programs. Standards for Internal Control in the Federal Government also states that management should design control activities to achieve objectives and respond to risks, such as by comparing actual performance to planned or expected results and analyzing significant differences. Because EPA had not periodically evaluated through audits or spot- checks the quality of financial disclosure reviews for SGEs appointed to advisory committees, the agency was not well positioned to compare the program\u2019s actual performance with planned results or address instances of noncompliance with federal ethics requirements. Until EPA\u2019s Ethics Office, as part of its periodic review of its ethics program, evaluates\u2014for example, through audits or spot-checks\u2014the quality of financial disclosure reviews conducted for SGEs appointed to EPA advisory committees, it will not have reasonable assurance that it is addressing noncompliance with federal ethics requirements and preventing conflicts of interest among SGEs appointed to EPA advisory committees. EPA officials acknowledged that taking this additional oversight measure could enhance the agency\u2019s ethics program. Of the four characteristics we reviewed\u2014committee composition, regional affiliation, membership turnover, and number of committee meetings\u2014 one or more of the first three characteristics changed notably for four of 18 of EPA\u2019s advisory committees after January 2017. There were no notable changes in the four characteristics we reviewed for the other 14 committees for which we reviewed at least one of the characteristics. The committee composition, regional affiliation, or membership turnover of four of EPA\u2019s advisory committees changed notably after January 2017 compared to the period after January 2009. There was no notable change in the fourth characteristic we reviewed\u2014that is, the number of meetings committees held. Each change identified as notable had at least a 20 percentage point difference in the change to the characteristic after January 2017 compared to the period after January 2009. See appendix I for additional information about our methodology. There was a notable decrease in the percentage of members affiliated with academic institutions on the SAB and EPA Board of Scientific Counselors (BOSC) committees after January 2017 compared to the period after January 2009. Our analysis shows that the percentage of committee members with an academic affiliation serving on the SAB decreased by 27 percentage points, or from 77 percent (36 of 47 members) on January 19, 2017, to 50 percent (22 of 44 members) about 15 months later on March 31, 2018. There was little change in the period after January 2009, when the percentage of academic members serving on the SAB remained stable at 83 percent (33 of 40 members) on January 19, 2009, and 82 percent (32 of 39 members) about 15 months later on March 31, 2010. Regarding 2013, academic members serving on the SAB decreased from 82 percent (40 of 49 members) on January 20, 2013 to 73 percent (37 of 51 members) about 15 months later. In addition to academic members, other members serving on the SAB are (1) affiliated with government (federal, local, state, or tribal) or with industry or non-government organizations (NGO); (2) are consultants; or (3) are others we could not assign to one of the above categories. See figure 3. BOSC also experienced a notable decrease in the percentage of members with an academic affiliation serving on the committee after January 2017 compared to the period after January 2009. Our analysis shows that the percentage of committee members with an academic affiliation serving on BOSC decreased by 45 percentage points, or from 65 percent (11 of 17 members) on January 19, 2017, to 20 percent (3 of 15 members) about 15 months later on March 31, 2018. There was little change in the percentage of academic members serving on BOSC after either January 2009 or January 2013. The percentage of members with an academic affiliation serving on BOSC was 55 percent (6 of 11 members) on January 19, 2009, and 56 percent (5 of 9 members) about 15 months later on March 31, 2010. Seven of 12 members were affiliated with academic institutions on January 20, 2013, and 5 of 9 members were similarly affiliated about 15 months later. See table 2. The regional affiliation of SAB committee members also changed notably after January 2017 compared to the period after January 2009. Our analysis shows that members affiliated with the southern region\u2014which spans from Texas to Delaware\u2014increased by about 25 percentage points, or from 28 percent (13 of 47 members) on January 19, 2017, to 52 percent (23 of 44 members) about 15 months later on March 31, 2018. There was little change in the period after January 2009, when the percentage of members affiliated with the southern region increased from 30 percent (12 of 40 members) on January 19, 2009, to 33 percent (13 of 39 members) about 15 months later on March 31, 2009. Regarding 2013, members affiliated with the southern region decreased from 33 percent (16 of 49 members) on January 20, 2013, to 27 percent (14 of 51 members) about 15 months later. Figure 4 shows the regional affiliation of SAB members using U.S. Census regions after January 2017 and January 2009. There was also a notable change in the number of members who left three committees after January 2017 compared to the number of members who left those committees after January 2009. Our analysis shows that of the members serving on January 19, 2017, 71 percent (12 of 17 members) of BOSC, 62 percent (23 of 37 members) of the Clean Air Act Advisory Committee, and 63 percent (25 of 40 members) of the Pesticide Program Dialogue Committee were no longer serving about 15 months later on March 31, 2018. There was little change in the period after January 2009, when 18 percent (2 of 11 members) of the members of BOSC and 3 percent (one of 35 members) of the members serving on the Clean Air Act Advisory Committee on January 19, 2009, were no longer serving on the committees about 15 months later on March 31, 2010. All of the members serving on the Pesticide Program Dialogue Committee (34 members) on January 19, 2009, were also serving about 15 months later on March 31, 2010. Regarding 2013, 25 percent (3 of 12 members) serving on BOSC on January 20, 2013, were not serving about 15 months later. All members serving on the other two committees on January 20, 2013, were also serving about 15 months later. In most instances, the four characteristics that we analyzed\u2014committee composition, regional affiliation, membership turnover, and number of committee meetings held\u2014did not change notably for the committees we reviewed from January 2017 to about 15 months later compared to the same time frame after January 2009. In many of these instances, the characteristics we analyzed had changed, but these changes were not large enough to be considered notable based on the approach we used to identify notable changes. Other than the SAB and BOSC, there were no notable changes after January 2017 in the composition of the five committees for which we analyzed this characteristic. We analyzed the committee composition of the three other committees combined because they did not have enough members to make individual analysis meaningful. Our analysis shows that the largest change after January 2017 that we did not identify as notable also occurred with BOSC. The percentage of members serving on BOSC with a government affiliation increased by 22 percentage points, or from 18 percent (3 of 17 members) on January 19, 2017, to 40 percent (6 of 15 members) about 15 months later on March 31, 2018. This compares to 2009 when the percentage of members serving on BOSC with a government affiliation remained at zero percent on January 19, 2009, (11 members) and about 15 months later on March 31, 2010, (9 members). Other than the SAB, there were no notable changes after January 2017 in the regional affiliation of members of the 10 committees for which we analyzed this characteristic. In addition to the SAB, we analyzed the regional affiliation of three other committees individually and the remaining six committees combined. The largest change in regional affiliation after January 2017 that we did not identify as notable also occurred with the SAB. Members affiliated with the northeast region decreased by more than 14 percentage points, or from 28 percent (13 of 47 members) on January 19, 2017, to 14 percent (6 of 44 members) about 15 months later on March 31, 2018. This compares to 2009 when the percentage of members affiliated with the northeast region stayed about the same, changing from 20 percent (8 of 40 members) on January 19, 2009, to 18 percent (7 of 39 members) about 15 months later on March 31, 2010. Other than BOSC, the Clean Air Act Advisory Committee, and the Pesticide Program Dialogue Committee, there were no notable changes after January 2017 to membership turnover for the 14 committees for which we analyzed this characteristic. In addition to these three committees, we analyzed the membership turnover of six other committees individually and the remaining five committees combined. Our analysis shows that the largest change in membership turnover after January 2017 that we did not identify as notable occurred with the SAB. Of the members serving on this committee on January 19, 2017, 45 percent (21 of 47 members) were no longer serving about 15 months later on March 31, 2018. This compares to 2009 when 35 percent (14 of 40 members) serving on January 19, 2009, were not serving about 15 months later on March 31, 2010. There was no notable change in the percentage decrease of meetings held before and after January 2017 compared to a similar time frame before and after January 2009. We analyzed the number of meetings held by 18 committees. Our analysis shows that for the 18 committees combined, the number of meetings decreased by 40 percent (from 90 to 54 meetings) from the approximately 15 month period before January 2017 to the approximately 15 month period after January 2017. This compares to a 27 percent decrease in meetings (from 164 to 120 meetings) from the approximately 15-month period before January 2009 to the approximately 15-month period after January 2009. Overall, there was a decrease in the number of meetings from before January 2009 to after January 2017. The number of meetings held by the 18 committees combined decreased 67 percent (from 164 to 54 meetings) from the approximately 15-month period before January 2009 to the approximately 15-month period after January 2017. Figure 5 illustrates the decrease in the number of meetings held during this time frame. The figure shows the number of meetings held by SAB separately because of the relatively large number of meetings that it held relative to the other committees. EPA\u2019s federal advisory committees play an important role in advising the agency. EPA generally followed its established process for 15 of the 17 advisory committees that appointed or reappointed committee members during the time period we reviewed. However, EPA did not follow a key step in its process for appointing 20 members to two committees that advise the agency on environmental regulatory matters, among other things. The agency did not prepare draft membership grids with staff rationales for proposed membership, the documents intended to reflect EPA staff input on the best qualified and most appropriate candidates for achieving balanced committee membership before appointing these members. EPA officials told us in March 2019 that they did not prepare draft membership grids, as recommended by EPA\u2019s Federal Advisory Committee Handbook, because EPA management requested a series of briefings instead. There may be benefits to following different procedures; however, under EPA\u2019s established process, agency staff are to document in draft membership grids and include in appointment packets their rationales for recommending the candidates they deem best qualified and most appropriate for achieving balanced committees. By directing officials responsible for appointing committee members to prepare draft membership grids and include them in appointment packets for all committees, the agency would have better assurance that it could show how it made appointment decisions to achieve the best qualified and most appropriate candidates for balanced committee membership. EPA also did not consistently ensure that committee members appointed as SGEs met federal ethics requirements, and as part of its periodic review of its ethics program, EPA did not evaluate through audits or spot- checks the quality of financial disclosure reviews conducted by deputy ethics officials for these committee members. Until EPA\u2019s Ethics Office periodically evaluates\u2014for example, through audits or spot-checks\u2014the quality of financial disclosure reviews conducted for SGEs appointed to EPA advisory committees, it will not have reasonable assurance that it will address noncompliance with federal ethics requirements and prevent conflicts of interest among SGEs appointed to EPA advisory committees. We are making the following two recommendations to EPA: The EPA Administrator should direct EPA officials responsible for appointing advisory committee members to follow a key step in its appointment process\u2014developing and including draft membership grids in appointment packets with staff rationales for proposed membership\u2014 for all committees. (Recommendation 1) EPA\u2019s Designated Agency Ethics Official should direct EPA\u2019s Ethics Office, as part of its periodic review of EPA\u2019s ethics program, to evaluate\u2014for example, through audits or spot-checks\u2014the quality of financial disclosure reviews for special government employees appointed to EPA advisory committees. (Recommendation 2) We provided a draft of this report to EPA for review and comment. In its written comments, reproduced in appendix IV, EPA disagreed with a key finding related to the first recommendation, with how we conducted some of our data analyses, and with some of the data points we presented. EPA agreed with the findings and conclusions related to the second recommendation. EPA also provided other comments, which we incorporated as appropriate. EPA stated that it believed a key finding related to the draft report\u2019s first recommendation\u2014that EPA follow, for all committees, the key step in its appointment process related to developing draft membership grids\u2014was in error and should be removed from the final version of the report. EPA also stated that it followed all membership steps outlined in agency guidance with the exception of two committees, SAB and CASAC, who substituted the development of a membership grid with what the agency states was a more rigorous examination of the candidates (a series of briefings with senior management discussing the strengths and weaknesses of potential candidates). EPA stated that this is within the discretion of the EPA Administrator and that the vetting of candidates for SAB and CASAC occurred in a different manner than in previous years with a process more robust than membership grids. In addition, EPA stated that the public comment process was more robust, going beyond what was prescribed in the traditional membership process. According to EPA, for SAB and CASAC, the public was offered additional opportunity to provide input on all nominated candidates under consideration. We agree that conducting such briefings is within the discretion of the EPA Administrator, and we did not assess the outcomes of the membership appointment process. However, it remains that for SAB and CASAC, EPA did not follow a key step in its established appointment process\u2014as documented in its agency-wide handbook\u2014in which agency staff are to document in draft membership grids their rationales for recommending the candidates they deem best qualified and most appropriate for achieving balanced committees. While there may be benefits to following any number of alternative processes for appointing committee members, as EPA stated in its Federal Advisory Committee Advisory Handbook, EPA developed the handbook to help agency officials comply with FACA requirements. For these two advisory committees, EPA did not follow its established committee appointment process, impeding EPA\u2019s ability to ensure that it consistently meets\u2014 across all of its advisory committees\u2014FACA\u2019s purpose of encouraging uniform committee appointment procedures. Furthermore, EPA did not provide documentation of the \u201cmore rigorous examination\u201d of candidates it conducted in briefings. In its written comments, EPA stated that the SAB Staff Office documented staff evaluations in briefing documents and that we did not request such documents. However, we requested all appointment packets for the 17 committees that appointed or reappointed committee members from fiscal year 2017 through the first two quarters of fiscal year 2018. These appointment packets were to contain the documents used by EPA management to make appointment and reappointment decisions. EPA did not include the briefing documents in their packets for the SAB or CASAC, impeding EPA\u2019s ability to ensure that it consistently meets\u2014 across all of its advisory committees\u2014FACA\u2019s purpose of encouraging uniform committee appointment procedures. Nor did the agency provide any such documentation in subsequent discussions about the extent to which the agency followed its established process. Our most recent meeting with EPA took place on March 19, 2019. As appropriate, we modified the report to further clarify our specific finding. Moreover, EPA disagreed with how we conducted some of our data analyses and with some of the data points we presented. We took numerous steps to ensure the accuracy of the data points presented in this report. In some instances, we identified missing or inconsistent data and shared this information with EPA officials. EPA provided some corrected data for members with missing or inconsistent appointment- date data from October 1, 2015 to March 31, 2018. We also asked EPA staff to confirm that the data had been updated in the FACA database, discussing the data with individual EPA staff members, conducting logic tests and spot-checking the data to identify errors and inconsistencies, and providing EPA with an opportunity to review and correct in writing the data presented prior to preparing our draft report. Also, in its written comments, EPA stated that we did not review data for BOSC subcommittees. Our methodology focused on the composition of committees and not their subcommittees. We continue to believe that the methodology we employed to analyze data was appropriate. We outline our rationale in appendix I, which includes the steps we took to ensure data reliability. For these reasons, we do not plan to make any further changes based on the additional data EPA provided. Lastly, EPA did not dispute our findings and conclusions related to the second recommendation that the agency evaluate, for example, through audits or spot checks, the quality of financial disclosure reviews for special government employees appointed to EPA advisory committees. EPA noted that at the time of our audit, its Ethics Office was understaffed. In its written comments, EPA said that it has now resolved these staffing issues and is engaged in a full and thorough review of all employees\u2019 (including special government employees serving on federal advisory committees) ethics forms to ensure they meet all ethics requirements. As agreed with your offices, unless you publicly announce the contents of this report earlier, we plan no further distribution until 30 days from the report date. At that time, we will send copies of this report to the appropriate congressional committees, the Administrator of the U.S. Environmental Protection Agency, the Administrator of the U.S. General Services Administration, and the Director of the U.S. Office of Government Ethics. In addition, the report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staff members have any questions about this report, please contact me at (202) 512-3841 or gomezj@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff members who made major contributions to this report are listed in appendix V. To describe the U.S. Environmental Protection Agency\u2019s (EPA) established process for appointing members to serve on EPA advisory committees, we identified and reviewed the federal laws, regulations, and policies that are relevant to EPA\u2019s process for appointing advisory committee members. To ensure that we correctly identified all relevant laws, regulations, and guidance, we consulted with: (1) the Committee Management Secretariat at the U.S. General Services Administration (GSA), which issues regulations and guidance for Federal Advisory Committee Act (FACA) committees government-wide; (2) the U.S. Office of Government Ethics, which develops ethics-related regulations for executive branch employees; and (3) EPA. Examples of EPA guidance that we reviewed include EPA\u2019s Federal Advisory Committee Handbook, Strengthening and Improving Membership on EPA Federal Advisory Committees, and EPA Ethics Advisory 2008-02. To evaluate the extent to which EPA followed its established process for appointing members from fiscal year 2017 through the first two quarters of fiscal year 2018, we reviewed pertinent documentation from the 17 committees that appointed or reappointed advisory committee members during this time frame. The remaining committees did not appoint any committee members during the time frame we reviewed. For the above- mentioned 17 committees, we reviewed all advisory committee appointment packets\u2014each of which can contain appointment documents for numerous appointees or reappointees\u2014produced during this time. We also reviewed the first section (Section 1: Identifying Information and Record of Agency Review) of the Confidential Financial Disclosure Form for EPA Special Government Employees (EPA Form 3110-48) for 74 individuals who were required to submit them to EPA to determine if they met federal financial-disclosure-reporting requirements. We reviewed all 74 of the forms provided by the 8 committees that appointed or reappointed special government employees (SGE) to serve on a committee from fiscal year 2017 through the first two quarters of fiscal year 2018. Additionally, we interviewed EPA officials involved with appointing committee members to understand the steps these officials took. We then compared the steps they described taking with selected steps in EPA\u2019s established process for appointing members to evaluate the extent to which the agency followed its process. We focused on steps in the appointment process that were to be documented in the appointment packets, which EPA used to support appointment decisions. Specifically, we reviewed those aspects of the process for which EPA had documentary evidence, and we evaluated the implementation of ethics oversight requirements that are relevant to EPA\u2019s committee-member appointment process. To determine whether the agency followed selected steps in its established process, two senior analysts reviewed the appointment packets. Specifically, one senior analyst conducted the primary analysis for about half of the 22 appointment packets we received, while the other conducted the primary analysis for the remaining packets. Afterwards, each analyst reviewed the other\u2019s conclusions and noted agreement or disagreement based on the evidence provided. In some cases, discussion was necessary to resolve differences of opinion between the two analysts. Those discussions were documented. If additional documentation was necessary to resolve differences of opinion, we obtained additional information from the agency. The two analysts reached agreement on all of the packets. To describe how, if at all, selected characteristics of EPA\u2019s advisory committees changed after January 2017, we analyzed information from the FACA database, a publically-available database maintained by GSA. The database contains information about FACA advisory committees that agencies, including EPA, are required to provide. The initial scope of our review was the 22 committees in existence on March 31, 2018. Of these 22 committees, we excluded from all of our analyses the four committees that were established after November 2007 because this is the earliest date of one of our analyses. We also excluded four other committees from the three analyses that rely on member appointment start and end dates (committee composition, membership turnover, and regional affiliation) because of missing or inconsistent data. Additionally, we excluded some other committees from some of our analyses because of other types of data reliability issues or because of the nature of the characteristic. To assess the reliability of the committee data, we reviewed database technical documentation and interviewed GSA and EPA officials to identify any potential issues with our planned analysis of the data, among other things, and determined that overall the data were sufficiently reliable for conducting analysis to describe changes in selected member and committee characteristics for our selected time periods. We discuss additional steps we took to assess the reliability of the data and data reliability issues with the FACA database at the end of this appendix. Additionally, appendix II identifies which committees we excluded from which analyses and the reasons why. Primarily using information available in the FACA database, we compared changes in four committee characteristics across committees and changes in presidential administrations. Specifically, we measured the characteristics before and after January 20, 2017, and compared them to similar periods before and after January 20, 2009. Additionally, we also compared the characteristics to those before and after January 21, 2013, to provide context to our findings and identify any patterns over time in the data. The four characteristics we measured and compared across committees and changes in presidential administrations were: Number of committee meetings For the first two characteristics, we compared across committees the percentage of members in the characteristics\u2019 categories on either January 19, 2017, or January 19, 2009, to a day about 15 months later (either March 31, 2010, or March 31, 2018). For membership turnover, we compared across committees the percentage of members on either January 19, 2017, or January 19, 2009, who left a committee by about 15 months later (either March 31, 2010, or March 31, 2018). We chose March 31, 2018, to allow for a period of time after January 2017 for changes to occur in committee characteristics, and the fiscal year 2018 data file we received from GSA was updated as of March 31, 2018. For the fourth characteristic, we compared across committees the number of meetings held in the 15 months before January 20, 2009 and January 20, 2017, to a similar period after those dates (November 12, 2007, to March 31, 2010, or November 12, 2015, to March 31, 2018). To identify changes to a characteristic that were notable, we used the following methodology. First we identified any changes after January 2017 that were large relative to other changes to that characteristic after January 2017. If we identified a relatively large change, we then compared it to changes to the characteristic after January 2009 to assess whether it was large relative to those changes. If it was, we would identify the change as notable. The committees we analyzed individually had at least 10 members (or 10 meetings) in the relevant time periods being measured, with the exception of two committees which had nine members on March 31, 2010. We analyzed the other committees combined since relatively small changes in counts would have a relatively large impact on percentages. We measured the committee composition of 5 of 18 committees. We excluded 4 of the 18 committees because of data reliability issues and 9 committees because they were not staffed primarily with SGEs. We limited the committee composition analysis to SGEs because SGEs are expected to provide their best judgement free from conflicts of interest, rather than represent a particular viewpoint. We analyzed two of the five committees individually and the other three committees combined. To measure the composition of the five committees, we first categorized each member\u2019s occupation from the \u201coccupation/affiliation\u201d field in the FACA database into one of six categories. The categories were: non-government organization (NGO); or other. To assign the categories, one GAO analyst reviewed the occupation/affiliation data for each member and assigned one of five categories (academic, consultant, government, industry, or NGO) to each member. In instances where it was unclear what category to assign, the analyst conducted online searches regarding the occupation/affiliation information to identify the type of entity and assign a category. We assigned the category \u201cother\u201d in 30 instances where the member was affiliated with more than one of the other categories, not affiliated with any of the other categories (for example, retired), or for which the FACA database did not provide sufficient information to assign one of the other categories. A second analyst reviewed the reasonableness of the categories assigned by the first analyst\u2014including the additional research. The two analysts reached consensus on the categories for each member. We then applied the methodology described above to identify notable changes in committee composition after January 2017. We measured the regional affiliation of 10 of 18 committees. We excluded 8 committees because of data reliability issues. We analyzed 4 of the 10 committees individually and the other 6 committees combined. To measure the regional affiliation of the 10 committees, we assigned one of four U.S. Census regions (as defined by the U.S. Census Bureau) to each committee member based on data in the \u201coccupation/affiliation\u201d field in the FACA database for that member\u2014in most instances, state information is included in this field. We then applied the methodology described above to identify notable changes in regional affiliation to the period after January 2017. The regions were: Western. We measured membership turnover in 14 of 18 committees. We excluded 4 committees because of data reliability issues. We analyzed 9 of the committees individually and the other 5 committees combined. To measure membership turnover of the 14 committees, we used date fields indicating when committee members began and ended their terms to determine the percentages of members on a committee on January 19, 2017, and January 19, 2009, who were not members about 15 months later. We then applied the methodology described above to identify notable changes in membership turnover after January 2017. We measured the change in the number of meetings for 18 committees. We analyzed two of the committees individually and the other 16 committees combined. To measure this characteristic, we used data on the date that meetings were held (we used the date that the meeting began if it was a multi-day meeting). We then applied the methodology described above to identify notable changes in the number of meetings after January 2017. We assessed the reliability of the data provided to us by GSA and took certain steps to prepare the data for analysis. GSA provided us with data files downloaded to Excel from its FACA database from October 1, 2005, to March 31, 2018, for our analysis. GSA maintains the FACA database on a fiscal year basis. During the fiscal year, staff in each agency, including EPA, are to enter data to reflect any changes about the agency\u2019s FACA committees. At the end of each fiscal year, GSA is to perform, in conjunction with each agency, an annual comprehensive review of the data entered into the database by the agency for that fiscal year. According to GSA officials, these reviews constitute the agency\u2019s main process for ensuring the reliability of the database. Once the review is complete, the data are locked down, meaning they can no longer be changed. We received data through the 2017 fiscal year after GSA completed the 2017 review. Because this latest GSA review was the end of fiscal year 2017 and we wanted to include data into 2018, we requested that EPA update the database to March 31, 2018, for each committee for certain data fields relevant to our analyses. We asked that for each committee, the EPA staff member responsible for entering a committee\u2019s data in the FACA database provide confirmation to us that the data had been updated through March 31, 2018. After we received confirmation that data for the 22 committees in existence on March 31, 2018, had been updated, GSA staff provided us the data update for EPA committees from October 1, 2017, through March 31, 2018. To further assess the reliability of these data, we reviewed the database\u2019s technical documentation and interviewed GSA and EPA officials to identify any potential issues with our planned analysis of the data. We conducted logic tests and spot-checked the data to identify errors and inconsistences. For example, we scanned committee member\u2019s names to identify potential duplicates of the same person in the same committee and made corrections where appropriate. If a person served on more than one committee, we included that person separately for each committee on which he or she served. For each member, we also checked the appointment start and end dates indicated in each fiscal year for inconsistencies across fiscal years. In some instances, we identified missing or inconsistent data in these dates and shared this information with EPA officials. EPA was able to provide some corrected data for members with missing or inconsistent appointment-date data from October 1, 2015, to March 31, 2018. We excluded from our analyses four committees for which over 30 percent of members had appointment date issues we were not able to resolve, as well as individual members with unresolved date issues for the committees we included in the analysis. We also checked the 2018 data that GSA provided to us against the data posted to EPA\u2019s website. We determined that overall the data were sufficiently reliable for conducting analysis to describe changes in selected member and committee characteristics for our selected time periods. Finally, we took steps to structure the data provided by GSA in the format needed for our analyses. Specifically, because GSA maintains its data on a fiscal year basis, the data we received from GSA contained a separate row in the database for each committee member for each fiscal year that he or she was a member. To facilitate our analyses, we transposed the dataset so there was one row for each member (for each committee, if a member was in more than one committee) that contained the data from all of the fiscal year records for that member. We conducted this performance audit from October 2017 to July 2019 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. Table 3 provides information about each of the 22 advisory committees managed by the U.S. Environmental Protection Agency (EPA) as of March 31, 2018. For each of these committees, the table also identifies whether we included it in one or more of our analyses. If we excluded a committee from certain analyses, we also explain why. Table 4 summarizes the number of advisory-committee appointment packets for which the U.S. Environmental Protection Agency (EPA) did or did not follow the steps we evaluated for appointing members to serve on EPA advisory committees. In addition to the individuals named above, Joseph Thompson (Assistant Director), John Delicath, Charles Egan, Chad Gorman, Richard Johnson, Yvonne Jones, Mary Koenen, James Lager, Amber Sinclair, and Kiki Theodoropoulos made important contributions to this report.", "summary": "Federal advisory committees provide advice to federal agencies on many topics. As of March 31, 2018, EPA managed 22 such committees. They advise the agency on such issues as developing regulations and managing research programs. Questions have been raised about EPA's process for appointing committee members after recent policy changes affecting who serves on the advisory committees. GAO was asked to review issues related to how EPA appoints advisory committee members. This report examines: (1) EPA's process for appointing advisory committee members, (2) the extent to which EPA followed its process for selecting members from October 2016 through March 2018, and (3) how, if at all, selected characteristics of EPA advisory committees changed after January 2017. GAO reviewed relevant federal laws, regulations, and guidance; reviewed documents from committees that appointed members over this period; analyzed information from the GSA's FACA database; and interviewed agency officials. Based on GAO's review of U.S. Environmental Protection Agency's (EPA) guidance, the agency's established process for appointing advisory committee members involves three main phases: soliciting nominations, evaluating candidates, and obtaining approvals. Each phase involves several steps. For example, a key step for evaluating candidates involves EPA staff's preparing documents that reflect staff recommendations on the best qualified and most appropriate candidates for achieving balanced committee membership, according to EPA guidance. EPA generally followed its established process for most of its 22 advisory committees; however, in fiscal year 2018, EPA did not follow a key step for appointing 20 committee members to two committees GAO reviewed: the EPA Science Advisory Board and Clean Air Scientific Advisory Committee, which advise the agency on environmental regulatory matters, among other things. The 2018 appointment packets for these two committees did not contain documents reflecting EPA staff rationales for proposed membership, as called for by EPA's established process. EPA developed guidance to implement the Federal Advisory Committee Act (FACA). By directing officials responsible for appointing committee members to follow a key step in its process to document staff rationales for proposed membership, the agency would have better assurance that it will (1) consistently meet FACA's purpose of encouraging uniform appointment procedures and (2) show how it made appointment decisions to achieve the best qualified and most appropriate candidates for balanced committee membership. EPA also did not consistently ensure that members appointed as special government employees (SGE)\u2014who are expected to provide their best judgment free from conflicts of interest and are required by federal regulations to disclose their financial interests\u2014met federal ethics requirements. For about 23 percent, or 17 of the 74 financial disclosure forms GAO reviewed, an ethics official had not signed and dated that the SGE filing the form was in compliance with federal ethics rules. EPA also did not periodically review its ethics program, as called for by federal regulations, such as through audits or spot-checks, to evaluate the quality of financial disclosure reviews for SGEs. Until EPA's Ethics Office evaluates the quality of financial disclosure reviews of SGEs as part of its periodic review of its ethics program, it will not have reasonable assurance that it will address noncompliance with federal ethics requirements and prevent conflicts of interest on its advisory committees. Based on GAO's review of the U.S. General Services Administration's (GSA) FACA database, there were notable changes to selected characteristics of EPA advisory committees (i.e. at least a 20 percentage point difference in the change to a characteristic after January 2017 compared to the period after January 2009). Of the four characteristics GAO reviewed\u2014committee composition, regional affiliation, membership turnover, and number of meetings committees held\u2014one or more of the first three changed notably for four of 18 EPA advisory committees after January 2017. GAO is recommending that EPA direct (1) officials responsible for appointing committee members to follow a key step in its appointment process to document staff rationales for proposed membership and (2) EPA's Ethics Office to evaluate the quality of financial disclosure reviews of SGEs appointed to advisory committees. EPA disagreed with the first and agreed with the second recommendation. GAO continues to believe that both are valid, as discussed in the report."}
{"id": "govreport_2", "report": "According to the National Research Council, although the exact details cannot be predicted with certainty, climate change poses serious risks to many of the physical and ecological systems on which society depends. Moreover, according to key scientific assessments, the effects and costs of extreme weather events such as floods and droughts will increase in significance as what are considered rare events become more common and intense because of climate change. According to the National Academies of Sciences, Engineering, and Medicine, extreme weather events are directly traceable to loss of life, rising food and energy prices, increasing costs of disaster relief and insurance, fluctuations in property values, and concerns about national security. Table 1 shows seven effects commonly associated with climate change that DOD has documented. According to a 2010 National Research Council report on making informed decisions about climate change and our October 2009 report on climate change adaptation, most decision makers need a basic set of information to understand and make choices about how to adapt to the effects of climate change. This set of information includes information and analysis about observed climate conditions, information about observed climate effects and vulnerabilities, and projections of what climate change might mean for the local area. In November 2015, we found that in order for climate information to be useful, it must be tailored to meet the needs of each decision maker, such as an engineer responsible for building a bridge in a specific location, a county planner responsible for managing development over a larger region, or a federal official managing a national-scale program. Agencies across the federal government collect and manage many types of climate information, including observational records from satellites and weather monitoring stations on temperature and precipitation, among other things; projections from complex climate models; and tools to make this information more meaningful to decision makers. For example, the Fourth National Climate Assessment, completed in November 2018 by the U.S. Global Change Research Program, references various sources of climate information, including projected temperature and precipitation data. Likewise, in 2016, a multi-agency group led by the Strategic Environmental Research and Development Program (SERDP) developed a report and accompanying database of future sea level projections and extreme water levels, which as of May 2019 contained sea level change projections for 1,813 DOD sites worldwide. Climate projections are typically a range of possible future scenarios for particular time frames. Multiple future scenarios allow for planners and engineers to see a range of possible conditions that could occur at various points in time. For example, a planner or engineer could consider four different future scenarios occurring over the course of 20, 40, or 60 years or over the service life of the project being designed. Figure 1 shows an example of sea level change projections provided by the National Oceanic and Atmospheric Administration (NOAA). Specifically, the chart shows historical mean sea levels and multiple scenarios of projected relative sea level rise in Norfolk, Virginia. The chart shows the historical annual mean sea level from 1960 to 2018 through the bold black line. The projections use 2000 as a starting point, and so overlap with the historical data. Relative sea level rise takes into account changes in land levels\u2014in the Norfolk area the land is generally subsiding over time. Each scenario is based on different assumptions about future greenhouse gas emissions, according to an official from NOAA\u2019s National Ocean Service. Planners and engineers can use the multiple scenarios to evaluate when potential effects could occur and determine their risk tolerances to inform their planning or design choices. Figure 2 similarly shows the same historical mean sea levels at Norfolk, Virginia, as well as the very likely range of projections of future relative sea levels, according to the National Ocean Service. This chart shows the range of possibilities considered very likely\u2014those between the low and intermediate scenarios in figure 1\u2014according to an official from NOAA\u2019s National Ocean Service. Master planning for military installations involves the evaluation of factors affecting the present and future physical development and operation of a military installation. DOD requires all installations to develop master plans. DOD\u2019s instruction on real property management states that plans must be based on a strategic assessment of the operational mission and expected use of the installation. The plans must cover at least a 10-year period and be updated every 5 years, or more often if necessary. The plans must include lists, by year, of all construction projects, major repair and sustainment projects, and restoration and modernization projects needed within the time period covered by the plan. Individual DOD facilities projects within installations must be designed in accordance with DOD\u2019s facilities design standards, which are defined in the Unified Facilities Criteria. Unified Facilities Criteria are technical manuals and specifications used for planning, design, construction, maintenance, and operations of all DOD facilities projects. The U.S. Army Corps of Engineers, Naval Facilities Engineering Command, and the Air Force Civil Engineer Center are responsible for administering and updating the Unified Facilities Criteria. The Unified Facilities Criteria include a core group of 27 standards that apply to building systems found in most DOD facility construction projects, and include standards such as architecture, roofing, and civil engineering. Engineers and planners apply the criteria that are most appropriate for their individual facilities projects to their project proposals and designs. Table 2 shows excerpts from requirements and guidance to project designers in the Unified Facilities Criteria relevant to the consideration of climate. Table 2. Excerpts from Unified Facilities Criteria Requirements and Guidance on Consideration of Climate Excerpt consider site-specific, long-term, climate change impacts such as drought, flood, wind, and wildfire risks. Knowing the probable wind speed and direction in a particular month can be helpful in construction and mission planning as well as in designing structures that experience severe wind-driven rain or drifting snow. Pumps, piping, and equipment must be protected from the weather. In cold climates pumps and piping must be protected from freezing temperatures. The pump station building must comply with 1-200-01 , be constructed of noncombustible materials and meet applicable building standoff distances. In new construction, the roof system selection is an integral part of the overall building design and must take into account interior building usage and climate. For example, the building can be designed to prevent outward moisture drive, support heavy roof systems (such as garden roofs or paver systems), or sloped for the desired durability (life cycle cost benefit) and aesthetic considerations. Building shape, orientation, and design must utilize the site seasonal environmental factors to minimize annual facility energy use and to optimize daylighting. Coordinate building and glazing orientation and architectural shading with seasonal solar angles and prevailing winds to enhance energy performance of the building within the site-specific micro climate. Streets, paved parking lots, roofs, and other impermeable surfaces allow no infiltration of runoff and provide little resistance to flow. Runoff draining from these surfaces can be highly concentrated and move at a velocity greater than runoff flowing over an unpaved surface. Soils must be protected from this erosive force, particularly at the edges of impermeable surfaces and soils. 11988 directs all Federal agencies to avoid floodplain development wherever there is a practicable alternative. When development within the floodplain is considered, evaluate alternative site locations to avoid or minimize adverse impacts to the floodplain. When mission needs require siting a building within or partially within the 100-year floodplain, indicate\u2026the base flood elevation\u2026and the minimum design flood elevation\u2026. Extreme weather and climate change effects can damage infrastructure, requiring repairs and resulting in budgetary risks (i.e., costs) to DOD. While no individual weather event can be definitively linked to climate change, particular weather events can demonstrate the vulnerability of military facilities. For example, in October 2018, Hurricane Michael devastated Tyndall Air Force Base in Florida, shutting down most base operations until December; causing severe damage to the flight line, drone runway, and other base facilities including family housing; and destroying the base\u2019s marina. The Air Force estimates that repairs at the base will cost about $3 billion and take 5 or more years to complete. Camp Lejeune and Marine Corps Air Stations Cherry Point and New River in North Carolina sustained heavy damage to facilities, housing, and training locations from Hurricane Florence in September 2018. The Marine Corps estimates that the recovery from the hurricane damage will cost about $3.6 billion and take years to complete. In 2014, we reported that more frequent and more severe extreme weather events and climate change effects may result in increased fiscal exposure for DOD. In the same report, officials provided examples of costs associated with extreme weather and climate change effects at DOD facilities. For example, officials from a Navy shipyard we visited stated that the catastrophic damage that could result from the flooding of a submarine in dry dock could cause substantial repair costs. In 2017, we found that DOD installations overseas face operational and budgetary risks posed by weather events and climate change effects at the military services\u2019 installations in each of DOD\u2019s geographic combatant commands. We recommended that the Secretaries of the Army, Navy, and Air Force work with the Office of the Secretary of Defense to issue a requirement to their installations to systematically track the costs associated with extreme weather events and climate change effects. DOD did not concur with this recommendation. In its response, DOD stated that tracking impacts and costs associated with extreme weather is important, but that the science of attributing these events to a changing climate is not supported by previous GAO reports. DOD also stated that associating a single event with climate change is difficult and does not warrant the time and money expended in doing so. However, as we stated in our response to DOD\u2019s comments, installations generally have the capability to track the costs associated with extreme weather events, which are projected to become more frequent and intense as a result of climate change. There is substantial budgetary risk resulting from weather effects associated with climate change, and these types of repairs are neither budgeted for nor clearly represented in the federal budget process. As of April 2019, the military departments have not implemented this recommendation. Fifteen of the 23 installations we visited or contacted had integrated some considerations of extreme weather or climate change effects into their plans. For example, Langley Air Force Base, Virginia, partnered with the City of Hampton, Virginia, to study the effects of sea level rise. A 2018 addendum to the installation\u2019s 2010 joint land use study with the City of Hampton outlined climate vulnerabilities and identified recommendations for actions to increase installation resilience. Separately, after sustaining damage from Hurricane Isabel in 2003, the installation required all new development to be constructed to a minimum elevation of 10.5 feet above sea level, higher than the flooding associated with the hurricane and one foot higher than the flooding anticipated from a storm with a 1-in-500 chance of occurring in any given year. As DOD noted in its January 2019 report to Congress on climate-related vulnerabilities, Joint Base Langley-Eustis, of which Langley Air Force Base is a part, has experienced 14 inches in relative sea level rise since 1930, due in part to land subsidence, and has experienced more frequent and severe flooding as a result. The 611th Civil Engineer Squadron, based at Joint Base Elmendorf- Richardson in Alaska, partnered with the University of Alaska, Anchorage, to develop site-specific predictive models of coastal erosion for two radar sites on the North Slope of Alaska. The squadron plans to use this information in the future to develop possible alternative facilities projects to address the erosion risks. Squadron officials told us they consulted with the military users of the radars to determine the length of time to plan for their continued use and that they intend to use this information to develop plans to address this coastal erosion. The North Slope radar sites are experiencing greater than anticipated coastal erosion rates, which have begun to threaten the infrastructure supporting the sites. Fort Irwin, California, in response to severe flash flooding in 2013 that caused loss of power and significant damage to base infrastructure, worked with the U.S. Army Corps of Engineers to develop a plan to improve stormwater drainage. The 2014 plan recommended a series of infrastructure projects, some of which Fort Irwin has implemented; others remain to be implemented, depending on the availability of funding. Figure 2 depicts flooding damage in 2013 at Fort Irwin and a stormwater diversion channel subsequently built by the installation. The flash flooding on the installation caused damage to roads and other facilities throughout the installation, according to officials. The installation subsequently raised berms and built other structures, such as the diversion channel shown in figure 3, to divert stormwater from installation facilities. Marine Corps Recruit Depot Parris Island, South Carolina, reported that the installation plans to award a contract to study sea level rise at the installation and incorporate the results into the next iteration of its master plan. The installation stated that incorporating the study\u2019s results is included in the scope of work for the contract that has been awarded for the master plan update. Naval Station Norfolk, Virginia, noted in its 2017 master plan that climate change and sea level rise are expected to exacerbate effects to the installation from tidal flooding and storm surge, increasing risks to installation assets and capabilities. The plan established a goal of identifying measures that could minimize the effect of sea level rise on the installation. With the majority of the installation near mean sea level, Naval Station Norfolk is vulnerable to frequent flooding that is disruptive to operations. Figure 4 depicts flooding at Naval Station Norfolk. Installation officials told us that such floods can interfere with traffic on base, thus reducing the ability of those working on the installation to transit within, to, and from the base. Naval Base San Diego, California, noted in its most recent master plan that local climate change effects include water and energy shortages, loss of beaches and coastal property, and higher average temperatures, among others. The plan also stated that Naval Base San Diego should be funded to conduct a study to determine installation-specific effects of sea level rise. Navy Region Southwest subsequently partnered with the Port of San Diego to study local effects of sea level rise, which installation officials said will help them understand the effects of sea level rise on the base. Camp Lejeune, North Carolina, participated in a study of the effects of sea level rise on the installation and on certain other DOD installations in North Carolina and Florida. An installation official stated that installation officials have used the results of the study to make planning decisions, in particular by feeding the study data into the installation\u2019s mapping of potential flood zones. The 10-year study, which concluded in 2017, was funded by SERDP and was based at Camp Lejeune to, among other things, understand the effects of climate change at Camp Lejeune. Camp Lejeune officials and one of the scientists involved in the study told us that installation officials have used the study\u2019s results to make decisions about where to site buildings so as to take into account the possible future condition of marshes on the base. However, 8 of the 23 installations we visited or contacted had not integrated considerations of extreme weather or climate change effects into their master plans or related installation planning documents. For example, Joint Base Pearl Harbor Hickam, Hawaii, did not consider extreme weather and climate change effects in its most recent master plan, although it is located in an area that has been subject to tropical storms and where, according to projections in the DOD database of sea level change scenarios, further sea level rise is anticipated. Specifically, under the highest scenario in the database, sea level at Naval Station Pearl Harbor, part of the joint base, could rise more than 3 feet by 2065. The lowest elevation point on the base is 0.6 feet below sea level. The installation stated that it plans to incorporate the effects of climate change into the next update to its facilities master plan. Pearl Harbor Naval Shipyard, Hawaii, did not consider extreme weather or climate change effects in its most recent master plan, although it is co-located with Joint Base Pearl Harbor Hickam and therefore shares the same weather and climate conditions noted previously. Fort Wainwright, Alaska, officials told us they had not considered climate change as part of the installation\u2019s master planning. Officials noted that the majority of the base is on thaw-stable permafrost that would be unlikely to be significantly affected by rising temperatures, but some areas of the base are on less stable permafrost. DOD noted in its January 2019 report to Congress that thawing permafrost can decrease the structural stability of buildings and other infrastructure that is built on it. Camp Pendleton, California, officials told us that although they are aware of a variety of climate-related challenges to their installation and have taken or plan to take some steps to address them, an example of which we discuss later in this report, the installation has not yet considered extreme weather and climate change effects in its master plan. The officials stated that they are still planning based on historical conditions rather than considering possible future conditions. DOD\u2019s Unified Facilities Criteria standard specific to master planning states that where changing external conditions affect planning decisions, master planners should seek to understand, monitor, and adapt to these changes, including changes in climatic conditions such as temperature, rainfall patterns, storm frequency and intensity, and water levels. DOD\u2019s directive on climate change adaptation further states that military departments should integrate climate change considerations into their plans. The directive also states that the Assistant Secretary of Defense for Energy, Installations, and Environment should consider climate change adaptation and resilience in the installation planning process, including the effects of climate change on both built and natural infrastructure. Our findings based on the 23 installations we reviewed for this report are consistent with our prior reports on extreme weather and climate change effects at military installations. Specifically, installations have not consistently integrated these considerations into their master plans or related installation planning documents. In May 2014, we reported that some domestic installations had integrated considerations of changing climatic conditions into their installation planning documents, but DOD had not provided key information\u2014such as how to use climate change projections\u2014to help ensure that efficient and consistent actions would be taken across installations. We recommended that DOD further clarify the planning actions that should be taken in installation master plans to account for climate change, to include further information about changes in applicable building codes and design standards that account for potential climate change effects and further information about potential projected climate change effects on individual installations. However, as of January 2019, DOD had not fully implemented this recommendation. For example, as we discuss later in this report, DOD\u2019s updates to its facilities design standards lacked guidance on the use of climate projections. DOD also had not provided information on a range of potential effects of climate change on individual installations. DOD has taken some positive steps in this area, such as making available to the military services a database of sea level change scenarios for 1,774 DOD sites worldwide. However, DOD has not provided other specific types of climate projections, which we discuss in more depth later in this report. Moreover, in November 2017 we reported that about a third of the installations in our sample of overseas installations had integrated climate change adaptation into their installation plans, but the lack of key guidance and updated design standards to reflect climate change concerns hampered their ability to consistently incorporate climate change adaptation into their plans. We recommended, among other things, that the military departments integrate climate change data and projections into DOD\u2019s facilities criteria and periodically revise those standards based on any new projections, as appropriate. DOD partially concurred, and as of January 2019, an official from the Office of the Assistant Secretary of Defense for Sustainment stated that the office was continuing to work with the military departments to evaluate how to effectively translate the latest climate data into a form usable by installation planners and facilities project designers. Based on our findings for this review, we continue to believe that DOD should take all necessary steps to implement these recommendations. While 15 of the 23 installations we visited or contacted had integrated some consideration of extreme weather or climate change effects into their planning documents, only two of these installations had taken steps to fully assess the weather and climate risks to the installation or develop plans to address identified risks. DOD has taken some broad actions to assess risk to installations from extreme weather and climate change effects. For example, in January 2018, DOD issued a report to Congress on the results of its survey of installations on the extent to which they faced a variety of extreme weather or climate effects. However, the survey responses constituted a preliminary assessment and were based on installations\u2019 reporting of negative effects they had already experienced from extreme weather effects, rather than assessments of all future vulnerabilities based on climate projections. DOD noted that the information in the survey responses is highly qualitative and is best used as an initial indicator of where a more in-depth assessment may be warranted. However, except for two of the installations in our sample, the installations\u2019 master plans and related installation planning documents did not (1) identify a range of possible extreme weather events and climate change effects that could affect the installation, (2) assess the likelihood of each event occurring and the possible effect on the installation, and (3) identify potential responses to these events. For example, Naval Air Station Key West, Florida, included discussion of the effects of sea level rise and storm surge on the installation in its master plan, as well as steps it could take to mitigate these effects. However, although the installation experienced drought conditions rated severe in 2011 and extreme in 2015, its master plan does not discuss effects on the installation of drought, which, according to a DOD report to Congress, can pose significant risks to an installation, including implications for base infrastructure. All of the Air Force installations in our sample rated their degree of vulnerability to a range of climatic conditions\u2014such as flood, temperature rise, and precipitation pattern changes\u2014in their master plans, thereby identifying a range of possible climate events and the likelihood of each event. However, of those installations that identified a range of possible extreme weather and climate change effects that could affect the installation, most did not consistently identify potential responses to these events. The two exceptions\u2014Eglin Air Force Base, Florida, and Joint Base Langley-Eustis, Virginia\u2014took the additional step of identifying possible actions to address these climate events. For example, Eglin Air Force Base rated itself as having a high vulnerability to storm surge, but a low vulnerability from rising temperatures, and identified steps the installation could take in facilities planning and design to mitigate the identified risks. The DOD directive on climate adaptation states that military departments should assess and manage risks to both built and natural infrastructure, including changes as appropriate to installation master planning, and should assess, incorporate, and manage the risks and effects of altered operating environments on capabilities and capacity, including basing. Moreover, Standards for Internal Control in the Federal Government states that management should identify, analyze, and respond to risks related to achieving defined objectives. Risk assessment is the identification and analysis of risks related to achieving defined objectives in order to form a basis for designing responses to these risks. Our prior work has shown that assessing risks includes assessing both the likelihood of an event occurring and the effect the event would have. Agency leaders and subject matter experts should assess each risk by assigning the likelihood of the event\u2019s occurrence and the potential effect if the event occurs. Despite a DOD directive requiring that the military departments assess and manage risks to both built and natural infrastructure, DOD has not required in the Unified Facilities Criteria standard that guides master planning that installations assess risks posed by extreme weather and climate change effects as part of their master plans or develop plans to address identified risks. Officials in the Office of the Assistant Secretary of Defense for Sustainment acknowledged that the Unified Facilities Criteria standard on master planning does not explicitly require a risk assessment specifically for extreme weather or climate change as part of the master planning process. Because installations have not consistently assessed the risks from extreme weather and climate change effects as part of their master plans or identified potential responses to identified risks, they may formulate plans and make planning decisions without consideration of those risks. By assessing and developing actions to address these risks in their master plans, installations could better anticipate exposure of the facilities to greater than anticipated damage or degradation as a result of extreme weather events or climate change effects. Eight of the 23 installations we visited or contacted, as well as the Air Force unit responsible for the North Slope radar facilities, had made some use of climate projections to incorporate consideration of extreme weather and climate change effects into their master plans or related installation planning documents. For example, as noted previously, the 611th Civil Engineer Squadron was developing its own site-specific projections of coastal erosion affecting the North Slope radar sites in Alaska, and Norfolk Naval Shipyard considered local sea level rise projections in a study on mitigating flooding at its docks. However, officials from 11 of the 23 installations in our sample\u2014including some from installations that had made some use of climate projections\u2014cited the need for additional guidance from DOD or their military department headquarters on which projections to use in planning or on how to use them. This is consistent with our prior findings on DOD\u2019s installation-level efforts to increase climate resilience. Our May 2014 report noted that installation officials told us they did not have the installation-level climate data from their military departments or from other DOD sources that they would need to understand the potential effects of climate change on their installations. We recommended, among other things, that DOD provide further direction on planning actions to account for climate change, including information about changes in applicable building codes and design standards and the projected effects of climate change on individual installations. DOD concurred but as of January 2019 had not fully implemented this recommendation, as noted previously. In December 2018, an official in the Office of the Assistant Secretary of Defense for Sustainment stated that DOD plans to develop a policy on the use of sea level rise projections by some time in 2019 and eventually to incorporate these projections into the Unified Facilities Criteria. However, DOD has no current time table for incorporating guidance on the use of other types of climate projections into its Unified Facilities Criteria. The official stated that the department is working toward eventually incorporating the use of other types of climate projections into guidance but that these types of projections would have to be vetted by DOD subject matter experts and approved prior to adoption. DOD intends to move in this direction, according to the official, but DOD has not yet developed a defined process for evaluating and incorporating the use of additional climate projections into guidance. Our prior work has found that using the best available climate information, including forward-looking projections, can help an organization to manage climate-related risks. Until November 2018, DOD\u2019s Unified Facilities Criteria on master planning stated that changes in climate conditions are to be determined from reliable and authorized sources of existing data but that to anticipate conditions during the design life of existing or planned new facilities and infrastructure, installations could also consider climate projections from reliable and authorized sources, such as, among others, the U.S. Global Change Research Office and the National Climate Assessment. In November 2018, in response to a statutory requirement in the John S. McCain National Defense Authorization Act for Fiscal Year 2019, DOD updated the Unified Facilities Criteria on master planning to specify that climate projections from reliable and authorized sources, such the U.S. Global Change Research Office and the National Climate Assessment, shall be considered and incorporated into military construction designs and modifications. DOD guidance states that the Assistant Secretary of Defense for Energy, Installations, and Environment provides guidance and direction on relevant technologies, engineering standards, tools, development and use of scenarios, and other approaches to enable prudent climate change adaptation and resilience. The guidance also states that military departments are to leverage authoritative environmental prediction sources for appropriate data and analysis products to assess the effects of weather and climate. Installations have not consistently used climate projections in their master plans because DOD has not provided detailed guidance on how to do so. Simply updating the language of the Unified Facilities Criteria on master planning in November 2018 to require the use of climate projections does not provide guidance to installations on how to use climate projections, such as what future time periods to consider and how to incorporate projections involving multiple future scenarios, nor does it identify the specific types of projections to use. The absence of guidance has hindered the ability of some installations to effectively apply the best available climate projections to their installation master planning. If they do not use climate projections in their master plans, installations risk failing to plan for changing climate and weather conditions and, as a result, could expose their facilities to greater risk of damage or degradation from extreme weather events and climate change effects. Incorporating such data into planning would help installation master planners better anticipate changing climate and weather conditions and increase the effectiveness of the installation\u2019s long-term investments in its facilities. Eleven of the 23 installations we visited or contacted had designed or constructed one or more individual facilities projects to increase the resilience of the facilities themselves, or to increase the resilience of the installation more broadly, to extreme weather and climate change effects. For example, Joint Base Langley-Eustis, Virginia. In 2018, officials designed a project to build a maintenance hangar with a special foundation that would elevate the floor to 10 feet above the average high-water level at the project site and protect it against coastal storm flooding. Joint Base Langley-Eustis has experienced severe flooding in the past because of its low-lying geographical elevations in the Chesapeake Bay. The installation stated in its draft encroachment management action plan that the effects of climate change may exacerbate flooding issues through sea level rise or the increasing frequency and severity of storms. Norfolk Naval Shipyard, Virginia. In 2018, shipyard officials designed a project to increase the installation\u2019s resilience to storm-induced flooding, including building a floodwall to protect the dry docks that are used to perform maintenance on ships and submarines. Norfolk Naval Shipyard experiences extreme high tides three to five times a year on average and a significant hurricane on average once a year, according to an installation presentation, and flooding has been increasing over time in the area as relative sea levels have risen. The floodwall will enclose the dry docks, providing protection to critical assets and electrical utilities while they are in dry dock, among other things. Figure 5 depicts a flooded dry dock at Norfolk Naval Shipyard, Virginia. Installation officials told us that flooding into dry docks poses risks to the ships being serviced there and to the performance of the base\u2019s mission of servicing and maintaining Navy ships and submarines. Camp Pendleton, California. In 2018, as part of a project to construct a new aircraft landing zone, officials included protection of the nearby coastline, which had been rapidly eroding from the impact of ocean waves and rain storms. According to officials, the erosion has accelerated in recent years and has threatened not only landing zones along the coast, but also beaches that are used for amphibious assault training. Figure 6 depicts coastal erosion near a landing zone at Camp Pendleton, California. According to officials, the erosion leading to the gulley shown in the photograph has accelerated in recent years and advances further inland every year; it is now within feet of the landing zone. The officials told us that the erosion can threaten the function of the landing zone if it reaches that site. Fort Shafter, Hawaii. In 2016, officials constructed flood mitigation structures, including a flood control levee, to protect maintenance facilities being built in a flood zone. At the time, there were no adequate permanent maintenance facilities for units stationed at the base, and the only available land big enough to support the proposed maintenance facilities was located within a flood zone. Despite limited efforts to increase the resilience of facilities to extreme weather and climate change effects, officials from 17 of the military installations in our sample said that their individual facilities project designs generally did not consider climate projections. Of the installations that stated that they considered climate projections in facilities project designs, one military installation said it uses a study on sea level rise at the installation as a tool that incorporates forward-looking projections, and another installation said it uses a NOAA web-based tool, Sea Level Rise Viewer, for graphical representations of projected sea level rise. One installation noted that it had considered sea level rise projections in a pier design, which we discuss further below. A fourth installation said it plans to use a draft Navy study on the vulnerability of coastal Navy installations to sea level rise to inform an upcoming facilities project design. However, another installation said it has used energy consumption projections, which are not climate projections, and another installation cited a Navy climate adaptation handbook, which does not include climate projections for individual Navy installations. Moreover, over the course of our review of 23 installations, we were able to identify only one project as having a design informed by climate projections. Specifically, in 2018, officials from Naval Base San Diego, California, designed a project to demolish and replace an existing pier. The project\u2019s design was informed by the expectation of sea level rise over the 75-year lifespan of the pier. An installation official told us that the consideration of rising sea levels was not part of the original project proposal, but when a contractor provided the sea level rise projections, installation officials decided to raise the pier by one foot. Figure 7 depicts a notional example of a pier\u2014not specific to San Diego or any other particular location\u2014raised to account for sea level rise. The Unified Facilities Criteria on piers and wharves states that the bottom elevation of the deck slab should be kept at least one foot above the extreme high water level. In this notional example, the pier is raised to account for an anticipated one-foot sea level rise, so that the bottom of the deck slab remains one foot above the extreme high water level, as shown in the figure. DOD guidance requires the military departments to assess and manage risks to both built and natural infrastructure, including making changes, as appropriate, to design and construction standards. The guidance also requires the military departments to leverage authoritative environmental prediction sources for appropriate data and analysis products to assess weather and climate effects. However, DOD\u2019s Unified Facilities Criteria pertaining to project design, with the exception of the standard on high performance and sustainable building requirements, do not require consideration of climate projections as part of facilities project designs. The Unified Facilities Criteria standard on high performance and sustainable building requirements requires engineers to provide building design solutions that are responsive to any government-provided projections of climate change and determination of acceptable risk. We analyzed 27 core Unified Facilities Criteria, as well as 3 other Unified Facilities Criteria, Installation Master Planning, Design: Engineering Weather Data, DOD Building Code (General Building Requirements), and one facility criteria standard on Navy and Marine Corps Design Procedures. Our analysis showed that as of March 2019 these criteria, other than the Unified Facilities Criteria standard on installation master planning, do not identify authoritative sources of climate projections for use in facilities project designs. The Unified Facilities Criteria standard on installation master planning states that climate projections from the U.S. Global Change Research Program and the National Climate Assessment as well as the National Academy of Sciences shall be considered and incorporated into military construction designs and modifications. However, an official in the Office of the Assistant Secretary of Defense for Sustainment acknowledged that this requirement in the standard on installation master planning is not sufficient on its own to apply to all facility project designs. Additionally, the standard on installation master planning does not identify the specific types of climate projections to use or how to locate them. Our analysis showed that the Unified Facilities Criteria do not provide guidance on how to incorporate projections into facilities project designs, such as how to use projections involving multiple future scenarios and what future time periods to consider. We found that while some Unified Facilities Criteria direct project designers to climate data, these are historical climate data rather than projections. For example, the following standards do not direct project designers to sources of climate projections: 2015) (change 1, Feb. 1, 2016). This guidance directs project designers to use long-term rainfall records, such as those from regional weather stations, and directs engineers toward a table that provides rainfall data for selected locations. However, information included in the guidance is historical and does not include or refer to projections. Unified Facilities Criteria 3-400-02, Design: Engineering Weather Data (Sept. 20, 2018). This guidance directs project designers toward instructions for accessing climate data for use in designing facilities and in mission planning. However, the guidance does not discuss the use of or specifically reference climate projections. Unified Facilities Criteria 3-201-01, Civil Engineering (Apr. 1, 2018) (change 1, Mar. 19, 2019). This guidance requires project designers to plan for flood hazard areas and, if the project is constructed within the 100-year floodplain, requires that the project design document include flood mitigation measures as part of the project\u2019s scope of work. However, the guidance does not include or reference projections that would help engineers design for various potential flooding scenarios. As previously noted, in response to a statutory requirement, DOD updated its Unified Facilities Criteria on master planning in November 2018 to require installations to consider and incorporate reliable and authorized sources of data on changing environmental conditions. However, simply including this language does not provide guidance to installations on what sources of climate projections to consider and how to use them in designing facilities projects, such as what future time periods to consider and how to incorporate projections involving multiple future scenarios. In addition, the Unified Facilities Criteria standard on master planning provides requirements and guidance for installation master planning but not for the design of individual facilities projects. An official of the Office of the Assistant Secretary of Defense for Sustainment stated that his office plans to develop a policy on the use of sea level rise projections by some time in 2019 and eventually to incorporate guidance on how to use sea level rise projections into the Unified Facilities Criteria or other guidance. This official added that there is currently no defined DOD process for vetting authoritative sources of climate projections, but that DOD plans to continue vetting sources for possible use, as appropriate. Furthermore, officials of 10 of the 23 military installations we reviewed stated that in order to incorporate such projections into project designs, they would need additional guidance from DOD or their military departments identifying authoritative sources of such projections or how to use climate projections that involve multiple future scenarios and different time periods. Ultimately, installations that do not consider climate projections in the design of their facilities projects may be investing in facilities projects without considering potential risks, such as potential future damage and degradation, which are associated with additional costs and reductions in capability. If DOD does not provide guidance on the use of climate projections in facilities designs, including what sources of climate projections to use, how to use projections involving multiple future scenarios, and what future time periods to consider, installation project designers will continue to lack direction on how to use climate projections. Further, if DOD does not update the Unified Facilities Criteria to require installations to consider climate projections in project designs and incorporate the department\u2019s guidance on how to use climate projections in project designs, installation project designers may continue to exclude consideration of climate projections from facilities project designs. Considering climate projections in facilities projects would help DOD to reduce the climate-related risks to its facilities investments. DOD has a global real estate portfolio that supports the department\u2019s global workforce and its readiness to execute its national security missions. The department has repeatedly acknowledged the threats of extreme weather and climate change effects to its installations, and as we have previously reported, has begun taking steps to increase the resilience of its infrastructure to these threats. We found that 15 of the 23 the installations we visited or contacted had considered some type of extreme weather or climate change effects in their plans, a positive step toward increasing resilience to these climate risks. However, not all had done so and most of the installations we visited or contacted did not fully assess the risks associated with extreme weather and climate change effects\u2014including the likelihood of the threat, potential effects on the installation, and possible responses to mitigate such effects. Likewise, many of the installations did not consider climate projections in planning. Without fully assessing the risks of extreme weather and climate change effects, and without considering climate projections as part of the planning process, installations may make planning decisions that do not fully anticipate future climate conditions. By seeking to anticipate future climate conditions, DOD may be able to reduce climate-related risks to its facilities and the corresponding budgetary risks. Eleven of the 23 installations we visited or contacted had designed or implemented one or more construction projects that incorporated resilience to extreme weather or climate change effects. These projects illustrate some of the steps that can be taken to increase an installation\u2019s resilience to climate risks. However, most of the installations had not considered climate projections in project design. Considering climate projections in facilities projects would help DOD to reduce the climate- related risks to its facilities investments. By updating its facilities project design standards to require installations to consider climate projections in project designs, identifying authoritative sources of climate projections, and providing guidance on how to use climate projections, DOD can aid installations to better position themselves to be resilient to the risks of extreme weather and climate change effects. We are making eight recommendations, including two to DOD and two to each of the military departments. Specifically, The Secretary of the Army should ensure that the Chief of Engineers and Commanding General of the U.S. Army Corps of Engineers works with the Assistant Secretary of Defense for Sustainment; the Chief of Civil Engineers and Commander, Naval Facilities Engineering Command; and the Director of the Air Force Civil Engineer Center to update the Unified Facilities Criteria standard on installation master planning to require that master plans include (1) an assessment of the risks from extreme weather and climate change effects that are specific to the installation and (2) plans to address those risks as appropriate. (Recommendation 1) The Secretary of the Navy should ensure that the Chief of Civil Engineers and Commander, Naval Facilities Engineering Command works with the Assistant Secretary of Defense for Sustainment, the Chief of Engineers and Commanding General of the U.S. Army Corps of Engineers, and the Director of the Air Force Civil Engineer Center to update the Unified Facilities Criteria standard on installation master planning to require that master plans include (1) an assessment of the risks from extreme weather and climate change effects that are specific to the installation and (2) plans to address those risks as appropriate. (Recommendation 2) The Secretary of the Air Force should ensure that the Director of the Air Force Civil Engineer Center works with the Assistant Secretary of Defense for Sustainment; the Chief of Engineers and Commanding General of the U.S. Army Corps of Engineers; and the Chief of Civil Engineers and Commander, Naval Facilities Engineering Command to update the Unified Facilities Criteria standard on installation master planning to require that master plans include (1) an assessment of the risks from extreme weather and climate change effects that are specific to the installation and (2) plans to address those risks as appropriate. (Recommendation 3) The Secretary of Defense should issue guidance on incorporating climate projections into installation master planning, including\u2014at a minimum\u2014 what sources of climate projections to use, how to use projections involving multiple future scenarios, and what future time periods to consider. (Recommendation 4) The Secretary of Defense should issue guidance on incorporating climate projections into facilities project designs, including\u2014at a minimum\u2014what sources of climate projections to use, how to use projections involving multiple future scenarios, and what future time periods to consider. (Recommendation 5) The Secretary of the Army should ensure that the Chief of Engineers and Commanding General of the U.S. Army Corps of Engineers works with the Assistant Secretary of Defense for Sustainment; the Chief of Civil Engineers and Commander, Naval Facilities Engineering Command; and the Director of the Air Force Civil Engineer Center to update relevant Unified Facilities Criteria to require that installations consider climate projections in designing facilities projects and incorporate, as appropriate, DOD guidance on the use of climate projections in facilities project designs\u2014including identification of authoritative sources of such projections, use of projections involving multiple future scenarios, and what future time periods to consider. (Recommendation 6) The Secretary of the Navy should ensure that the Chief of Civil Engineers and Commander, Naval Facilities Engineering Command works with the Assistant Secretary of Defense for Sustainment, the Chief of Engineers and Commanding General of the U.S. Army Corps of Engineers, and the Director of the Air Force Civil Engineer Center to update relevant Unified Facilities Criteria to require that installations consider climate projections in designing facilities projects and incorporate, as appropriate, DOD guidance on the use of climate projections in facilities project designs\u2014 including identification of authoritative sources of such projections, use of projections involving multiple future scenarios, and what future time periods to consider. (Recommendation 7) The Secretary of the Air Force should ensure that the Director of the Air Force Civil Engineer Center works with the Assistant Secretary of Defense for Sustainment; the Chief of Engineers and Commanding General of the U.S. Army Corps of Engineers; and the Chief of Civil Engineers and Commander, Naval Facilities Engineering Command to update relevant Unified Facilities Criteria to require that installations consider climate projections in designing facilities projects and incorporate, as appropriate, DOD guidance on the use of climate projections in facilities project designs\u2014including identification of authoritative sources of such projections, use of projections involving multiple future scenarios, and what future time periods to consider. (Recommendation 8) We provided a draft of this report for review and comment to DOD and NOAA. In written comments, DOD concurred with all eight of our recommendations and identified actions it plans to take to address two of them. DOD\u2019s comments are reprinted in their entirety in appendix II. DOD also provided technical comments, which we incorporated as appropriate. NOAA did not provide any comments on the draft. We are sending copies of this report to the appropriate congressional addressees; the Secretary of Defense; the Secretaries of the Departments of the Army, Navy, and Air Force; and the Secretary of Commerce (for NOAA). In addition, this report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact Diana Maurer at (202) 512-9627 or at maurerd@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix III. Senate Report 115-130, accompanying a bill for fiscal year 2018 appropriations for military construction, the Department of Veterans Affairs, and related agencies, cited concerns with the frequency and costs of extreme weather events and the potential effects of climate change, and included a provision for us to review the Department of Defense\u2019s (DOD) progress in developing a means to account for potentially damaging weather in its project designs. In response to this provision, we examined the extent to which DOD has taken steps to incorporate resilience to extreme weather and climate change effects into (1) installation master plans and related planning documents, and (2) individual installation facilities projects. For both of our objectives, we visited or requested information from a sample of domestic military installations. We focused on domestic installations because our November 2017 report focused on foreign installations. To develop this sample, we selected installations in the continental United States, Alaska, Hawaii, and U.S. territories that had identified one or more climate-related vulnerabilities, based on their past experiences, in a DOD-administered survey of climate vulnerabilities, or installations that were referenced in a prior GAO report on weather and climate risks at DOD installations. In addition to these criteria, we selected sites that represented both a diversity in types of climate vulnerabilities and geographic diversity among the military services, as well as installations involved in any climate change-related pilot studies. From these criteria, we developed a non-generalizable sample of 23 installations. We also included in the sample one Air Force unit (not an installation) with responsibilities for particular facilities of interest in Alaska, because these facilities presented a climatic vulnerability (accelerating coastal erosion) that was not necessarily included elsewhere in the sample. We visited 10 of these installations, as well as the Air Force unit in Alaska, in person. Within the sample, we selected installations to visit based on geographic diversity and installations in proximity to each other, allowing us to visit multiple installations on each trip. For the remaining 13 installations, we developed and administered a questionnaire and document request. We received responses from 12 of these installations. One installation\u2014Camp Lejeune\u2014sustained significant damage from Hurricane Florence in September 2018, and to minimize the burden on installation officials\u2019 time to respond, we met with them by phone. Results from our nongeneralizable sample cannot be used to make inferences about all DOD locations. However, the information from these installations provides valuable insights. We asked similar questions to installations on our site visits and in the questionnaires, and we collected similar documents\u2014such as installation master plans and individual facilities project documents\u2014 allowing us to report on similar information, such as the extent to which extreme weather and climate change considerations were integrated into installation master plans and individual facilities projects. For objective one, we reviewed DOD policies, guidance, and standards related to increasing climate resilience and conducting installation master planning. These documents included, among others, DOD Directive 4715.21, which establishes policy and assigns responsibilities for DOD to assess and manage risks associated with climate change; DOD\u2019s Unified Facilities Criteria standard on installation master planning, which establishes the requirements for installation master plans; and a memorandum from the Office of the Under Secretary of Defense for Acquisition, Technology and Logistics on floodplain management on DOD installations. We interviewed officials in the Office of the Assistant Secretary of Defense for Sustainment and the Strategic Environmental Research and Development Program. We also interviewed officials in each of the military departments, including officials involved with installation policy, as well as officials from the engineering organizations of each military department and officials in the National Oceanic and Atmospheric Administration to discuss climate science and the data potentially available for planners to use. We reviewed documents from each of the 23 installations and the one Air Force unit in our sample, including master plans, and used interviews with installation officials and questionnaires received from installations to determine the extent to which the installations had incorporated consideration of extreme weather and climate change effects into their installation plans. We compared DOD\u2019s actions to take steps in installation planning to increase resilience to extreme weather and climate change effects with DOD guidance on climate change adaptation and resilience, Unified Facilities Criteria standards, federal internal control standards, and best practices for enterprise risk management. For objective two, we reviewed DOD guidance, including DOD Directive 4715.21, requiring DOD components to integrate climate change considerations into DOD plans. We also reviewed DOD\u2019s facilities project design standards\u2014the Unified Facilities Criteria\u2014to determine the extent to which installations incorporated requirements for climate resilience and to identify any required or recommended climate data sources for facilities project design. Specifically, we reviewed the 27 core Unified Facilities Criteria standards, as well as 3 other Unified Facilities Criteria standards outside of the core 27\u2014because of their broad relevance to project design\u2014and one facility criteria on Navy and Marine Corps design procedures. Additionally, we performed a content analysis of these criteria for references to climate, weather, environment, and any climate data to be used as a basis for facilities design. We also identified any required or recommended climate data sources or tools for facilities design by searching for references, web links, or tables related to climate data within the criteria. Where climate data sources were identified, we reviewed them to determine the extent to which the sources and tools involved historical data or climate projections that anticipate future climate conditions. We interviewed officials from the U.S. Army Corps of Engineers, Naval Facilities Engineering Command, and the Air Force Civil Engineer Center to understand the extent to which the Unified Facilities Criteria include guidance or data sources for adapting DOD facilities to extreme weather and climate change effects. In addition, we used interviews with installation officials and questionnaires we received from installations to determine the extent to which the installations had planned or executed any military construction or sustainment, restoration, and modernization facilities projects since 2013 that included any elements for building resilience to extreme weather or climate change effects. We then reviewed project documentation for proposed or approved facilities projects to identify the resilience measures taken. We also observed some facilities-related climate resilience measures adopted by these installations. In addition, we interviewed officials from the Office of the Assistant Secretary of Defense for Sustainment to determine what plans, if any, the office had to update Unified Facilities Criteria with climate resilience requirements. We also interviewed officials from the Office of the Assistant Secretary of the Army for Installations, Energy and Environment; the Office of the Assistant Secretary of the Navy for Energy, Installations and Environment; and the Office of the Assistant Secretary of the Air Force, Installations, Environment and Energy to identify any actions, policies, or processes related to adapting facilities to extreme weather and climate change effects. Moreover, we interviewed officials from the American Society of Civil Engineers to understand what efforts, if any, had been made to incorporate climate projections into industry standards. Finally, we compared the extent to which DOD took steps in its facilities projects and its project design standards to increase resilience with DOD guidance on climate change resilience. Table 3 lists the locations we visited or contacted during this review, including the installations receiving our questionnaire. Diana Maurer at (202) 512-9627 or maurerd@gao.gov. In addition to the contact named above, Brian J. Lepore (Director, retired), Kristy Williams (Assistant Director), Michael Armes, Kendall Childers, Simon Hirschfeld, Joanne Landesman, Amie Lesser, Grace Meany, Shahrzad Nikoo, Samantha Piercy, Monica Savoy, Benjamin Sclafani, Joseph Dean Thompson, and Jack Wang made key contributions to this report. High-Risk Series: Substantial Efforts Needed to Achieve Greater Progress on High-Risk Areas, GAO-19-157SP. Washington, D.C.: March 6, 2019. Climate Change: Analysis of Reported Federal Funding. GAO-18-223. Washington, D.C.: April 30, 2018. Climate Change Adaptation: DOD Needs to Better Incorporate Adaptation into Planning and Collaboration at Overseas Installations. GAO-18-206. Washington, D.C.: November 13, 2017. Climate Change: Information on Potential Economic Effects Could Help Guide Federal Efforts to Reduce Fiscal Exposure. GAO-17-720. Washington, D.C.: September 28, 2017. High-Risk Series: Progress on Many High-Risk Areas, While Substantial Efforts Needed on Others. GAO-17-317. Washington, D.C.: February 15, 2017. Climate Change: Improved Federal Coordination Could Facilitate Use of Forward-Looking Climate Information in Design Standards, Building Codes, and Certifications. GAO-17-3. Washington, D.C.: November 30, 2016. Defense Infrastructure: DOD Efforts to Prevent and Mitigate Encroachment at Its Installations. GAO-17-86. Washington, D.C.: November 14, 2016. Climate Information: A National System Could Help Federal, State, Local, and Private Sector Decision Makers Use Climate Information. GAO-16-37. Washington, D.C.: November 23, 2015. High-Risk Series: An Update. GAO-15-290. Washington, D.C.: February 11, 2015. Budget Issues: Opportunities to Reduce Federal Fiscal Exposures Through Greater Resilience to Climate Change and Extreme Weather. GAO-14-504T. Washington, D.C.: July 29, 2014. Climate Change Adaptation: DOD Can Improve Infrastructure Planning and Processes to Better Account for Potential Impacts. GAO-14-446. Washington, D.C.: May 30, 2014. Extreme Weather Events: Limiting Federal Fiscal Exposure and Increasing the Nation\u2019s Resilience. GAO-14-364T. Washington, D.C.: February 12, 2014. Climate Change: Energy Infrastructure Risks and Adaptation Efforts. GAO-14-74. Washington, D.C.: January 31, 2014. Climate Change: Federal Efforts Under Way to Assess Water Infrastructure Vulnerabilities and Address Adaptation Challenges. GAO-14-23. Washington, D.C.: November 14, 2013. Climate Change: State Should Further Improve Its Reporting on Financial Support to Developing Countries to Meet Future Requirements and Guidelines. GAO-13-829. Washington, D.C.: September 19, 2013. Climate Change: Various Adaptation Efforts Are Under Way at Key Natural Resource Management Agencies. GAO-13-253. Washington, D.C.: May 31, 2013. Climate Change: Future Federal Adaptation Efforts Could Better Support Local Infrastructure Decision Makers. GAO-13-242. Washington, D.C.: April 12, 2013. High-Risk Series: An Update. GAO-13-283. Washington, D.C.: February 14, 2013. International Climate Change Assessments: Federal Agencies Should Improve Reporting and Oversight of U.S. Funding. GAO-12-43. Washington, D.C.: November 17, 2011. Climate Change Adaptation: Federal Efforts to Provide Information Could Help Government Decision Making. GAO-12-238T. Washington, D.C.: November 16, 2011.", "summary": "DOD manages a global real-estate portfolio with an almost $1.2 trillion estimated replacement value. Since 2010, DOD has identified climate change as a threat to its operations and installations. In January 2019, DOD stated that the effects of a changing climate are a national security issue with potential impacts to the department's missions, operational plans, and installations. GAO was asked to assess DOD's progress in developing a means to account for potentially damaging weather in its facilities project designs. GAO examined the extent to which DOD has taken steps to incorporate resilience to extreme weather and climate change effects into (1) selected installation master plans and related planning documents, and (2) selected individual installation facilities projects. GAO reviewed DOD documents related to increasing climate resilience, conducting installation master planning, and designing facilities projects. GAO visited or contacted a non-generalizable sample of 23 installations that had been associated with one or more climate vulnerabilities. Department of Defense (DOD) installations have not consistently assessed risks from extreme weather and climate change effects or consistently used projections to anticipate future climate conditions. For example, DOD's 2018 preliminary assessment of extreme weather and climate effects at installations was based on the installations' reported past experiences with extreme weather rather than an analysis of future vulnerabilities based on climate projections. Fifteen of the 23 installations GAO visited or contacted had considered some extreme weather and climate change effects in their plans as required by DOD guidance, but 8 had not. For example, Fort Irwin, California, worked with the U.S. Army Corps of Engineers to improve stormwater drainage after intense flash flooding caused significant damage to base infrastructure. By contrast, Joint Base Pearl Harbor-Hickam, Hawaii, did not include such considerations in its plans, although it is located in an area subject to tropical storms and where further sea level rise is anticipated. GAO also found that most of the installations had not used climate projections, because they lack guidance on how to incorporate projections into their master plans. Not assessing risks or using climate projections in installation planning may expose DOD facilities to greater-than-anticipated damage or degradation as a result of extreme weather or climate-related effects. Eleven of the 23 installations we reviewed had designed one or more individual facilities projects to increase the resilience of the facilities to extreme weather and climate change effects. However, project designs generally did not consider climate projections, according to installation officials. These officials told us that DOD lacks guidance on how to use climate projections that involve multiple future scenarios and different time periods. Until DOD updates its facilities design standards to require installations to consider climate projections in project designs, identify authoritative sources for them to use, and provide guidance on how to use projections, installation project designers may continue to exclude consideration of climate projections from facilities project designs, potentially making investments that are planned without consideration of climate-related risks. GAO is making eight recommendations, including that the military departments work together to update master planning criteria to require an assessment of extreme weather and climate change risks and to incorporate DOD guidance on the use of climate projections into facilities design standards. GAO also recommends that DOD issue guidance on incorporating climate projections into installation master planning and facilities project designs. DOD concurred with all eight of GAO's recommendations."}
{"id": "govreport_3", "report": "Nursing homes are required to keep residents safe from harm, but when abuse is alleged, a combination of federal, state, and local agencies\u2014as well as the nursing homes themselves\u2014play a role in investigating. Federal laws establish minimum requirements nursing homes must meet to participate in the Medicare and Medicaid programs, including standards for the quality of care. These standards cover a variety of categories, such as resident rights, quality of care, and quality of life. In 2016, CMS finalized a comprehensive update to its nursing home standards to reflect new requirements and align requirements with current clinical practices, among other things. The changes were implemented in three phases, starting November 28, 2016. The federal government and the states share oversight responsibility for the nation\u2019s nursing homes, with specific activities occurring at the national, regional, and state levels. CMS central office. At the national level, the CMS central office oversees the federal standards nursing homes must meet to participate in the Medicare and Medicaid programs. Primarily through its State Operations Manual, the office establishes the responsibilities of CMS\u2019s regional offices and state survey agencies in ensuring that federal quality standards for nursing homes are met. CMS regional offices. CMS\u2019s 10 regional offices oversee state activities and report back to the CMS central office the results of their efforts. Specifically, regional offices use the State Performance Standards System to evaluate state surveyors\u2019 performance on factors such as the frequency and quality of state surveys. State survey agencies. Under agreement with CMS, a state survey agency in each state assesses whether nursing homes meet CMS\u2019s standards, allowing them to participate in the Medicare and Medicaid programs. State survey agencies assess nursing homes using (1) recurring standard surveys and (2) as-needed investigations. Standard surveys. State survey agencies are required by federal law to perform unannounced, on-site standard surveys of every nursing home receiving Medicare or Medicaid payment at least every 15 months, with a statewide average frequency of every 12 months. These surveys are a comprehensive assessment designed to determine whether nursing homes are complying with Medicare and Medicaid quality standards. Investigations. In addition to standard surveys, state survey agencies are required by federal law to investigate (1) complaints submitted by residents, family members, friends, physicians, and nursing home staff; and (2) \u201cfacility-reported incidents,\u201d including incidents involving abuse of residents, that are self-reported by the nursing homes. State survey agencies review the information provided through these complaints and incidents and determine if an on-site investigation is required. During this unannounced investigation, the state surveyors assess available evidence to determine whether the allegation can be substantiated. These investigations offer the state survey agency the opportunity to identify and correct care problems in a more timely manner than through the standard surveys. If a surveyor determines that a nursing home violated a federal standard during a survey or investigation, then a deficiency code specific to that standard is cited. For instance, one deficiency code for abuse of residents encompasses mental/verbal, sexual, or physical abuse; while a few additional deficiency codes encompass abuse-related issues, such as a failure by the nursing home to train staff on issues related to abuse. Cited deficiencies are then classified into categories according to scope (the number of residents potentially affected) and severity (the potential for or occurrence of harm to residents). (See table 1.) State survey agencies are required to enter data about deficiencies into CMS\u2019s survey database. For most deficiencies, the nursing home is required to prepare a plan of correction, and, depending on the scope and severity of the deficiency, surveyors may re-visit the facility to ensure that the nursing home has implemented its plan and corrected the deficiency. In any instances where surveyors substantiate the occurrence of resident abuse, the state survey agency is required to refer the case to three entities: 1) local law enforcement; 2) the MFCU, if appropriate; and 3) the state\u2019s nurse aide registry or other applicable professional licensure authority. When nursing homes are cited with deficiencies, federal enforcement actions\u2014or penalties\u2014can be imposed to encourage homes to make corrections. In general, enforcement actions: (1) may be initially recommended by the state survey agency, (2) are transferred to the CMS regional office for review, (3) are imposed by the same CMS regional office, and (4) are implemented\u2014that is, put into effect. Depending on the scope and severity of the deficiency cited, the CMS regional office may impose certain enforcement actions so that they are implemented immediately. However, for other enforcement actions, the regional office may provide the nursing home with an opportunity to correct the deficiencies, which, if corrected before the scheduled effective date, can result in the penalty not being implemented. Penalties include directed in- service training, fines known as civil money penalties, denial of payment, and termination from the Medicare and Medicaid programs, among others. (See fig. 1.) When a nursing home becomes aware of an incident of alleged resident abuse, the home must: immediately report the allegation to the state survey agency and then conduct an investigation of the alleged incident. Specifically, the process is as follows: The nursing home must immediately report alleged abuse to the state survey agency. After notifying the state survey agency, the nursing home is also required to conduct its own investigation and submit its findings in a written report to the state survey agency within 5 working days of the incident. Depending on the severity of the circumstances, the state survey agency may visit the nursing home to investigate the incident or wait until the nursing home submits its report. Depending on the content of the report, the state survey agency may request the home conduct additional work or the state survey agency may investigate further on its own. If the state survey agency opts not to investigate further, it may still review the manner in which the home conducted its investigation during the state survey agency\u2019s next scheduled standard survey. If a state survey agency determines that a nurse aide is responsible for abuse, the agency must add this finding to the state\u2019s nurse aide registry\u2014a registry that each state is required to maintain that lists all individuals who have satisfactorily completed approved nurse aide training and a competency evaluation program in that state. Nursing homes are prohibited from employing a nurse aide with a finding of abuse on the nurse aide registry. Further, if there is a reasonable suspicion that a crime has occurred that results in serious bodily injury, federal law requires certain covered individuals at the nursing home to immediately report to law enforcement in addition to the state survey agency. Before employing a nurse aide, nursing homes are required to check each relevant state\u2019s registry to verify that the nurse aide has passed a competency evaluation. All nursing homes must also verify with the relevant state board of licensing the professional credentials of the licensed personnel, such as registered nurses, whom they hire. In addition to state survey agencies, there are other state and local agencies that may be involved in investigating abuse in nursing homes. These other state and local agencies that investigate abuse in nursing homes are generally focused on the different aspects of the specific alleged abuse incident, in contrast to the state survey agency, which focuses on the safety of individual residents, as well as on the facility\u2019s policies and procedures for preventing and effectively addressing abuse. These other state and local agencies include: Adult Protective Services. In some states, Adult Protective Services\u2019 investigators are trained to provide protection and intervention for older adults in nursing homes and can play a valuable role in helping to protect residents from abuse. Ombudsmen. Long-term care ombudsmen, who serve as advocates for nursing home residents, may also investigate abuse complaints made by or on behalf of residents. Local law enforcement. Law enforcement may also play a role in investigating alleged nursing home resident abuse. Specifically, local police departments may learn of suspected instances of resident abuse and conduct criminal investigations. MFCU. The state MFCUs typically learn of abuse allegations through referrals from state survey agencies, which CMS requires if abuse is substantiated. If, after investigating an allegation, the MFCU decides that there is sufficient evidence to press criminal charges, it may prosecute the case itself or refer the matter to the state\u2019s attorney general or a local prosecutor. Our analysis of CMS data found that from 2013 through 2017, abuse deficiencies cited in nursing homes became more frequent, with the largest increase in severe cases. While abuse deficiencies are relatively rare\u2014they comprise less than 1 percent of the total deficiencies in each of the years we examined\u2014they became more common over the 5-year period. Specifically, the number of abuse deficiencies cited more than doubled\u2014from 430 in 2013 to 875 in 2017 (a 103.5 percent increase). This trend for the abuse deficiencies is in contrast to the trend for all deficiencies, which decreased about 1 percent between 2013 and 2017. At the state level, 32 states had more abuse deficiencies cited in 2017 than 2013, six states had a consistent number, and the remaining 13 had fewer. (See app. III for additional data on abuse deficiencies by state.) Furthermore, abuse deficiencies cited in 2017 were more likely to be categorized at the highest levels of severity\u2014deficiencies causing actual harm to residents or putting residents in immediate jeopardy\u2014than they were in 2013. Specifically, 42.6 percent of the 875 abuse deficiencies were categorized as causing actual harm or posing immediate jeopardy to residents in 2017, compared to 31.9 percent of the 430 abuse deficiencies in 2013. (See fig. 2.) In examining the types of survey or investigations conducted to identify abuse deficiencies, we found that, from 2013 to 2017, the majority (about two-thirds in each year) were identified through either a complaint investigation or facility-reported incident investigation. In contrast, for all types of deficiencies, we found the inverse\u2014the vast majority were identified through a standard survey. This demonstrates the unique and significant role that complaint and facility-reported incident investigations have in identifying abuse deficiencies, because they allow for the identification and correction of abuse in a more timely manner than a standard survey. In fact, for the deficiencies for which we were able to identify the source, the percentage of abuse deficiencies identified through facility-reported incident investigations increased from 42.3 percent of the 430 abuse deficiencies in 2013 to 47.4 percent of the 875 abuse deficiencies in 2017. Conversely, for all types of deficiencies, a very small percentage resulted from facility-reported incident investigations\u2014about 5 percent or less each year. (See fig. 3.) We found that enforcement actions\u2014or penalties\u2014were imposed and implemented by CMS infrequently each year in response to abuse deficiencies, and that fines were the most common type of implemented penalty. Specifically, for each year from 2013 through 2017, we found that about one-third of abuse deficiencies had an enforcement action imposed but not implemented, and less than 8 percent of abuse deficiencies had enforcement actions that were implemented against the nursing home. This was fairly consistent over the 5-year period. For example, in 2017, of the 875 abuse deficiencies cited, 275 (31.4 percent) resulted in enforcement actions that were imposed but not implemented and 65 (7.4 percent) had enforcement actions that were implemented against the nursing home. Furthermore, for abuse deficiencies cited at the most severe levels\u2014that is, those causing actual harm or immediate jeopardy to residents\u2014a smaller percentage of the deficiencies had an enforcement action imposed but not implemented compared to all abuse deficiencies, but a larger percentage were implemented. For example, in 2017, 373 of the 875 abuse deficiencies were cited at the most severe levels; of those, 81 (21.7 percent) resulted in enforcement actions that were imposed but not implemented, and 51 (13.7 percent) were implemented against the nursing home. Regardless of the severity, the predominant reason that CMS did not implement imposed enforcement actions was because the nursing home came into compliance prior to the implementation date of the penalty. For implemented enforcement actions, fines\u2014known as civil money penalties\u2014were overwhelmingly the most common type of penalty implemented against nursing homes with abuse deficiencies, increasing from 69.6 percent of the 23 abuse deficiencies with implemented enforcement actions in 2013 to 83.1 percent of the 65 in 2017. Denial of payments for new Medicare and Medicaid admissions\u2014another financial penalty\u2014was the second most common type of implemented enforcement action, but decreased from 34.8 percent in 2013 to 13.8 percent in 2017. Mandatory termination is the most severe enforcement action as it ends all payments for Medicare and Medicaid residents; it is implemented very rarely, with only one abuse deficiency resulting in mandatory termination of the nursing home across all 5 years. (See fig. 4.) In addition, we found the number of nursing homes with abuse deficiencies also more than doubled over the 5-year period. In 2013, 394 nursing homes (2.7 percent of all surveyed nursing homes) had at least one abuse deficiency compared to 821 nursing homes (5.6 percent of all surveyed nursing homes) in 2017. A nursing home may have more than one abuse deficiency cited in a single year, such as from a standard survey early in the year and then a complaint investigation later in the year. We found that in 2013, of the 394 nursing homes that had a total of 430 abuse deficiencies cited, 85 of the homes had two or more abuse deficiencies that year. In 2017, of the 821 nursing homes that had 875 total abuse deficiencies cited, 155 had two or more that year. Further, across the 5-year period, we found that a small proportion of all nursing homes with abuse deficiencies had them in multiple consecutive years. Specifically, across all years, 2,214 total unique nursing homes (13.6 percent of all surveyed nursing homes) had at least one abuse deficiency. A small portion of these nursing homes had at least one abuse deficiency in multiple consecutive years, indicating potential patterns in abuse at these nursing homes. Specifically, 185 of the 2,214 nursing homes with abuse deficiencies over the 5-year period\u20148.4 percent\u2014had an abuse deficiency in any 2 consecutive years. In addition, 25 of the nursing homes\u20141.1 percent\u2014had an abuse deficiency in 3 or more consecutive years. (See fig. 5.) Finally, we analyzed a selection of characteristics, including ownership type and bed size, for these nursing homes that had abuse deficiencies cited in multiple years and compared them to homes that had abuse deficiencies cited in a single year and surveyed homes that did not have any abuse deficiencies. We found that the nursing homes differed. For example, while for-profit organizations\u2014the largest ownership group accounting for 67.9 percent of all surveyed nursing homes\u2014owned 66.9 percent of nursing homes without any abuse deficiencies cited over the 5- year period, they accounted for 78.6 percent of nursing homes that had abuse deficiencies cited in 2 or more years. In addition, nursing homes designated as Special Focus Facilities\u2014a CMS program that provides increased oversight to homes with consistent poor performance\u2014 constituted 2.5 percent of all surveyed nursing homes compared to 1.9 percent of nursing homes without abuse deficiencies and 10.1 percent of nursing homes with abuse deficiencies cited in 2 or more years. (See table 2.) Our analysis of a representative sample of CMS narrative descriptions\u2014 written by state surveyors\u2014associated with abuse deficiencies cited in 2016 and 2017 found that physical and mental/verbal abuse occurred most often in nursing homes, followed by sexual abuse. Further, staff were more often the perpetrators of the deficiencies cited as abuse than were residents or others. (See fig. 6.) Physical abuse, which CMS defines as hitting, slapping, punching, biting and kicking residents, was present in about 46 percent (+/- 5 percent) of the abuse deficiency narratives. Mental/verbal abuse, which CMS defines as verbal or nonverbal conduct that can cause a resident to experience humiliation and fear, among other things, was present in about 44 percent (+/- 5 percent) of the abuse deficiency narratives. Sexual abuse, which CMS defines as non-consensual sexual contact with a resident, was present in about 18 percent (+/- 5 percent) of the abuse deficiency narratives. Staff, which includes those working in any part of the nursing home, were perpetrators in 58 percent (+/- 5 percent) of abuse deficiency narratives, followed by resident perpetrators (30 percent +/- 5 percent) and other types of perpetrators (2 percent +/- 5 percent). Other types of perpetrators can include family members of residents or other visitors. Further, our analysis of the narratives found that sexual abuse perpetrated by residents (39 percent) occurred more frequently within our sample than sexual abuse perpetrated by staff (10 percent) or others (17 percent). When staff were the perpetrators of abuse, we found within our sample that mental/verbal abuse was the most common type of abuse (60 percent), while physical abuse was most common in situations where residents (59 percent) or others (67 percent) were the perpetrators. For examples of the different types of abuse and perpetrators from our analysis, see table 3 below. Within our sample of narratives, mental/verbal abuse was less likely to be categorized by surveyors as severe compared to physical and sexual abuse. Specifically, we found in our sample that the proportion of mental/verbal abuse (30 percent) categorized by state surveyors as severe\u2014defined as actual harm or immediate jeopardy\u2014was smaller than the proportion of physical (40 percent) and sexual abuse (58 percent) categorized as severe. In addition, we found that most of the mental/verbal (88 percent), physical (91 percent), and sexual abuse (77 percent) narratives in our sample were categorized by surveyors as \u201cisolated\u201d in scope. Stakeholder groups in most of the five states we interviewed\u2014including state survey agencies, Adult Protective Services, law enforcement, MFCUs, ombudsmen, and nursing home administrators and clinical staff\u2014identified risk factors for abuse in nursing homes that included resident characteristics, such as residents with infrequent visitors, and nursing home staffing characteristics, such as insufficient staffing levels. (See table 4 for a description of these risk factors.) Officials we interviewed from national organizations with knowledge of abuse in nursing homes also noted some of these same risk factors. Resident characteristics. Stakeholders in each of our five selected states noted that residents who do not have frequent visitors, are cognitively impaired, or mixed with widely different age groups may be at an increased risk for abuse. Residents who do not have frequent visitors. Stakeholders in four of the five states said that residents without regular visitors, such as family, may be at an increased risk for abuse because regular visitors could notice and report potential warning signs of abuse, such as changes in their behavior or physical appearance. Residents who are cognitively impaired. Stakeholders in each of the five states said that cognitively impaired residents may be especially vulnerable to abuse because they often cannot speak or may have difficulty recalling recent events, and they are therefore less likely to be able to remember or describe what happened. In addition to noting that cognitively impaired residents may be at an increased risk of abuse, some stakeholders said that some cognitively impaired residents may be more likely to be perpetrators of abuse as their condition can have behavioral symptoms, such as physical aggressiveness. Residents mixed with widely different age groups. Stakeholders in four of the five states also noted that elderly nursing home residents who are mixed with widely differing age groups, such as young adults with mental illness, may be at a higher risk for incidents of abuse due to the different characteristics of these groups. Combining these two populations, which have differing needs, can also be challenging for staff. For example, staff may have more experience caring for elderly residents with complex needs, such as dementia, and they may not have the necessary skills or training to care for needs of younger residents, who require other types of complex care. This can create a stressful environment for staff, which is a risk factor for staff as potential perpetrators of abuse. Two stakeholders noted that younger residents who may have mental illness can have conflicts with older and frailer residents, potentially leading to abusive incidents between residents. Nursing home staffing characteristics. Stakeholders we interviewed in each of our five selected states noted that nursing homes with insufficient staffing, inadequate staff training, and inadequate staff screening may be at risk for abuse. Nursing homes with insufficient staff. Stakeholders in each of the five states said that nursing homes with insufficient staff may be at risk for abuse because there may not be enough staff attending to the needs of residents. Stakeholders noted that nursing homes have faced challenges hiring and retaining qualified staff and that, as a result, existing staff can feel overworked, stressed, or exhausted, which can lead to abusive behaviors. Staffing issues are not just risk factors for staff as perpetrators of abuse, but they can also limit a staff member\u2019s ability to identify and report abuse. For example, insufficient staffing may mean that there are not enough available staff to notice signs of abuse in a timely fashion, such as noticing a resident\u2019s bruises before they heal. Nursing homes with inadequate staff training on abuse. Inadequate staff training on abuse was noted by stakeholders we interviewed in four of the five states as a risk factor for abuse because; for example, staff may not know how to diffuse challenging situations with residents and identify and report abuse. As previously noted, recognizing abuse can be challenging and, even when abuse is identified, it is often not reported. Officials from all of the nursing homes that we visited said that they provide training to their staff on abuse, including on defining abuse, identifying or detecting different types of abuse, and reporting abuse. Staff members we spoke with at one nursing home said that, not only are they trained to look for physical signs of abuse, such as bruising, but they are also trained to observe changes in behavior that may be warning signs for abuse, such as a resident suddenly withdrawing from group activities. Staff at another nursing home said that they are also taught to ask another staff member for assistance when they are feeling frustrated or stressed by caring for a particular resident. In contrast, staff at another nursing home noted the challenges of not having these types of resources and said they are needed at their facility. Nursing homes with inadequate staff screening. Stakeholders in three of our five states said that inadequate staff screening can be a risk factor for abuse. Some stakeholders said that a thorough background screening can be time consuming. Further, because staff screening through background checks and the nurse aide registry is not coordinated across the country, there are gaps that could enable individuals who committed crimes in one state to obtain employment at a nursing home in another state, a concern that we previously reported. Staff from a nursing home we visited said the prevention of abuse \u201cstarts with hiring the right staff\u201d and noted the importance of conducting background checks and checking references for prospective employees. The key challenges for abuse investigations most frequently identified by stakeholder groups in the five states we reviewed were underreporting of abuse, cognitive impairment of victims, lack of cooperation from nursing homes, and lack of agency coordination. (See table 5 for a description of these challenges.) Officials we interviewed from national organizations with knowledge of abuse in nursing homes also noted some of these same challenges. Underreporting of abuse. Stakeholders in each of the five states in our review noted that abuse in nursing homes may be underreported because residents or their families feel uncomfortable or fear retaliation from nursing home staff. For example, residents who were sexually abused may feel ashamed or embarrassed to report these incidents. In addition, residents may fear retaliation by the nursing home staff on whom they depend, which might include substandard care, exclusion from activities, or even eviction from the home. A fear of retaliation can also extend to nursing home staff, who may witness abuse by another staff member, but may be afraid to report it out of fear that they will lose their jobs or that they will face retaliation from co-workers. This underreporting creates challenges for investigators, who are unable to investigate if they do not know that abuse has occurred. Cognitive impairment of victims. Stakeholders in each of the five states in our review said that victims with cognitive impairment may not be able to give statements regarding the abuse or may not be considered reliable witnesses. For example, residents with dementia may not be able to remember the details of an abusive incident, and their memory of the details may deteriorate over the course of an investigation. Or, residents with dementia may report abuse that stems from traumatic memories from an incident that occurred earlier in their lives. One stakeholder said this can be a challenge for investigations because they do not know how much they can rely on a cognitively impaired resident\u2019s statement, making it difficult for them to corroborate an abuse allegation. However, one stakeholder noted that, while it can be difficult to interview abuse victims with cognitive impairment, it is important to treat their allegations seriously and with credibility. One law enforcement stakeholder noted that interviews with these victims require special training. Lack of cooperation from some nursing homes. Stakeholders in each of the five states in our review said that some nursing homes may withhold, alter, or make it difficult for investigatory agencies to gain access to necessary, timely, or accurate information about alleged abuse. This may be, for example, because they may fear adverse publicity, litigation, or penalties from the state or CMS. In addition, as noted previously, nursing home staff may be fearful of losing their jobs. Stakeholders said that nursing home staff who witnessed abuse may be intentionally vague when interviewed by investigators; for example, by saying they cannot recall an incident. Some stakeholders also noted that nursing homes may delay investigators\u2019 access to patient records, or they may even alter patient records in order to fill in information that should have been documented but was not at the time of the incident. One stakeholder we interviewed noted that the problem is not necessarily widespread\u2014that some nursing homes are open about sharing information while others can be more difficult. Another stakeholder noted that a nursing home\u2019s cooperation can sometimes depend on the seriousness of the allegation. Lack of agency coordination. Stakeholders in three of the five states in our review said that having multiple agencies involved in investigations, such as the state survey agency, law enforcement, the ombudsman, and, in some states, Adult Protective Services, can create challenges, including coordinating investigations and notifying one another about investigation outcomes. One stakeholder said they sometimes begin an investigation without realizing another investigatory agency has already started its own investigation. Further, stakeholders in two of the five states in our review said that CMS does not allow state survey agencies to share important investigatory information with law enforcement. (We discuss this issue in more detail later in this report.) We found that CMS: (1) cannot readily access data on the type of abuse or type of perpetrator, (2) has not provided guidance on what information nursing homes should include in facility-reported incidents, and (3) has numerous gaps in its referral process that can result in delayed and missed referrals to other entities. Together, these gaps affect critical points in CMS\u2019s oversight of abuse in nursing homes including the prevention, identification, and timely investigation of abuse. CMS cannot readily access information on abuse or perpetrator type in its datasets and, as a result, lacks key information critical to understanding and appropriately addressing nursing home abuse with its oversight. Specifically, in two of CMS\u2019s datasets\u2014complaints/facility-reported incidents and deficiencies\u2014agency officials told us they do not require the state survey agencies to record abuse and perpetrator type. As a result, we found that CMS\u2019s data do not readily support CMS\u2019s understanding of the types of abuse and perpetrators that are most prevalent in nursing homes. CMS officials told us they believe that the majority of abuse is committed by nursing home residents, and that physical and sexual abuse were the most common types; officials said they based this current understanding of abuse and perpetrator types on professional experience, literature, and ad hoc analyses of deficiency narrative descriptions. However, our review of a representative sample of abuse deficiency narratives from 2016 and 2017 found that staff were more often the perpetrators of deficiencies cited as abuse than residents or others, and that physical and mental/verbal abuse occurred most often in nursing homes, followed by sexual abuse. CMS officials noted that some incidents resulting from resident altercations\u2014particularly those that do not show a willful intent to harm\u2014may not have been cited as an abuse deficiency by some state survey agencies and may have been cited as other deficiencies not specified as abuse. This may have contributed to the difference between CMS\u2019s understanding of the prevalence of resident to resident abuse and what their abuse deficiency data show. If CMS required information on abuse and perpetrator type to be recorded, the agency would have a better understanding of abuse in nursing homes. However, CMS officials told us they do not currently require the state survey agencies to specify abuse and perpetrator type because they consider the surveyor\u2019s job to be identification and documentation of noncompliance. Additionally, CMS officials told us they have not conducted a systematic review to gather information on abuse and perpetrator type. This is inconsistent with federal internal control standards directing management to use quality information to achieve program objectives. Without the systematic collection and monitoring of specific abuse and perpetrator data, CMS lacks key information and, therefore, cannot take actions\u2014such as tailoring prevention and investigation activities\u2014to address the most prevalent types of abuse or perpetrators. All of the state survey agencies we spoke to told us that facility-reported incidents can lack key information that can cause potential delays in abuse investigations. Specifically, officials from each of the five state survey agencies told us that the facility-reported incidents they receive from nursing homes can lack key information that affects their ability to effectively triage incidents and determine whether an investigation should occur and how soon. Two state survey agencies we spoke with said they sometimes have to conduct significant follow-up with the nursing homes to obtain the information they need to prioritize the incident for investigation\u2014follow-up that delays and potentially negatively affects investigations. For example, one state survey agency told us that a facility reported abuse involving two residents but did not initially report that the residents were injured, and that the facility did not file an addendum to the facility-reported incident to indicate resident injury. As a result of this incomplete information, the state survey agency did not properly prioritize this incident response. Despite federal law requiring nursing homes to self-report allegations of abuse, and covered individuals to report reasonable suspicions of crimes against residents, CMS has not provided guidance on what information should be included in these reports. Our review of CMS\u2019s State Operations Manual found that CMS does not have guidance related to the information that nursing homes or covered individuals should report to the state survey agencies or local law enforcement; in contrast, it does contain guidance on the type of information members of the public should include in a complaint about nursing home quality to the state survey agency\u2014and CMS makes a standardized complaint template form available on its website. The lack of guidance on the information that state survey agencies should collect on facility-reported incidents is inconsistent with federal internal control standards directing management to use quality information to achieve program objectives. CMS could outline basic information requirements that states must include on incident forms used by nursing homes and covered individuals to ensure the state survey agency is receiving the information it needs to accurately and quickly triage these incidents. CMS officials told us in November 2018 that they have efforts underway to examine guidance related to the information state survey agencies need to appropriately triage these facility-reported incidents and are developing a facility-reported incident template. Until the guidance and template are in place, these facility-reported incidents may lack key information that can cause potential delays in abuse investigations. CMS requires state survey agencies to make referrals to law enforcement and, if appropriate, to MFCUs when abuse is substantiated; however, we found numerous gaps in CMS\u2019s referral process that can result in delayed and missed referrals. (See table 6.) Timing of abuse referrals. We found CMS\u2019s requirements for when state survey agencies should report abuse to law enforcement and MFCUs lag behind the federal requirements for when covered individuals should make such referrals, and, as a result, referrals may be significantly delayed. Specifically, federal law requires covered individuals to immediately report reasonable suspicions of a crime against a resident that results in serious bodily injury to law enforcement and the state survey agency. Conversely, state survey agencies do not have to report suspicions of crime identified on complaints submitted to, and surveys conducted by, the state survey agency until the abuse has been substantiated\u2014a process that can often take weeks or months. Officials from one law enforcement agency and two MFCUs that we interviewed told us the delay in receiving referrals limits their ability to collect evidence and prosecute cases\u2014for example, bedding associated with potential sexual abuse may have been washed and wounds may have healed. This is consistent with the findings of our 2002 report, where we recommended that CMS should ensure that state survey agencies immediately notify law enforcement or MFCUs when nursing homes report allegations of physical or sexual abuse. One state survey agency in our review established more stringent guidelines than CMS by requiring the surveyors to notify law enforcement and the MFCU promptly upon receiving a complaint of abuse. CMS officials told us their state survey agency reporting requirements are based on a March 2002 policy. This is inconsistent with standards for internal control, which state that management should communicate quality information externally so that external parties can help the entity achieve its objectives. Tracking of abuse referrals. In addition to delays in referring cases to law enforcement and MFCUs, CMS officials also told us that CMS does not conduct oversight to ensure that state survey agency referrals to law enforcement and the MFCUs are occurring as required for substantiated abuse, and, as a result, CMS cannot ensure that state survey agencies are complying with reporting obligations. For example, an official from one of the five state survey agencies we interviewed said they had never made a referral to law enforcement or the MFCU, despite having substantiated allegations of abuse. The state survey agency official told us that they do not refer cases to law enforcement, and that law enforcement referrals are the responsibility of the nursing home. This is incompatible with CMS guidelines requiring that substantiated abuse be referred to law enforcement; however, CMS officials told us that they do not track whether state survey agencies make referrals to law enforcement and the MFCUs. This is inconsistent with federal standards for internal control, which state that management should establish and operate monitoring activities to monitor the internal control system and evaluate the results. Definition of substantiated abuse. We found confusion among some state survey agencies about CMS\u2019s definition of what it means to substantiate an allegation of abuse\u2014a challenge because substantiation is a trigger in the investigation process, and CMS requires state survey agencies to make referrals to law enforcement and staff registries when abuse is substantiated by evidence. As a result, there is a potential for substantiated abuse to not be reported and, subsequently, not referred to law enforcement or MFCUs for criminal investigation. Two of the five state survey agencies in our review told us they believed they could not substantiate an allegation unless they could also cite a federal deficiency. This is inconsistent with CMS\u2019s guidance, which says that state survey agencies can substantiate that an allegation occurred without citing a federal deficiency and that, subsequently, these substantiated allegations must be referred to law enforcement and staff registries. For example, according to CMS guidance, if the state survey agency investigated and found evidence that a resident was abused, but the nursing home had taken preventive actions against the deficient practice, the state survey agency would then substantiate that the abuse occurred, but not cite a deficiency. However, state survey agencies may decide not to substantiate an abuse allegation verified by evidence if they believe no deficiency should be cited, such as if the nursing home had taken preventive action against the deficient practice, which could result in that abuse going unreported and not referred to law enforcement, MFCUs, or staff registries. Because substantiation of abuse is a critical trigger in abuse investigations, confusion around its interpretation could prevent these important next steps. CMS officials told us they are aware that the state survey agencies have varying interpretations of what it means to substantiate abuse. According to federal standards for internal control, management should internally communicate quality information to achieve the entity\u2019s objectives. Information sharing. We also found that CMS\u2019s guidance on state survey agency referrals contained in its State Operations Manual does not specify what incident information can be shared with local law enforcement, either in response to local law enforcement\u2019s request for information or when the state survey agency refers substantiated findings of abuse to local law enforcement. As a result, both state survey and law enforcement agencies expressed confusion and frustration about what information can be shared and said delays have occurred that can impede law enforcement investigations. Officials from two state survey agencies told us that CMS does not allow them to share any information with law enforcement without a written request. For example, officials from one state survey agency said that they cannot share the name of the resident abused or the time when the incident occurred. One state survey agency said that information sharing can be uneven, and told us that law enforcement is required to share information with the state survey agencies, but the state survey agencies do not share their investigatory information with law enforcement. Officials from another state survey agency wrote to CMS notifying CMS of a change in their state survey agency protocol that would make the referral process timelier by providing un-redacted survey records of substantiated abuse to local law enforcement. However, in CMS\u2019s 2017 written response to the survey agency, CMS told them that all written requests for these records must continue to be forwarded to CMS for processing in accordance with the federal Privacy Act. When we asked CMS officials what information state survey agencies can share with law enforcement in a referral, CMS explained that scenarios for requesting information can vary, and that CMS does not prescribe a specific method as it depends on the needs of the investigation. This lack of guidance is inconsistent with federal standards for internal control, which state that management should internally communicate quality information to achieve the entity\u2019s objectives. While nursing home abuse is relatively rare, our review shows that abuse deficiencies cited in nursing homes are becoming more frequent, with the largest increase in severe cases. As such, it is imperative that CMS have key information critical to understanding abuse and that the agency\u2019s oversight of nursing homes is strong. We found weaknesses in both CMS\u2019s understanding of abuse and in its oversight that need to be addressed. Specifically, because CMS cannot readily access information on abuse or perpetrator types in its data, it lacks key information critical to taking appropriate actions to address the most prevalent types of abuse and perpetrators. In addition, CMS has not provided guidance on what information should be included in facility-reported incidents, contributing to a lack of information for state survey agencies and, subsequently, delays in their investigations. This lack of guidance related to facility- reported incidents is important in light of our findings that abuse deficiencies are identified most commonly through facility-reported incidents. We also found other gaps in CMS\u2019s process related to ensuring timely referrals of abuse to law enforcement, tracking abuse referrals, defining abuse substantiation, and sharing information with law enforcement. These gaps affect CMS\u2019s oversight of abuse in nursing homes\u2014including the prevention, identification and timely investigation of abuse\u2014and may limit CMS\u2019s ability to ensure that nursing homes meet federal requirements for residents to be free from abuse. We are making the following six recommendations to the administrator of CMS: Require that abuse and perpetrator type be submitted by state survey agencies in CMS\u2019s databases for deficiency, complaint, and facility- reported incident data, and that CMS systematically assess trends in these data. (Recommendation 1) Develop and disseminate guidance\u2014including a standardized form\u2014to all state survey agencies on the information nursing homes and covered individuals should include on facility-reported incidents. (Recommendation 2) Require state survey agencies to immediately refer complaints and surveys to law enforcement (and, when applicable, to MFCUs) if they have a reasonable suspicion that a crime against a resident has occurred when the complaint is received. (Recommendation 3) Conduct oversight of state survey agencies to ensure referrals of complaints, surveys, and substantiated incidents with reasonable suspicion of a crime are referred to law enforcement (and, when applicable, to MFCUs) in a timely fashion. (Recommendation 4) Develop guidance for state survey agencies clarifying that allegations verified by evidence should be substantiated and reported to law enforcement and state registries in cases where citing a federal deficiency may not be appropriate. (Recommendation 5) Provide guidance on what information should be contained in the referral of abuse allegations to law enforcement. (Recommendation 6) We provided a draft of this product to HHS for review and comment. In its comments, reproduced in appendix IV, HHS concurred with our six recommendations and identified actions it is taking to implement them. Specifically, HHS said that it will: (1) look into options for requiring state survey agencies to record data on abuse and perpetrator type so that HHS may assess trends in these data; (2) develop guidance that includes a list of standardized data elements to be included when nursing homes report facility-reported incidents and guidance specific to the reporting and tracking of facility-reported incidents involving abuse; (3) require state survey agencies to immediately refer complaints to law enforcement if a reasonable suspicion of a crime against a resident has occurred and share relevant survey information; (4) consider how to implement mechanisms for tracking law enforcement referrals; (5) identify opportunities to clarify in guidance situations where citing a federal deficiency may not be appropriate, but reporting the abuse is still required; and (6) develop a list of standardized elements that should be included when reporting an abuse allegation to law enforcement. HHS also provided technical comments, which we incorporated as appropriate. As agreed with your offices, unless you publicly announce the contents of this report earlier, we plan no further distribution until 30 days from the report date. At that time, we will send copies to the Secretary of HHS and other interested parties. In addition, the report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact me at (202) 512-7114 or at dickenj@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix V. This appendix describes our scope and methodology for determining the trends and types of abuse occurring in nursing homes in recent years. For this examination, we reviewed CMS guidance and analyzed data from 2013 through 2017, which represented the most recent data for a 5-year period at the time of our review. Specifically, we first reviewed the CMS State Operations Manual\u2019s Appendix PP that was in effect during our period of review to determine which federal standards and deficiency codes were relevant to resident abuse. We focused our analysis on the deficiency code to be used by state surveyors when a nursing home fails to keep a resident free from abuse, which encompasses mental/verbal, sexual, or physical abuse. Surveyors can also use other deficiency codes for abuse-related issues, such as a failure by the nursing home to train staff on issues related to abuse, either in conjunction with an abuse deficiency or without an abuse deficiency. Since these abuse-related deficiency codes do not necessarily represent incidents of abuse, but do represent situations where a nursing home\u2019s inadequate policies could leave residents vulnerable to abuse, we conducted a limited analysis on the trends of these deficiencies, which is described in appendix II. For our analysis, we identified abuse deficiencies cited by surveyors in all 50 states and Washington, D.C., between 2013 and 2017, using data provided by CMS from its Certification and Survey Provider Enhanced Reports system. Specifically, we calculated the number of abuse deficiencies cited each year and determined how many of these abuse deficiencies were at each level of severity\u2014no actual harm with a potential for minimal harm, no actual harm with a potential for more than minimal harm, actual harm, and immediate jeopardy\u2014for each year. We compared the results for abuse deficiencies with the results for all types of deficiencies in each year. To avoid over-counting deficiencies, deficiencies that were for the same violation on the same day for the same facility were counted as a single deficiency. We then tracked (1) the origin of these abuse deficiencies and (2) enforcement actions implemented against nursing homes with these abuse deficiencies. Origin of abuse deficiencies. To identify trends in the origin of those abuse deficiencies\u2014that is, whether the deficiency originated from a standard survey, complaint investigation, or a facility-reported incident investigation\u2014we analyzed data provided by CMS from its Automated Survey Processing Environment Complaint/Incident Tracking System. Specifically, we matched the deficiencies with the complaint/incident data using provider number, survey date, and deficiency code. We found that some deficiencies were the result of a combination of complaints, facility-reported incidents, surveys, or all three. We counted those deficiencies as originating from each relevant category. Enforcement actions. To identify trends in the enforcement actions imposed and implemented against nursing homes with abuse deficiencies, we analyzed data provided by CMS from its Automated Survey Processing Environment Enforcement Manager. Specifically, we matched the deficiencies with the enforcement data using provider number, survey date, case identification number, and deficiency code. To avoid over-counting, deficiencies that share the same code and case identification number were counted as a single deficiency. For each year, we determined how many of the abuse deficiencies resulted in enforcement actions imposed or implemented, the severity of the abuse deficiencies with enforcement actions, and the types of enforcement actions implemented. We then examined these abuse deficiencies to determine the number of nursing homes that had abuse deficiencies, as well as the number of homes with repeated abuse deficiencies cited across the 5 years and the characteristics of those homes. We also determined the proportion of surveyed nursing homes in a given year that had an abuse deficiency. Nursing homes that had repeated abuse deficiencies. Since a nursing home can have more than one abuse deficiency cited in a given year, we determined the number of surveyed nursing homes each year that had at least one abuse deficiency, both nationally and by state. For each of those nursing homes, we determined if the home had an abuse deficiency repeated in multiple years and in two or more consecutive years. Nursing home characteristics. We attempted to identify commonalities among homes with multiple years of abuse deficiencies, homes with only a single year with an abuse deficiency, and surveyed homes without any abuse deficiencies throughout the 5- year period. Specifically, we matched deficiency data to CMS\u2019s publicly available Provider of Services files and the Nursing Home Compare Provider Information files for each nursing home; and we examined bed size, non-profit or for-profit status, Five-Star Quality Rating System overall rating, Special Focus Facility designation, and urban or rural location. Finally, because abuse and perpetrator type are not readily identifiable in CMS\u2019s data, we identified this information by reviewing the narratives written by surveyors that describe the substantiated abuse. Specifically, we obtained 1,557 narrative descriptions written by state surveyors for abuse deficiencies cited in 2016 and 2017 provided by CMS from its Automated Survey Processing Environment database. From that universe of abuse deficiency narratives, we selected a randomly selected representative sample of 400 narratives, and each narrative was reviewed by two separate reviewers who independently analyzed the text of each narrative to determine the abuse and perpetrator type according to the definitions that CMS implemented on November 28, 2017, in its State Operations Manual. Any disagreements between the two reviewers were resolved by a third independent reviewer. (See table 7.) For those narratives where the abuse type could not reasonably be categorized under an existing CMS definition, reviewers had the option to mark narratives as \u201cother.\u201d Furthermore, we analyzed the scope and severity for each narrative within our sample. CMS\u2019s abuse deficiency code also included involuntary seclusion in the time period we examined and is defined in its November 22, 2017, guidance as \u201cseparation of a resident from other residents or from her/his room or confinement to her/his room (with or without roommates) against the resident\u2019s will, or the will of the resident representative.\u201d Our analysis of the narrative descriptions found that 3 percent of the abuse deficiency narratives in our sample were attributable to involuntary seclusion. We were unable to categorize the abuse and perpetrator type for about 11 percent of the deficiency narratives in our sample, because we determined the narrative description did not meet CMS\u2019s abuse definition. We assessed the reliability of each of the datasets by checking for missing values and obvious errors and discussed them with CMS officials who were knowledgeable about the data. In the course of this assessment, we found some data limitations. Specifically, CMS officials told us that some state survey agencies may not have entered all facility- reported incidents into the Automated Survey Processing Environment Complaint/Incident Tracking System, while other state survey agencies did. We also found underreporting, as noted in our 2019 report, where the Oregon state survey agency was not entering all abuse-related complaints or facility-reported incidents into this same database\u2014a problem that could exist in other states. In addition, CMS officials told us that it is possible there are additional incidents that may not have been represented in the abuse deficiency data during the period of our review. Specifically, CMS officials noted that some incidents resulting from resident altercations\u2014particularly those that do not show a willful intent to harm\u2014may not be cited as an abuse deficiency by some state survey agencies. We therefore consider the number of abuse deficiencies that resulted from complaints or facility-reported incidents to be a conservative estimate. After reviewing the possible limitations of these data, we determined the data were sufficiently reliable for the purposes of this reporting objective. This appendix describes trends in abuse-related deficiencies over the 5- year period from 2013 through 2017. We reviewed Centers for Medicare & Medicaid Services (CMS) guidance that was in effect during this period of review to determine which federal standards and deficiency codes were relevant to resident abuse. For the report, we focused our analysis on the deficiency code cited when state surveyors substantiate incidents of abuse, but there are also deficiencies that surveyors can cite for abuse-related issues, such as a failure by the nursing home to train staff on issues related to abuse, either in conjunction with an abuse deficiency or without an abuse deficiency. Since these abuse-related deficiencies do not necessarily represent incidents of abuse, but do represent situations where a nursing home\u2019s inadequate policies could leave residents vulnerable to abuse, we also conducted a limited analysis on the trends of these deficiencies. Specifically, we analyzed CMS data to identify the number of abuse-related deficiencies cited in each year in all 50 states and Washington, D.C., and determined how many were cited at each level of severity\u2014no actual harm with a potential for minimal harm, no actual harm with a potential for more than minimal harm, actual harm, and immediate jeopardy. We also tracked the source of these abuse-related deficiencies\u2014that is, whether the deficiency originated from a standard survey, complaint investigation, or a facility-reported incident investigation. Finally, we compared the results for abuse-related deficiencies with the results for all types of deficiencies cited by surveyors in each year. From 2013 to 2017, we found that abuse-related deficiencies became slightly more common with a resulting increase in severity. Specifically, abuse-related deficiencies increased by about 9.9 percent over the 5-year period, from 4,899 deficiencies cited in 2013 to 5,383 deficiencies cited in 2017, but peaked in 2016 with 5,687 deficiencies. This increasing trend for abuse-related deficiencies is in contrast to the slight decrease in all deficiencies cited over the same period, but not nearly as high as the 103.5 percent increase in abuse deficiencies. In addition, the proportion of abuse-related deficiencies cited at the highest levels of severity\u2014 deficiencies causing actual harm to residents or putting residents in immediate jeopardy\u2014fluctuated throughout the 5-year period. Specifically, about 6.1 percent of the 4,899 abuse-related deficiencies in 2013, about 5.6 percent of the 5,278 abuse-related deficiencies in 2015, and about 7.8 percent of the 5,383 abuse-related deficiencies in 2017 caused actual harm or immediate jeopardy. (See fig. 7.) We also found that over half of the abuse-related deficiencies each year were cited by surveyors as a result of standard surveys, and the rest were cited by surveyors as a result of either complaint or facility-reported incident investigations. This falls between what we found for abuse deficiencies\u2014the majority were a result of either complaint or facility- reported incident investigations\u2014and all types of deficiencies\u2014the vast majority were a result of standard surveys. Over the 5 years, similar to abuse deficiencies and all types of deficiencies, the percentage of abuse- related deficiencies that resulted from standard surveys decreased while the percentage that resulted from both complaint and facility-reported incident investigations increased. Specifically, over the 5-year period, the percentage of abuse-related deficiencies resulting from standard surveys decreased by about 8.8 percentage points, complaint investigations increased by about 3.6 percentage points, and facility-reported incident investigations increased by about 5.3 percentage points. (See fig. 8.) Tables 8 and 9 provide state-level data on abuse deficiencies and the nursing homes that had abuse deficiencies cited in consecutive years. John E. Dicken, (202) 512-7114 or dickenj@gao.gov. In addition to the contact named above, Karin Wallestad (Assistant Director); Sarah-Lynn McGrath and Kathryn Richter (Analysts-in-Charge); Luke Baron; Summar Corley; Zosha Kandel; and Julianne Flowers made key contributions to this report. Also contributing were Laurie Pachter, Jennifer Whitworth, and Vikki Porter.", "summary": "Nursing homes provide care to about 1.4 million nursing home residents\u2014a vulnerable population of elderly and disabled individuals. CMS, an agency within the Department of Health and Human Services (HHS), defines standards nursing homes must meet to participate in the Medicare and Medicaid programs. GAO was asked to review abuse of residents in nursing homes. Among other objectives, this report: (1) determines the trends and types of abuse in recent years, and (2) evaluates CMS oversight intended to ensure residents are free from abuse. GAO reviewed CMS's policies, analyzed CMS data on abuse deficiencies from 2013 through 2017, the most recent data at the time of our review, and interviewed officials from CMS and state survey agencies in five states, as well as other key stakeholders in those states such as ombudsmen and law enforcement officials. The states were selected for variation in factors such as number of nursing homes and role of other state agencies in abuse investigations. The Centers for Medicare & Medicaid Services (CMS) is responsible for ensuring nursing homes meet federal quality standards, including that residents are free from abuse. CMS enters into agreements with state survey agencies to conduct surveys of the state's homes and to investigate complaints and incidents. GAO analysis of CMS data found that, while relatively rare, abuse deficiencies cited in nursing homes more than doubled, increasing from 430 in 2013 to 875 in 2017, with the largest increase in severe cases. GAO also reviewed a representative sample of abuse deficiency narratives from 2016 through 2017. Physical and mental/verbal abuse occurred most often in nursing homes, followed by sexual abuse, and staff were more often the perpetrators of the abuse deficiencies cited. CMS cannot readily access information on abuse or perpetrator type in its data and, therefore, lacks key information critical to taking appropriate actions. GAO also found gaps in CMS oversight, including: Gaps in CMS processes that can result in delayed and missed referrals. Federal law requires nursing home staff to immediately report to law enforcement and the state survey agency reasonable suspicions of a crime that results in serious bodily injury to a resident. However, there is no equivalent requirement that the state survey agency make a timely referral for complaints it receives directly or through surveys it conducts. CMS also does not conduct oversight to ensure that state survey agencies are correctly referring abuse cases to law enforcement. Insufficient information collected on facility-reported incidents. CMS has not issued guidance on what nursing homes should include when they self-report abuse incidents to the state survey agencies. Officials from all of the state survey agencies in GAO's review said the facility-reported incidents can lack information needed to prioritize investigations and may result in state survey agencies not responding as quickly as needed. GAO is making six recommendations, including that CMS: require state survey agencies to submit data on abuse and perpetrator type; require state survey agencies to immediately refer to law enforcement any suspicion of a crime; and develop guidance on what abuse information nursing homes should self-report. HHS concurred with all of GAO's recommendations and identified actions it will take to implement them."}
{"id": "govreport_4", "report": "This section provides an overview of (1) the legal framework governing mixed HLW, (2) the status of EM\u2019s IWTU reengineering project, (3) EM\u2019s requirements for capital asset projects and operations activities, (4) DOE\u2019s policy for the review of projects with start-up risks, and (5) our best practices for assessing cost and schedule estimates. The treatment and disposal of mixed HLW at INL is governed by a number of federal laws that define the roles of federal agencies and states in managing mixed HLW, as well as cleanup agreements among DOE, the state of Idaho, and other parties. DOE primarily regulates radioactive components of HLW under the Atomic Energy Act of 1954, as amended, and the Nuclear Waste Policy Act of 1982, as amended. These acts define HLW as (1) the highly radioactive waste material resulting from the reprocessing of spent nuclear fuel, including liquid waste produced directly in reprocessing and any solid material derived from such liquid waste that contains fission products in sufficient concentrations, and (2) other highly radioactive material that the Nuclear Regulatory Commission determines by rule, consistent with existing law, requires permanent isolation. DOE considers calcine waste HLW because it is solidified liquid waste produced during the reprocessing of spent nuclear fuel. EM manages the SBW as mixed HLW because, according to reports from DOE and National Academies, (1) the SBW was produced in the later stages of spent nuclear fuel reprocessing, (2) the tanks in which the SBW is stored previously held HLW, (3) the SBW is stored in a location at INL where waste is managed as HLW, and (4) the waste contains hazardous chemicals subject to RCRA and EPA\u2019s implementing regulations or authorized state programs that operate in lieu of the federal program. HLW must be disposed of in a geologic repository unless the Nuclear Regulatory Commission approves an alternative disposal site. DOE Order 435.1 and Manual 435.1-1 describe the department\u2019s policy and requirements for managing DOE\u2019s radioactive waste, including HLW, to ensure that it is managed in a manner that is protective of worker and public health and safety and the environment. Manual 435.1-1 also established processes to determine whether waste resulting from reprocessing spent nuclear fuel can be managed as transuranic waste or low-level waste if certain criteria are met, which is referred to as a determination that the waste is incidental to reprocessing. According to the manual, HLW is waste incidental to reprocessing if, among other things, the waste has been processed, or will be processed, to remove key radionuclides to the maximum extent technically and economically practicable. Hazardous components of mixed HLW are regulated by EPA or authorized states under RCRA. EPA\u2019s regulations require hazardous waste to meet certain treatment standards before land disposal of the waste unless a variance is granted. The regulations specify that the treatment standard (i.e., the required method for treatment) for Idaho\u2019s mixed HLW is vitrification\u2014the immobilization of waste in glass. Where EPA has authorized states to implement hazardous waste management programs, those state programs operate instead of the federal program. EPA, under RCRA, has authorized the state of Idaho to administer its own hazardous waste management program. EPA has also authorized New Mexico to administer its own hazardous waste management program. Pursuant to such authorization, New Mexico\u2019s Environment Department issues the permit for hazardous waste storage and disposal at WIPP under the New Mexico Hazardous Waste Act. As of March 2019, EM\u2019s IWTU reengineering project was in phase two of the four-phased approach to get the facility operational, according to EM Idaho Cleanup Project officials. According to project reports, phase one focused on identifying fixes to resolve problems with the facility\u2019s equipment and waste treatment process, for example, by performing engineering analyses and chemistry studies. Phase two has focused on implementing these fixes, for example, by modifying a piece of equipment that separates solidified waste before it is moved to storage canisters, according to the contractor\u2019s project plan. Figure 1 summarizes the four- phased approach for the IWTU reengineering project. According to EM documents, as of February 2019 total expenditures on phases one and two were approximately $150 million, about $64 million more than original costs estimated for those two phases combined, and the project was over 1 year behind schedule. Phase two has taken longer and cost more than initially estimated because of additional problems and required modifications to the facility as the work has progressed, according to EM Idaho Cleanup Project officials. Appendix II provides information on the actual costs of phases one and two compared to estimated costs. As previously noted, EM officials with the Idaho Cleanup Project estimated in March 2019 that phase three may begin in summer 2019. Further, these officials stated that phase three will involve a 6- month outage to continue implementing changes to the facility prior to the start of a 60-day performance test using a simulated waste form. EM Idaho Cleanup Project officials stated that phase four could begin in early 2020 and that EM and Fluor Idaho had yet to determine whether an outage would need to occur before starting testing with a small amount of the SBW. EM divides its cleanup work into capital asset projects and operations activities, two types of activities governed by different applicable project management policies: Capital asset projects. DOE Order 413.3B governs EM\u2019s program and project management activities for the acquisition of capital assets, with the stated goal of delivering fully capable projects within the planned cost, schedule, and performance baseline. The order establishes five critical decision points of project development that each end with a major approval milestone that cover the life of a project. The order specifies requirements that must be met, including developing and managing project cost and schedule estimates to move a project past each critical decision milestone. EM capital asset projects include construction projects and cleanup projects, such as soil and water remediation and facility decommissioning and demolition. Operations activities. Operations activities are recurring facility or environmental operations, as well as activities that are project-like, with defined start and end dates, according to EM policy. EM operations activities include operating waste processing facilities and the stabilization, packaging, transportation, and disposition of nuclear waste. EM manages operations activities based on requirements listed in a cleanup policy that it issued in July 2017. In February 2019, we found that EM cleanup site managers have discretion in how to classify cleanup work because DOE and EM have not established requirements on what work should be managed as an operations activity under EM\u2019s cleanup policy or as a capital asset project under DOE Order 413.3B. Further, we found that operations activities have less stringent management requirements than capital asset projects. We recommended that EM establish requirements for classifying work as an operations activity and revise its cleanup policy to follow program and project management leading practices. DOE generally agreed with our recommendations. Beginning in January 2005, EM managed the development and construction of the IWTU facility as a capital asset project. Once EM determined that construction on the facility was complete in April 2012, the project exited the capital asset oversight process established in DOE Order 413.3B and has since been managed as an operations activity, according to EM Idaho Cleanup Project officials. DOE officials also told us that the IWTU reengineering project has been managed as an operations activity because the facility has been constructed and is now in a period of maintenance and repair. Figure 2 shows a picture of the exterior of the IWTU facility. In August 2016, DOE\u2019s Deputy Secretary of Energy issued a memorandum establishing a new oversight requirement for selected projects for which an extended period of transition to operations is likely\u2014 the phase after construction is complete but before full operational capability is attained\u2014called the operational release milestone. According to the memorandum, DOE created the operational release milestone in the department\u2019s project life cycle to provide additional oversight after the completion of the project under DOE\u2019s Order 413.3B. DOE officials from the Office of Project Management stated that the operational release milestone was largely created in response to EM\u2019s experience with the IWTU facility not operating as expected. Under these new requirements, program offices are to provide DOE\u2019s Project Management Risk Committee (PMRC) with regular updates on selected projects until full operational capability of each facility is attained. Specifically, program offices are required to (1) develop and execute a plan that describes how the program will reach operational capability, which is referred to as an operational release plan, and (2) provide progress updates to the PMRC on the project, as described below. Operational release plan. Officials from DOE\u2019s Office of Project Management\u2014which serves as the secretariat for the PMRC\u2014stated that the purpose of the operational release plan is for the program office to describe what steps are required for the project to reach its operational capability. According to EM\u2019s guidance, the operational release plan should present the key processes, activities, interrelationships, risks, management and oversight, decision milestones and approvals, and overall schedule to achieve operational release. Progress updates. According to the memorandum and the PMRC\u2019s standard operating procedures, program offices are to provide the PMRC with quarterly progress updates on selected projects, including lessons learned, until full operational capability is attained. The GAO\u2019s cost guide and schedule guide compiled best practices corresponding to the characteristics of high-quality and reliable cost and schedule estimates. According to the cost guide, a high-quality, reliable cost estimate has four characteristics: comprehensive, well-documented, accurate, and credible. A comprehensive cost estimate has enough detail to ensure that cost elements are neither omitted nor double-counted. If a cost estimate is not comprehensive (that is, complete), then it cannot fully meet the other characteristics (i.e., well-documented, accurate, or credible). In addition, according to the schedule guide, a high-quality, reliable schedule has four characteristics: comprehensive, well- constructed, controlled, and credible. A comprehensive schedule captures all government and contractor activities necessary to accomplish a project\u2019s objectives, and a well-constructed schedule sequences all activities using the most straightforward logic possible. If a schedule is not comprehensive, with all activities accounted for, it is uncertain whether all activities are scheduled in the correct order, resources are properly allocated, missing activities will appear on the critical path, or a schedule risk analysis can account for all risk. If a schedule is not well-constructed, it will not be able to properly calculate dates and predict changes in the future, among other things. EM has not fully followed selected project management best practices for cost and schedule estimates for the IWTU reengineering project. EM generally followed best practices for a reliable EVM system to measure the performance of the reengineering project. However, in analyzing IWTU reengineering project data from March 2017 through February 2018, we found that the system is producing unreliable data, which may limit EM\u2019s ability to measure the project\u2019s performance. Further, EM has taken some steps toward meeting requirements under DOE\u2019s process for monitoring projects with start-up risks. EM has not fully followed (i.e., has partially met) selected best practices in developing the cost and schedule estimates we reviewed for phases one and two of the IWTU reengineering project and future planned IWTU operations. We made the following observations based on our analysis of these cost estimating documents and a March 2018 project schedule: Comprehensive cost estimate (partially met): EM partially met best practices for a comprehensive cost estimate. According to our cost guide, a comprehensive cost estimate should reflect the project\u2019s technical requirements and current schedule and account for all possible costs. While the cost estimate was based on documented technical information, it was not based on a standardized work breakdown structure. Without a standard, product-oriented work breakdown structure to facilitate the tracking of resource allocations and expenditures, EM may not be able to reliably estimate the cost of future similar programs. While assumptions are listed in EM\u2019s documents describing the cost estimates, no document discusses whether the assumptions came from inputs from technical subject matter experts or whether the assumptions are associated with specific risks. Since assumptions are best guesses, best practices state that the risk associated with any of these assumptions changing need to be identified and assessed. Further, the IWTU reengineering project\u2019s cost estimate was not complete because it did not account for all possible costs. According to our cost guide, a life cycle cost estimate provides an exhaustive and structured accounting of all resources and associated cost elements required to develop, produce, deploy, and sustain a particular program. The project\u2019s cost estimate did not reflect all life cycle costs, in part because estimates for phases three and four of the project had not been developed at the time of our review. Best practices state that all costs be included in an estimate, even in early stages, such as at a rough order of magnitude. EM officials from the Idaho Cleanup Project said that a cost estimate was not developed for the total cost of the IWTU reengineering project because of the approach for negotiating the cost and schedule baseline prior to the start of each phase. Without developing a cost estimate for the IWTU reengineering project that is comprehensive (e.g., accounts for all possible costs), EM will not have reasonable assurance that it can successfully plan program resource requirements. Well-constructed schedule estimate (partially met): EM partially met best practices for a well-constructed schedule. According to our schedule guide, a well-constructed schedule includes activities that are logically sequenced; a valid critical path; and a reasonable amount of total float, meaning an accurate reflection of the schedule\u2019s flexibility. EM\u2019s March 2018 schedule had minimal sequencing issues and a continuous critical path, with the exception of an external dependency, and the critical path was free of lags and constraints. However, there were long duration activities on the critical path that should be reevaluated to determine if they can be broken into more manageable pieces. Without a valid critical path, management cannot focus on activities that will detrimentally affect the key program milestones and deliveries if they slip. Additionally, the schedule estimate included unreasonably large values of positive and negative float. According to best practices, a schedule should identify reasonable values of float so that the schedule\u2019s flexibility can be determined to help accommodate for delays. EM officials from the Idaho Cleanup Project explained that the amount of total float was a result of the methods they used to structure the logic of the schedule estimate, which according to our best practices may have caused the schedule to be overly optimistic. According to scheduling best practices, without accurate values of total float, the schedule cannot be used to identify activities that could be permitted to slip and thus release and reallocate resources to activities that require more resources to be completed on time. Inaccurate values of total float also falsely depict true program status, which could lead to decisions that may jeopardize the program. In addition, the March 2018 schedule contained 14 activities with large amounts of negative float, meaning that these activities were behind schedule. Without fully developing a well-constructed schedule estimate for the IWTU reengineering project, EM will not have reasonable assurance that it can successfully achieve its plans to reengineer the IWTU and begin treatment of the SBW without further delays. Comprehensive schedule estimate (substantially met): EM substantially met best practices for a comprehensive schedule. According to our schedule guide, a comprehensive schedule includes all activities for both the government and its contractors to accomplish their objective, assigns resources (e.g., labor and materials) to all activities, and establishes how long each activity will take. EM\u2019s March 2018 schedule substantially captured all activities, but it may not have been planned to the level of detail for the work necessary to accomplish a program\u2019s objectives as defined in the program\u2019s work breakdown structure. For example, the schedule had activities that were described as level of effort but were not assigned the level of effort activity type. Level of effort activities represent effort that has no measurable output and, according to best practices, should be clearly marked so they do not interfere with the critical path. Further, the schedule substantially met the best practice of assigning resources to all activities. For example, the schedule assigned resources to specific materials and equipment as well as to travel, training, and labor. Appendix II contains the full results of our analysis of selected best practices for the cost and schedule of the IWTU reengineering project. As previously noted, EM is managing the IWTU reengineering project as an operations activity. We reported in February 2019 that EM manages operations activities using less stringent requirements than those used for capital asset projects, posing cost and schedule risks. For example, under EM\u2019s 2017 cleanup policy, there is no requirement for operations activities to follow best practices for cost estimates developed during contract execution. We recommended that EM review and revise its 2017 cleanup policy to include project management leading practices related to scope, cost, schedule performance, and independent reviews. DOE concurred with our recommendation and stated that EM was already in the process of reviewing its policy for necessary updates, revisions, and modifications, and that EM would consider our recommendation, as appropriate, during this process. EM officials with the Idaho Cleanup Project acknowledged that they do not have an estimate for the total cost or a completion date for the IWTU reengineering project or a schedule for when waste treatment operations will begin and be completed. An EM Idaho Cleanup Project official told us that Fluor Idaho submitted cost and schedule estimates for phases three and four of the reengineering project in January 2019 and that EM requested an independent cost estimate for this work from the Defense Contract Audit Agency, with contract negotiations between EM and Fluor Idaho for these phases estimated to begin in spring 2019. In addition, EM officials from the Idaho Cleanup Project acknowledged that a schedule for waste treatment operations at the project has not been developed. Further, these officials noted that design modifications to the IWTU are expected to reduce its operating capability, lengthening the time needed to treat the SBW. As a result, EM and Fluor Idaho plan to renegotiate the cost of their contract related to the treatment of the waste in the project, according to EM Idaho Cleanup Project officials. Specifically, because of the modifications to the project, the rate at which the SBW is treated will be slower than initially estimated, according to EM officials from the Idaho Cleanup Project. Treatment of all 900,000 gallons of the SBW was originally estimated to be completed in 10 months, but agency officials now estimate that treatment may take from 3 to 7 years\u2014 as much as eight times longer than originally planned. As previously noted, EM has already experienced approximately $64 million in added costs and, as of February 2019, a delay of over 1 year. Without fully following best practices for a comprehensive cost estimate and well- constructed schedule estimate for SBW waste treatment operations, EM cannot be assured that it has reliable cost and schedule estimates for decision-making, placing it at risk of continued cost overruns and delays in achieving its plans to reengineer the IWTU and begin treatment of the SBW. We analyzed IWTU reengineering project data for March 2017 through February 2018 from EM\u2019s EVM system and found that while EM has followed (i.e., fully met or substantially met) some best practices for a reliable EVM system, the system is producing unreliable data. These unreliable data may limit EM\u2019s ability to measure the project\u2019s performance. EVM is a management tool used to measure the value of work accomplished in a given period and compare it with the planned value of work scheduled for the same period and with the actual cost of the work accomplished. EVM data can alert project managers to potential problems sooner than expenditures alone can, and EVM\u2019s use as a management tool is considered a best practice for conducting cost and schedule performance analysis for projects, according to our cost guide. EM requires the use of an EVM system under its contract with Fluor Idaho for the Idaho Cleanup Project. Overall, we found that EM followed best practices to ensure that its EVM data for the IWTU reengineering project were (1) comprehensive and (2) used by leadership for decision-making. However, EM did not follow (i.e., partially met) best practices to ensure that the data resulting from the EVM system are reliable. Specifically: EM substantially met best practices for a comprehensive EVM system by, for example, requiring the contractor\u2019s EVM system to comply with the guidelines established by the Earned Value Management Systems EIA-748-D Intent Guide; EM conducted a compliance review of Fluor Idaho\u2019s EVM system in March 2017 and found some areas in need of improvement. In addition, EM has an EVM surveillance system in place under its contract with Fluor Idaho, and EM officials from the Idaho Cleanup Project stated that they review data from the EVM system each month. EM substantially met best practices ensuring that leadership uses the EVM data for decision-making. For example, Fluor Idaho updated data in its EVM system monthly during the period we reviewed, and EM reported issues in a monthly review briefing between EM and the contractor, according to EM Idaho Cleanup Project officials. Agency management also tracked the causes of cost and schedule variances in the data. However, the monthly reports did not contain all the information that best practices recommended. Specifically, the performance measurement baseline was not included in the contractor performance reports provided, so we could not determine how the performance measurement baseline changed as the project evolved. EM partially met best practices ensuring that the EVM system provides reliable data because, for instance, the system contained numerous anomalies, leading the system to produce unreliable data. Specifically, we found one or more anomalies present in all months of data reviewed, such as missing or negative values. While EM was able to explain the causes for most of these anomalies, negative values should occur rarely, if ever, in EVM reporting because they imply the undoing of previously scheduled or performed work. According to best practices, all anomalies should also be identified and the reason for each should be fully explained in EM\u2019s monthly EVM reports. However, EM did not document the reasons for these anomalies in its monthly reports. EM officials from the Idaho Cleanup Project said that most of the anomalies in the data were due to the phase two estimate including authorized unpriced work\u2014that is, additional work that EM agreed to let the contractor perform without first negotiating or independently verifying the costs. If errors in EVM reports are not detected, then EVM data will be skewed, resulting in bad decision-making and limiting EM\u2019s ability to use the EVM system to measure project performance. Appendix III provides detailed information on EM\u2019s performance on each EVM best practice. An EVM system that produces unreliable data may contribute to EM\u2019s challenges in measuring the performance of its operations activities. Our findings in this regard are consistent with our prior reports examining EM\u2019s use of EVM systems in other contracts. For example, in February 2019 we reviewed the use of EVM systems in the 21 contracts EM uses to execute its operations activities, including Fluor Idaho\u2019s contract for the cleanup at INL, and found that EM has not followed best practices to ensure that these systems (1) are comprehensive, (2) provide reliable data, and (3) are used by EM leadership for decision-making. We recommended that EM update its cleanup policy to require that EVM systems be maintained and used in a way that follows EVM best practices, such as ensuring the reliability of the data in the system. Without following best practices for ensuring EVM data reliability for the IWTU reengineering project\u2019s EVM system, EM leadership may not have access to reliable performance data with which to make informed decisions as it manages billions of dollars\u2019 worth of cleanup work and provides information to Congress and other stakeholders on the cleanup work every year. In 2016, DOE instituted independent review requirements to monitor facilities with commissioning or start-up risks, and EM has taken some steps toward meeting those requirements for the IWTU reengineering project. As previously noted, DOE\u2019s policy requires program offices to (1) develop and execute an operational release plan and (2) provide progress updates to the PMRC on the project each quarter. We made the following observations on EM\u2019s actions to meet these requirements for the reengineering of the IWTU project: EM developed an operational release plan for the IWTU project in December 2016, which preceded EM\u2019s developing guidance for these plans. We found that the operational release plan included the majority of elements that EM\u2019s guidance later required. EM has provided five progress update briefings to the PMRC on the IWTU reengineering project, according to DOE documents, but these briefings have not occurred each quarter as required by DOE\u2019s policy. Officials from DOE\u2019s Office of Project Management told us that briefings generally occur when progress has been made on a project. EM\u2019s guidance for operational release plans also states, with regard to progress update briefings, that an alternate reporting schedule may be proposed for PMRC approval. The PMRC made recommendations in three of these five briefings. For example, the PMRC recommended that EM revisit and review documents to ensure that the delegated authority is clear, current, and appropriate prior to facility start-up and the introduction of radioactive materials. According to documentation prepared following EM\u2019s most recent briefing to the PMRC in February 2019, the PMRC recommended an update on the project in July 2019. Based on our review of EM documentation and plans, the agency does not have a strategy or timeline to address its three main challenges for disposing of the SBW or for identifying an alternative disposal pathway. EM identified WIPP as its preferred disposal site for the SBW in a 2005 Record of Decision document, but in March 2019 EM officials told us that a final decision on the disposal path for the SBW had not been made. The three main challenges EM faces in its plan to dispose of the SBW at its preferred disposal site are: (1) the permit for WIPP prohibits the SBW from being disposed of at WIPP, (2) federal law prohibits HLW from being disposed of at WIPP, and (3) there are existing capacity limitations to disposal at the WIPP facility. EM has taken some steps to address these challenges, as discussed further below. WIPP permit\u2019s prohibition of the disposal of certain tank waste. New Mexico amended its permit for WIPP in 2004 to prohibit waste that has ever been managed as HLW, including the SBW at INL, from being disposed at WIPP unless the disposal of such waste is specifically approved through a permit modification. In 2013, DOE and its contractor responsible for operating and managing the facility filed a request with the state of New Mexico to modify the WIPP permit to remove this prohibition, which could allow the SBW to be disposed of at WIPP if EM determined that the SBW is waste incidental to reprocessing. However, the process was put on hold following the suspension of operations at WIPP in 2014, according to officials from DOE\u2019s Carlsbad Field Office and New Mexico\u2019s Environment Department. In April 2019, officials from New Mexico\u2019s Environment Department said that they anticipated holding discussions with DOE and its contractor for the facility regarding the prohibition after the renewal of the WIPP permit in July 2020. However, a representative from a New Mexico environmental organization said that this proposed modification would likely face strong public opposition. This representative noted that previous DOE attempts to expand the types of waste that could be disposed of at WIPP caused significant public concern in New Mexico. Further, New Mexico Environment Department officials told us that processing permit modifications of this nature would likely require public hearings and opportunities for input and may take as long as 2 years or more to complete. Federal statutory prohibition on HLW disposal at WIPP. The Waste Isolation Pilot Plant Land Withdrawal Act prohibits disposal of HLW at WIPP. Therefore, to enable EM to dispose of the SBW at WIPP, the SBW would need to be classified as non-HLW, or the act would need to be amended to remove the prohibition. DOE has a process for determining that certain waste resulting from reprocessing spent nuclear fuel, such as the SBW and calcine waste, could be managed as either transuranic waste or low-level waste, which are not HLW. Under DOE Order 435.1 and Manual 435.1-1, DOE may determine that waste is incidental to reprocessing and therefore manage the waste as transuranic waste or low-level waste if it meets certain criteria. EM began developing documentation supporting a waste incidental to reprocessing determination for the SBW in 2001. For example, in September 2001, EM requested consultation from the Nuclear Regulatory Commission, which oversees the nuclear power industry, on a draft waste incidental to reprocessing determination so that the SBW could be managed as transuranic waste and disposed of at WIPP rather than in an HLW repository. DOE\u2019s Authority to Determine That Certain Waste Is Not HLW In 2002, while litigation over the Department of Energy\u2019s (DOE) authority to use DOE Order 435.1 and Manual 435.1-1 was pending, DOE sought enactment of legislation clarifying its authority to manage portions of tank waste that have low levels of radioactivity as low- level waste. In response, Congress enacted section 3116 of the Ronald W. Reagan National Defense Authorization Act for Fiscal Year 2005 in October 2004. Under section 3116, radioactive waste resulting from the reprocessing of spent nuclear fuel is not high- level waste (HLW) if the Secretary of Energy, in consultation with the Nuclear Regulatory Commission, determines that it meets specified conditions. These conditions include that the waste does not require disposal in a deep geologic repository and has had highly radioactive radionuclides removed to the maximum extent practical. However, section 3116 only applies to waste stored at DOE sites in Idaho and South Carolina that is not transported from those states. Therefore, DOE cannot use section 3116 to classify the sodium-bearing waste (SBW) as transuranic waste for disposal as DOE\u2019s agreements with Idaho require the SBW to be removed from the state. However, DOE\u2019s authority to use Order 435.1 and Manual 435.1-1 to classify the SBW and other waste from reprocessing as non-HLW was challenged in a federal lawsuit in 2001, resulting in EM suspending its development of the waste incidental to reprocessing determination. Following the dismissal of the lawsuit on procedural grounds, EM restarted the internal process for developing the waste incidental to reprocessing determination for the SBW, according to EM officials and documents. For example, EM identified the waste incidental to reprocessing determination for the SBW as a priority item for executive decision-making in a 2017 EM study on mission operations. Internal discussions about this determination continued between EM and DOE into 2018, but the waste incidental to reprocessing determination was not finalized, according to EM officials. In October 2018, EM published a notice in the Federal Register seeking public comment on its proposed interpretation of the statutory definition of HLW, which EM officials said could help the agency make a decision about the classification of the SBW. EM also published a supplemental notice in June 2019 to modify the interpretation and provide additional information to the public, such as on the role of the Nuclear Regulatory Commission and states. Table 1 presents the statutory definition, the proposed interpretation from the October 2018 Federal Register notice, and the modified interpretation from the June 2019 Federal Register notice. EM officials told us that under the new interpretation, waste would be disposed of in accordance with its characteristics (which determines risk) instead of solely based on the source of the waste (which does not determine risk). Stakeholders, including members of the public, state and local governments, tribes, and the Nuclear Regulatory Commission, expressed a range of perspectives about EM\u2019s proposed interpretation in public comments. For example, some stakeholders submitted comments expressing concern about the Nuclear Regulatory Commission being excluded from the determination of what is HLW under the interpretation. These comments also stated that the interpretation is contrary to federal law and that the interpretation will elicit legal challenges. Other stakeholders expressed support for the interpretation in comments submitted to EM stating, for example, that the proposed interpretation could accelerate the cleanup of tank waste at DOE sites and result in cost savings. According to an EM document, potential benefits of the interpretation, if implemented, include a more risk-based approach to waste classification, which could provide a more cost-effective and timely approach to DOE\u2019s cleanup mission. However, EM officials stated that it was premature to discuss the administrative actions, such as revising orders or regulations that would be required to implement the new interpretation. The June 2019 Federal Register notice states that DOE will consider what actions may be needed and appropriate to update applicable DOE directives, such as Order 435.1 and Manual 435.1-1, in light of this interpretation and address any revisions in future actions. EM officials also told us that they did not have a timeline for implementing the new interpretation. Further, EM officials stated that if the HLW interpretation is implemented, alternative disposal options could also be considered for the SBW, but they declined to specify what those options could be. Limitations on disposal at WIPP. Further, existing limitations in the disposal space at WIPP could affect the disposal of the SBW at the facility. We reported in September 2017 that DOE does not currently have sufficient disposal space at WIPP for the waste identified in its 2016 annual inventory report\u2014a document that tracks waste intended to be disposed of at the facility. Specifically, DOE will need to expand the repository to accommodate this waste as well as other potential waste, such as the SBW, for which DOE has yet to determine if it meets all of WIPP\u2019s waste acceptance criteria. In March 2019, DOE officials stated that WIPP could be expanded within the current Waste Isolation Pilot Plant Land Withdrawal Act boundary for the site to accommodate the current planned waste and additional waste inventories. Specifically, DOE officials said that mining for a new disposal panel and design work for additional disposal panels was under way, and mining of the additional panel was scheduled to commence in 2021. Further, in September 2017 we also reported that additional potential waste beyond what is captured in the inventory could exceed WIPP\u2019s statutory capacity. However, in December 2018, New Mexico\u2019s Environment Department approved a modification to the WIPP permit\u2014which was requested by DOE and its contractor that operates and manages WIPP\u2014that will change the way waste volume is calculated to exclude empty space inside waste packing. According to DOE officials, this means that additional waste can be disposed of at WIPP under the existing statutory limit. Further, DOE officials stated that the revised counting methodology will reduce an overstatement in the volume of record for emplaced waste by about 30 percent. However, in January 2019 three environmental organizations filed lawsuits challenging the modification, which the court consolidated and, in May 2019, stayed pending mediation. EM officials said that if the office is not able to dispose of the SBW at WIPP, its plan is to dispose of the SBW\u2014once it is treated to a solid form in the IWTU\u2014with the calcine waste in an HLW geologic repository. However, there is still no HLW disposal site in the United States. In 2008, DOE submitted a license application to the Nuclear Regulatory Commission for an HLW repository at Yucca Mountain, Nevada, about 100 miles northwest of Las Vegas. In 2010, however, DOE terminated its efforts to obtain a license for the Yucca Mountain repository. Under the 1995 settlement agreement with the state of Idaho, DOE is required to treat the SBW so that it is ready for disposal outside of the state by a target date of 2035. An EM official responsible for the disposition of the SBW at INL told us that EM has not developed a strategy, including a timeline, for addressing challenges, including the WIPP permit prohibition, the federal law prohibition, and existing capacity limitations, that could affect EM\u2019s ability to meet this target date. According to standards for internal control, federal agency management should identify, analyze, and respond to risks related to achieving a defined objective. Until it develops such a strategy, including a timeline, to implement the actions required to achieve its preferred disposal pathway, or an alternative, for the SBW, EM will not have reasonable assurance that it can achieve its preferred plan for disposal or begin identifying an alternative. Moreover, if EM implements its new interpretation of HLW and uses this definition to classify the SBW as non- HLW, there is significant risk for extended litigation, which may delay to EM\u2019s plans to dispose of the SBW at its preferred disposal site. EM faces challenges implementing its selected treatment technology for calcine waste and faces uncertainties with a waste disposal pathway. As a result, the agency is suspending further development of its plan to treat calcine waste for land disposal, according to EM documents and officials. EM Idaho Cleanup Project officials told us that the agency is continuing to make progress toward its milestones for calcine waste disposal by considering alternatives for processing the waste for land disposal and conducting a pilot project to remove it from the oldest storage vessel. However, EM does not have a strategy or timeline for determining its next steps for the ultimate treatment and disposal of calcine waste. Because of challenges with implementing its chosen treatment technology as well as selecting a potential waste disposal pathway, EM is suspending further development of its plan to treat calcine waste for land disposal, according to EM documents and officials. In December 2009 EM identified hot isostatic pressing as its preferred treatment technology for preparing the calcine waste for land disposal outside of Idaho. Hot isostatic pressing is a manufacturing process that applies elevated temperatures and pressurized gas to materials in a containment vessel, resulting in a ceramic waste form. EM officials from the Idaho Cleanup Project told us that while hot isostatic pressing is a technology used in other industries, such as in industrial manufacturing, it has not been used before to treat HLW. Further, hot isostatic pressing would require a variance or an EPA regulation establishing a new treatment standard prior to land disposal. According to EM Idaho Cleanup Project officials and agency documents, EM selected hot isostatic pressing as the treatment technology because EM\u2019s analyses assumed it would result in significant cost savings for disposal at Yucca Mountain compared to other methods. In February 2011, an independent DOE review team issued a preliminary technology readiness assessment for using hot isostatic pressing for calcine waste treatment as part of DOE\u2019s process for managing capital asset projects. The review team identified several concerns, such as whether components of the technology would be mature enough to meet EM\u2019s planned milestones and challenges with EM\u2019s decision to retrofit and reuse the IWTU for the calcine waste treatment mission. EM officials from the Idaho Cleanup Project said that the decision to retrofit and reuse the IWTU for the calcine waste after treating the SBW resulted from reluctance within DOE to build another \u201cfirst-of-a-kind\u201d treatment facility. However, the review team\u2019s report stated that the decision to retrofit the facility may result in logistical and physical maintenance challenges because of space limitations and height requirements. Based on the results of an independent analysis of alternatives for calcine waste disposition, published in April 2016, EM decided to suspend developing the hot isostatic pressing technology, according to EM officials from the Idaho Cleanup Project. DOE initiated this analysis of alternatives in response to a new requirement from the Secretary of Energy and because hot isostatic pressing is not a mature technology for HLW, according to EM\u2019s summary report for the analysis. The report identified uncertainties and challenges with the use of hot isostatic pressing when compared to other potential treatment options given, including that hot isostatic pressing is significantly different than vitrification and would require the development and acceptance of testing protocols to validate that it produces a robust waste form, hot isostatic pressing had the second greatest estimated cost (more than $2 billion) of the options assessed in the analysis of alternatives, hot isostatic pressing represented the highest operational safety risk of all of the options assessed given its use of high pressures and temperatures, and other treatment options may perform better for managing the waste because of significant advances in technology since the selection of hot isostatic pressing in 2009. The independent team performing this analysis also concluded that uncertainties regarding plans for an HLW geologic repository also affect EM\u2019s ability to move forward with selecting a treatment technology. According to EM officials from the Idaho Cleanup Project and documents, EM\u2019s selection of hot isostatic pressing was based on assumptions developed based on sending the waste to the Yucca Mountain disposal facility. Specifically, an important factor in the selection of hot isostatic pressing as the treatment technology was its ability to provide the lowest volume of final waste, while producing a robust waste form, which would reduce disposal costs at Yucca Mountain. As previously noted, the licensing for developing the Yucca Mountain facility was terminated in 2010. The team performing the analysis of alternatives concluded that because selecting an appropriate treatment technology greatly depends on the calcine waste\u2019s disposal path and associated waste form performance requirements, EM should defer making a final decision on the treatment technology until the performance objectives of the disposal path are better defined. While further decisions regarding a treatment technology for the calcine waste are suspended, EM officials from the Idaho Cleanup Project said that they are taking steps to demonstrate to regulators from Idaho\u2019s Department of Environmental Quality that they are making progress to prepare the calcine waste for disposal outside the state. Under DOE\u2019s 1995 settlement agreement with Idaho, treatment of all calcine waste is to be completed by a target date of December 31, 2035. Further, DOE is required to meet interim milestones for the cleanup of the waste under a site treatment plan that DOE developed for the Idaho Department of Environmental Quality. EM officials from the Idaho Cleanup Project told us that they planned to work with the Idaho Department of Environmental Quality to make changes to milestones specific to calcine waste in the site treatment plan, and Idaho Department of Environmental Quality officials stated in December 2018 that preliminary discussions on this topic occurred in September 2018. Further, EM Idaho Cleanup Project officials identified actions that EM is taking at the site to study alternatives to treatment and aspects of the disposal process. EM officials from the Idaho Cleanup Project stated that with the suspension of developing hot isostatic pressing, they are studying the potential packaging of the calcine waste for disposal without additional treatment, or \u201cdirect disposal.\u201d The analysis of alternatives report identified direct disposal as having significant cost savings over other technologies. However, the team performing the analysis of alternatives also found that this method has a high degree of regulatory uncertainty and it is not clear whether it would be accepted by stakeholders, such as state regulators and the public. EPA officials told us that if EM wanted to proceed with plans for the direct disposal of the calcine waste in a geologic repository, EM would need, among other things, to seek a no-migration variance from EPA. A petition for a no-migration variance must demonstrate, to a reasonable degree of certainty, that the hazardous components would not leak or escape once the HLW is buried underground for as long as the waste remains hazardous. EPA officials added that there is a very high bar for such variances; only one such request has been approved since 1984, and it was later rescinded. In February 2019, an EM Idaho Cleanup Project official told us that EM has met with officials from the Idaho Department of Environmental Quality and EPA to receive their preliminary input on this approach. EM Idaho Cleanup Project officials said that they are focusing in the near term on developing and testing a system to retrieve the calcine waste from its storage vessels, called bin sets. According to EM documents, retrieval of the calcine waste from the bin sets is a precursor to treating or packaging the waste for disposal, and there are several challenges to address in developing an effective retrieval system. As a result, EM directed its contractor to conduct a project to retrieve calcine waste from the oldest bin set and move it to a partially empty bin set under EM\u2019s contract for hazardous waste cleanup at INL. The project serves to both test different forms of technologies and also to cease use of the older bin set, which does not have the same structural integrity as the other bin set because of its design, according to EM officials from the Idaho Cleanup Project and documents. The project is estimated to cost $50 million over 5 years, according to these officials. Fluor Idaho\u2019s plan for the calcine waste retrieval project involves developing a full-scale mock-up of the retrieval process for testing in fiscal years 2019 and 2020, with the commissioning and start-up of the full-scale system and transfer of the waste to occur in fiscal year 2021. In February 2019, an EM official told us that $6 million was obligated to the pilot project in fiscal year 2019 in part because of increased costs for the IWTU reengineering project and cleanup of transuranic waste at INL. Despite these efforts, EM officials from the Idaho Cleanup Project acknowledged that the agency has no plan to issue a new Record of Decision or amend the 2010 Record of Decision selecting the treatment option for calcine waste. Although EM identified challenges with using hot isostatic pressing for the treatment of the calcine waste in its technical readiness assessment in 2011 and analysis of alternatives in 2016, an EM official told us that the agency does not have a strategy for determining its next steps in treating this waste for land disposal. According to standards for internal control, federal agency management should identify, analyze, and respond to risks related to achieving a defined objective. Without developing a strategy, including a timeline, to identify and develop a treatment approach for the calcine waste, EM does not have reasonable assurance that it will meet milestones for the completion of treatment of all calcine by a target date of December 31, 2035. EM has been working since 2005 to construct and operate the IWTU to treat the SBW and calcine waste at INL. Despite declaring construction complete in 2012 at a cost of $571 million, EM is still working to repair and reengineer the IWTU following the discovery of facility problems during testing, with expenditures surpassing $416 million. EM has made progress in identifying the engineering problems plaguing the facility and implementing technical changes and expects to complete the second of the four phases of the reengineering project in mid-2019, with its next series of system testing to begin in early 2020. However, EM has experienced significant cost increases and schedule delays in phase two of the IWTU project, and additional engineering and testing remains to be completed before beginning a multiyear effort to treat the SBW. EM\u2019s ability to achieve the project\u2019s estimated cost and schedule in phase two may have been hampered because EM has not fully followed best practices for ensuring that the cost estimate is complete and the schedule estimate is well-constructed. By ensuring that the cost estimate for future phases of the IWTU reengineering project and the SBW treatment operations is comprehensive (e.g., account for all possible costs), EM will have greater assurance that it can successfully plan program resource requirements. Moreover, by developing a well-constructed schedule estimate for the IWTU reengineering project and the SBW treatment operations, EM will have greater assurance that it can successfully achieve its plans to reengineer the IWTU and begin treatment of the SBW without further delays. Further, while EM is using an EVM system to measure the performance of the project and generally followed best practices for EVM systems, the system produces unreliable data. By following best practices for ensuring EVM data reliability for the IWTU reengineering project\u2019s EVM system, EM leadership will have better access to reliable performance data as it manages billions of dollars\u2019 worth of cleanup work and provides information to Congress and other stakeholders on the cleanup work every year. EM faces long-standing challenges to implementing its preferred alternative for disposing of the treated SBW at WIPP. Key among these challenges are provisions in federal law and the WIPP permit that prevent EM from disposing of the SBW at WIPP. EM has taken some steps toward addressing these challenges, such as seeking public comment on its new interpretation of the statutory definition of HLW that according to EM could allow the waste to be disposed of at WIPP or an alternative to an HLW geologic repository. However, EM has no strategy or timeline for making any changes to DOE policies and regulations that may be required to implement its new interpretation or for making decisions regarding disposing of the SBW. Until it develops such a strategy, including a timeline, to implement the actions required to achieve its preferred disposal pathway, or an alternative, for the SBW, EM will not have reasonable assurance that it can achieve its preferred plan for disposal or begin the process of identifying an alternative. Further, if EM implements its new interpretation of HLW and uses this definition to classify the SBW as non-HLW, there is significant risk for extended litigation, which may delay EM\u2019s plans to dispose of the SBW at its preferred disposal site. Moreover, EM faces challenges in completing treatment of the calcine waste by a target date of December 31, 2035, in light of its decision to suspend development of the selected treatment technology, hot isostatic pressing, and the absence of an HLW geologic repository. Even though EM is studying alternatives to using hot isostatic pressing to prepare the calcine waste for disposal, it has not developed a strategy or a timeline for determining its plans for treating this waste for disposal. Without developing such a strategy, including a timeline, for the treatment and disposal of the calcine waste to ensure that EM meets the milestone for completing the treatment of the waste by December 31, 2035, EM does not have reasonable assurance that it can meet its milestones. We are making five recommendations to DOE: The Secretary of Energy should direct the Assistant Secretary of EM to develop cost estimates for the IWTU reengineering project and the SBW treatment operations that meet best practices for being comprehensive (e.g., account for all costs). (Recommendation 1) The Secretary of Energy should direct the Assistant Secretary of EM to develop schedule estimates for the IWTU reengineering project and the SBW treatment operations that meet best practices for being well- constructed. (Recommendation 2) The Secretary of Energy should direct the Assistant Secretary of EM to follow best practices for ensuring the reliability for the IWTU reengineering project\u2019s EVM system. (Recommendation 3) The Secretary of Energy should direct the Assistant Secretary of EM to develop a strategy, including a timeline, for implementing the actions required to achieve its preferred disposal pathway, or an alternative, for the SBW. (Recommendation 4) The Secretary of Energy should direct the Assistant Secretary of EM to develop a strategy, including a timeline, to identify and develop a treatment approach for the disposal of the calcine waste to ensure that EM meets the milestone for completing the treatment of this waste by the target date of December 31, 2035. (Recommendation 5) We provided a draft of this report for review and comment to the Secretary of Energy and the Administrator of the EPA. DOE provided written comments on the draft report, which are presented in appendix IV. EPA did not provide written comments. DOE and EPA both provided technical comments that we incorporated in the report as appropriate. DOE agreed with our recommendations related to the management of the IWTU reengineering project, including developing cost and schedule estimates that meet best practices and ensuring the reliability of the EVM system for the project. Regarding the cost estimate, DOE committed to developing cost estimates that meet best practices and stated that cost estimates for phases three and four of the IWTU reengineering project have been developed and reviewed by the Defense Contract Audit Agency. For the schedule estimate, DOE stated that the schedules for phases three and four have been developed and that the inclusion of these phases in the schedule is in accordance with best practices for the well-constructed characteristic. With regard to the EVM system, DOE stated that cost and performance data will be included in the EVM system in accordance with EVM best practices once contract negotiations are completed, which the agency estimated would conclude by December 31, 2019. DOE also agreed with our recommendations to develop a strategy, including a timeline, for the disposal of the SBW and calcine waste. DOE further stated that EM is in the process of developing a site options analysis for INL and other EM sites to identify opportunities to complete cleanup work through more efficient and innovative approaches over the next decade. This analysis is expected to be completed in fiscal year 2020, according to DOE. DOE stated that EM\u2019s HLW interpretation issued in June 2019 could potentially open new disposal pathways for some reprocessing waste, such as SBW and calcine, while noting that decisions about whether and how this interpretation will apply to existing wastes have yet to be made. In its written comments, DOE disagreed with our recommendation to seek clarification from Congress on DOE\u2019s authority to classify the SBW as other than HLW if such clarification is necessary to avoid extended litigation. DOE stated the agency does not require additional clarification from Congress to classify reprocessing waste as other than HLW. We are deleting our recommendation but continue to believe that there is significant risk for extended litigation if EM implements its new interpretation of HLW and uses this definition to classify the SBW as non- HLW. Extended litigation may delay EM\u2019s plans to dispose of the SBW at its preferred disposal site. We are sending copies of this report to the appropriate congressional committees, the Secretary of Energy, the Administrator of the Environmental Protection Agency, and other interested parties. In addition, the report is available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact me at (202) 512-3841 or trimbled@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made significant contributions to this report are listed in appendix V. Our report examines (1) the extent to which the Department of Energy\u2019s (DOE) Office of Environmental Management\u2019s (EM) management of the Integrated Waste Treatment Unit (IWTU) reengineering project follows selected project management best practices; (2) challenges EM faces in the disposal of the sodium-bearing waste (SBW); and (3) challenges EM faces in the treatment and disposal of the calcine waste. To address these three objectives, we conducted a site visit to DOE\u2019s Idaho National Laboratory (INL) in December 2017. During the site visit, we obtained documentation and interviewed officials from EM, which is responsible for hazardous waste cleanup at INL through its Idaho Cleanup Project. We also interviewed representatives from Fluor Idaho, LLC, which is the private contractor that manages hazardous waste cleanup at INL for EM, including the cleanup of the SBW and calcine waste. In addition, we conducted a site visit to Hazen Research, Inc., a subcontractor to Fluor Idaho, to observe pilot testing facilities for the IWTU reengineering project and discuss the status of the project with an EM official from the Idaho Cleanup Project and representatives from Hazen Research, Inc., and Fluor Idaho. To assess the extent to which EM\u2019s management of the IWTU reengineering project meets selected project management best practices, we first identified areas deemed to be important to project management based on our previous work on DOE projects and leading practices from the Project Management Institute, which are generally recognized as leading practices for project management. Specifically, we reviewed the project management leading practices identified in the Project Management Institute\u2019s A Guide to the Project Management Body of Knowledge\u2014Sixth Edition. From this review, we selected project management practices related to developing cost and schedule estimates and conducting project monitoring through the use of earned value management (EVM) and independent reviews. We then conducted assessments of these best practices, as discussed below. Cost. To determine the extent to which the cost estimate for the IWTU reengineering project is reliable, we conducted an abridged analysis of the IWTU reengineering project\u2019s cost estimate, focusing on its comprehensiveness. Typically, in analyzing a cost estimate against best practices in GAO\u2019s Cost Estimating and Assessment Guide (cost guide), we examine four characteristics, each defined by multiple criteria: credible. For this review, we assessed the cost estimate for the IWTU reengineering project against the comprehensive characteristic, in part because EM officials told us that they had yet to develop a cost estimate for the program beyond phases one and two at the time of our review. Specifically, we reviewed the cost estimate for the operation of the IWTU and the IWTU reengineering project, which, at the time of our review, was only developed for phases one and two of the project. If a cost estimate is not comprehensive (that is, complete), then it cannot fully meet the well- documented, accurate, or credible best practice characteristics. For instance, if the cost estimate is missing some cost elements, then the documentation will be incomplete, the estimate will be inaccurate, and the result will not be credible because of the potential underestimating of costs and the absence of a full risk and uncertainty analysis. See appendix II for a summary assessment of the IWTU reengineering project\u2019s cost estimate compared to selected best practices. Schedule. To assess EM\u2019s schedule for the IWTU reengineering project, we conducted an abridged analysis of the IWTU reengineering project\u2019s schedule, focusing on comprehensiveness and the degree to which it is well-constructed. Typically, in analyzing a schedule estimate against best practices in GAO\u2019s Schedule Assessment Guide (schedule guide), we examine four characteristics, each defined by multiple criteria: controlled. For this review, we assessed the IWTU reengineering project schedule that EM provided in March 2018 against the well-constructed characteristic, in part because EM officials told us that they had yet to develop a schedule estimate for the totality of the reengineering project because of Fluor Idaho\u2019s phased approach. If a schedule estimate is not well-constructed, it will not be able to properly calculate dates and predict changes in the future. When activities are missing logic links, the schedule will not be able to automatically transmit these delays to future activities that depend on them. When this happens, the schedule will not allow a sufficient understanding of the program as a whole, and users of the schedule will not have confidence in the dates and the critical path. In addition, we evaluated the comprehensive characteristic because it contributed to our analysis of EM\u2019s EVM system, as described below. See appendix II for a summary assessment of the IWTU reengineering project\u2019s schedule estimate compared to selected best practices. EVM. In addition, we analyzed EM\u2019s use of EVM as a way to assess its monitoring of the IWTU reengineering project\u2019s cost and schedule. EVM measures the value of work accomplished in a given period and compares it with the planned value of work scheduled for the period and with the actual cost of the work accomplished. It is an industry standard and is considered a best practice for conducting cost and schedule performance analysis for projects. Our EVM analysis focused on Fluor Idaho\u2019s EVM data for the IWTU reengineering project contained in cost performance reports from March 2017 to February 2018 and the project schedule that EM provided in March 2018. Specifically, we compared this project documentation with EVM best practices as identified in our cost guide. Our research has identified a number of best practices that are the basis of effective EVM and should result in reliable and valid data that can be used for making informed decisions. These best practices have been collapsed into three high-level characteristics of a reliable EVM system, which are establish a comprehensive EVM system, ensure that the data resulting from the EVM system are reliable, and ensure that the program management team is using EVM data for decision-making purposes. See appendix III for our summary assessment of the IWTU reengineering project\u2019s EVM data compared to best practices. EVM data are considered reliable if the overall assessment ratings for each of the three characteristics are substantially or fully met. If any of the characteristics are not met, minimally met, or partially met, then the EVM data cannot be considered reliable. Independent reviews. To assess the extent to which DOE has conducted independent reviews of the IWTU reengineering project, we examined DOE and EM policies to identify requirements for conducting reviews of operations activities. Specifically, we reviewed a 2016 DOE memorandum that established that DOE\u2019s Project Management Risk Committee (PMRC) would provide independent review of selected projects in the operational release phase, the PMRC\u2019s standard operating procedures, and EM\u2019s guidance for projects in the operational release milestone. We examined documentation from the PMRC\u2019s reviews of the IWTU reengineering project, including documentation that EM officials from the Idaho Cleanup Project prepared for these reviews and recommendations that the PMRC made to EM for the project. In addition, we spoke with officials from DOE\u2019s Office of Project Management, which serves as the secretariat of the PMRC; EM\u2019s Office of Acquisition & Project Management; and EM\u2019s Idaho Cleanup Project about independent reviews of projects in the operational release phase. To examine challenges EM faces in the disposal of the SBW, we reviewed federal laws, regulations, and DOE policies on radioactive waste management, including those described in DOE Order 435.1 on radioactive waste management and its implementation manual. In addition, we examined EM\u2019s October 2018 and June 2019 Federal Register notices, which provide DOE\u2019s new interpretation of the statutory definition of high-level radioactive waste (HLW). We also reviewed documentation related to EM\u2019s plans for disposing of the SBW at DOE\u2019s Waste Isolation Pilot Plant (WIPP) in New Mexico, such as Record of Decision documents for proposed actions that require development of environmental impact statements, and the hazardous waste facility permit for WIPP that the New Mexico Environment Department issued. We interviewed DOE officials from the Office of the General Counsel; officials from EM\u2019s Idaho Cleanup Project and Carlsbad Field Office, which is responsible for DOE\u2019s oversight of WIPP; and officials from EM\u2019s Office of Regulatory Compliance, Office of Nuclear Materials, and Office of Waste and Materials Management. We also interviewed officials from Idaho\u2019s Department of Environmental Quality and New Mexico\u2019s Environment Department, as well as representatives from two environmental advocacy groups in Idaho and New Mexico, to obtain their perspectives on the challenges facing EM\u2019s SBW disposal efforts. To examine challenges EM faces in the treatment and disposal of the calcine waste, we reviewed federal laws, regulations, and documents that DOE and EM\u2019s contractors for the Idaho Cleanup Project prepared related to the calcine waste cleanup mission. For example, we reviewed documents assessing treatment and disposal alternatives for calcine waste, including a 2016 analysis of alternatives report that EM prepared and a 2015 contractor-prepared report assessing the feasibility of the direct disposal of calcine waste. We interviewed officials from EM\u2019s Idaho Cleanup Project and Office of Nuclear Materials; EM\u2019s Chief Engineer; and representatives from EM\u2019s contractor, Fluor Idaho, about plans for treating and disposing of the calcine waste and the retrieval pilot project. In addition, we reviewed Environmental Protection Agency (EPA) Resource Conservation and Recovery Act, as amended (RCRA) regulations, guidance, and documents concerning land disposal requirements. We also interviewed officials from EPA\u2019s Office of Land and Emergency Management and Region 10 about EPA\u2019s responsibilities for implementing RCRA. Lastly, we interviewed officials from the Idaho Department of Environmental Quality about how EM\u2019s calcine waste treatment and disposal efforts address milestones in the Idaho Settlement Agreement. We conducted this performance audit from September 2017 to September 2019 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. Table 2 describes the initial cost and schedule estimates for the four phases of the Integrated Waste Treatment Unit reengineering project compared to actual expenditures and schedule as of February 2019. Table 3 details our assessment of the Office of Environmental Management\u2019s (EM) cost estimate for phases one and two of the Integrated Waste Treatment Unit (IWTU) reengineering project compared to selected best practices for cost estimating published in GAO\u2019s Cost Estimating and Assessment Guide (cost guide). For this review, we assessed the cost estimate for the IWTU reengineering project against the comprehensive characteristic, in part because EM officials told us that they had yet to develop a cost estimate for the program beyond phases one and two, at the time of our review of these documents. We assessed the comprehensive characteristic for the IWTU reengineering cost estimate because if a cost estimate is not comprehensive\u2014that is, complete\u2014then it cannot fully meet the other best practice characteristics. According to our analysis, EM\u2019s cost estimate for the IWTU reengineering project partially met best practices for a comprehensive cost estimate. Table 4 details our assessment of EM\u2019s schedule for the IWTU reengineering project compared to selected best practices for project schedules published in GAO\u2019s Schedule Assessment Guide (schedule guide). For this review, we assessed the schedule against the well- constructed characteristic, in part because EM officials told us that they had yet to develop a schedule for the totality of the reengineering project because of the contractor\u2019s phased approach. We assessed the well- constructed characteristic because, among other reasons, if a schedule is not well-constructed, it will not be able to properly calculate dates and predict changes in the future. In addition, we evaluated the comprehensive characteristic as it is needed to evaluate an earned value management system. According to our assessment, EM\u2019s schedule for the reengineering project partially met best practices related to the well- constructed characteristic and substantially met best practices related to the comprehensive characteristic. Table 5 details our assessment of March 2017 to February 2018 data from the Department of Energy\u2019s (DOE) Office of Environmental Management\u2019s (EM) earned value management (EVM) system for the Integrated Waste Treatment Unit (IWTU) reengineering project. EVM measures the value of work accomplished in a given period and compares it with the planned value of work scheduled for that period and with the actual cost of work accomplished. By using the metrics derived from these values to understand performance status and to estimate cost and time to complete, EVM can alert program managers to potential problems sooner than expenditures alone can. Our research has identified a number of best practices that are the basis of effective EVM and should result in reliable and valid EVM data that can be used for making informed decisions. Specifically, EM followed (i.e., substantially met) best practices to ensure that its EVM system is (1) comprehensive and (2) used by leadership for decision-making, but did not follow (i.e., partially met) best practices to ensure that the data resulting from the EVM system are reliable. In addition to the contact named above, Casey L. Brown (Assistant Director), Emily Ryan (Analyst in Charge), Juan\u00e1 Collymore, Jennifer Echard, Richard P. Johnson, Jason Lee, Eli Lewine, Katrina Pekar- Carpenter, Karen Richey, Jeanette Soares, Sheryl Stein, Farrah M. Stone, Paul Sturm, and Sara Sullivan made key contributions to this report.", "summary": "Decades of defense activities at DOE's Idaho National Laboratory produced two forms of waste that EM has managed as HLW: liquid SBW and granular calcine waste. Under an agreement with the state, DOE must treat the waste to prepare it for removal from Idaho by 2035. Construction on the IWTU, EM's facility to treat such waste, was completed in 2012, but initial testing of the SBW treatment process revealed design problems. EM has since been working to reengineer the IWTU. Total project construction and reengineering expenditures have reached nearly $1 billion as of February 2019. GAO was asked to review EM's efforts to treat and dispose of the SBW and calcine waste. This report examines (1) the extent to which EM's management of the IWTU follows selected project management best practices; (2) challenges EM faces in disposing of the SBW; and (3) challenges EM faces in treating and disposing of the calcine waste. GAO reviewed agency documents and IWTU project data from March 2017 through February 2018, analyzed EM project management efforts against selected project management best practices for cost and schedule, and interviewed DOE officials. The Department of Energy's (DOE) Office of Environmental Management (EM) has not fully followed selected project management best practices in managing the reengineering of the Integrated Waste Treatment Unit (IWTU), shown in the figure, to treat 900,000 gallons of liquid sodium-bearing waste (SBW) that must be solidified for disposal. EM's cost and schedule estimates for IWTU reengineering did not fully meet selected best practices for cost (i.e., did not account for all costs) and schedule estimates (e.g., did not have a valid critical path). For example, EM did not follow best practices for a comprehensive cost estimate because EM did not include both government and contractor costs over the entire project. As of February 2019, EM has experienced approximately $64 million in added costs and a more than 1-year delay in IWTU reengineering. Without fully following best practices for cost and schedule estimates, EM is at risk of future cost overruns and delays in meeting its target disposal milestones. Based on GAO's review of EM documents, EM faces challenges with its plans for SBW disposal at its preferred disposal site, the Waste Isolation Pilot Plant (WIPP), an underground repository for waste contaminated by nuclear elements, near Carlsbad, New Mexico. These challenges include a statutory prohibition on the disposal of high-level waste (HLW) at WIPP. Further, EM does not have a strategy or timeline to address these challenges or to identify an alternative disposal pathway. Without such a strategy or timeline, EM risks not meeting its commitments with Idaho to prepare the SBW for removal from the state by 2035. EM faces challenges implementing its selected technology to further treat 1.2 million gallons of granular calcine waste and selecting a potential waste disposal pathway. For example, DOE has identified challenges with retrofitting the IWTU for calcine waste treatment. As a result, EM is deferring further development of its plans to treat the calcine waste. EM officials said that the agency is making progress toward calcine waste disposal by testing options for removing the waste from its storage bins, a precursor to treating or packaging the waste for disposal. However, EM does not have a strategy or timeline for determining its next steps for the treatment and disposal of calcine waste. Such a strategy could help EM in seeking alternatives to its selected treatment technology and provide assurance that it will meet its commitments with Idaho for removing calcine waste from the state by the end of 2035. GAO is making five recommendations, including that DOE develop a strategy for the disposal of the waste. DOE generally agreed with all of these recommendations."}
{"id": "govreport_5", "report": "Consistent with the discretion afforded by the APA, Regulations.gov and agency-specific comment websites use required and optional fields on comment forms to collect some identity information from commenters. In addition to the text of the comment, agencies may choose to collect identity information by requiring commenters to fill in other fields, such as name, address, and email address before they are able to submit a comment. Regardless of the fields required by the comment form, the selected agencies all accept anonymous comments in practice. Specifically, in the comment forms on Regulations.gov and agency- specific comment websites, a commenter can submit under a fictitious name, such as \u201cAnonymous Anonymous,\u201d enter a single letter in each required field, or provide a fabricated address. In each of these scenarios, as long as a character or characters are entered into the required fields, the comment will be accepted. Further, because the APA does not require agencies to authenticate submitted identity information, neither Regulations.gov nor the agency-specific comment websites contain mechanisms to check the validity of identity information that commenters submit through comment forms. Regulations.gov and agency-specific comment websites also collect some information about public users\u2019 interaction with their websites through application event logs and proxy server logs, though the APA does not require agencies to collect or verify it as part of the rulemaking process. This information, which can include a public user\u2019s Internet Protocol (IP) address, browser type and operating system, and the time and date of webpage visits, is collected separately from the comment submission process as part of routine information technology management for system security and performance, and cannot be reliably connected to specific comments. Seven of the 10 selected agencies have documented some internal guidance associated with the identity of commenters during the three phases of the public comment process: intake, analysis, and response to comments. However, the focus and substance of this guidance varies by agency and phase of the comment process. As shown in Table 1, for selected agencies that have guidance associated with the identity of commenters, it most frequently relates to the comment intake or response to comment phases of the public comment process. The guidance for these phases addresses activities such as managing duplicate comments (those with identical or near-identical comment text but varied identity information) or referring to commenters in a final rule. Agencies are not required by the APA to develop internal guidance associated with the public comment process generally, or identity information specifically. Within the discretion afforded by the APA, the 10 selected agencies\u2019 treatment of identity information varies during the three phases of the public comment process. Selected agencies differ in how they treat identity information during the comment intake phase, particularly in terms of how they post duplicate comments, which can lead to identity information being inconsistently presented to public users of comment systems. Generally, officials told us that their agencies either (1) maintain all comments within the comment system, or (2) maintain some duplicate comment records outside of the comment system, for instance, in email file archives. When an agency chooses to post a sample of duplicate comments, the identity information and unique comment contents for all duplicate comments may not be present on the public website. For example, for all duplicate comments received, Securities and Exchange Commission (SEC) posts a single example for each set of duplicate comments and indicates the total number of comments received. As a result, the identity information and any unique comment content beyond the first example are not present on the public website. (See fig. 1.) Selected agencies\u2019 treatment of identity information during the comment analysis phase also varies. Specifically, program offices with the responsibility for analyzing comments place varied importance on identity information during the analysis phase. Finally, all agencies draft a response to comments with their final rule, but the extent to which the agencies identify commenters or commenter types in their response also varies across the selected agencies. Our analysis of Regulations.gov and agency-specific comment websites shows that the varied comment posting practices of the 10 selected agencies are not always documented or clearly communicated to public users of the websites. The E-Government Act of 2002 requires that all public comments and other materials associated with a given rulemaking should be made \u201cpublicly available online to the extent practicable.\u201d In addition to the requirements of the E-Government Act, key practices for transparently reporting open government data state that federal government websites\u2014like those used to facilitate the public comment process\u2014should fully describe the data that are made available to the public, including by disclosing data sources and limitations. We found that the selected agencies we reviewed do not effectively communicate the limitations and inconsistencies in how they post identity information associated with public comments. As a result, public users of the comment websites lack information related to data availability and limitations that could affect their ability to use and make informed decisions about the comment data and effectively participate in the rulemaking process themselves. Public users of Regulations.gov seeking to submit a comment are provided with a blanket disclosure statement related to how their identity information may be disclosed, and are generally directed to individual agency websites for additional detail about submitting comments. While additional information is provided in the Privacy Notice, User Notice, and Privacy Impact Assessment for Regulations.gov, public users are not provided any further detail on Regulations.gov regarding what information, including identity information, they should expect to find in the comment data. Additionally, there is not enough information to help public users determine whether all of the individual comments and associated identity information are posted. Available resources on Regulations.gov direct public users to participating agencies\u2019 websites for additional information about agency-specific review and posting policies. Seven of the eight participating agencies\u2019 websites direct public users back to Regulations.gov and the Federal Register, either on webpages that are about the public comment process in general, or on pages containing information about specific NPRMs. Three of these participating agencies \u2013 the Environmental Protection Agency (EPA), the Fish and Wildlife Service (FWS), and the Food and Drug Administration (FDA) \u2013 do provide public users with information beyond directing them back to Regulations.gov or the Federal Register, but only FDA provides users with details about posting practices that are not also made available on Regulations.gov. The eighth participating agency \u2013 the Employee Benefits Security Administration (EBSA) \u2013 does not direct public users back to Regulations.gov, and instead recreates all rulemaking materials for each NPRM on its own website, including individual links to each submitted comment. However, these links go directly to comment files, and do not link to Regulations.gov. While EBSA follows departmental guidance associated with posting duplicate comments, which allows some discretion in posting practices, the agency does not have a policy for how comments are posted to Regulations.gov or its own website. Further, in the examples we reviewed, the content of the NPRM-specific pages on EBSA\u2019s website does not always match what is posted to Regulations.gov. Because participating agencies are not required to adhere to standardized posting practices, Regulations.gov directs public users to participating agency websites for additional information about posting practices and potential data limitations. However, these websites do not describe the limitations associated with the identity information contained in publicly posted comments. As allowed for under the APA, all of the participating agencies in our review vary in the way in which they post identity information associated with comments\u2014particularly duplicate comments. However, the lack of accompanying disclosures may potentially lead users to assume, for example, that only one entity has weighed in on an issue when, actually, that comment represents 500 comments. Without better information about the posting process, the inconsistency in the way in which duplicate comments are presented to public users of Regulations.gov limits public users\u2019 ability to explore and use the data and could lead users to draw inaccurate conclusions about the public comments that were submitted and how agencies considered them during the rulemaking process. Both nonparticipating agencies use comment systems other than Regulations.gov and follow standardized posting processes associated with public comments submitted to their respective comment systems, but SEC has not clearly communicated these practices to the public. Although it appears to users of the SEC website that the agency follows a consistent process for posting duplicate comments, at the time of our June 2019 report, this practice had not been documented or communicated to public users of its website. In contrast, FCC identifies its policies for posting comments and their associated identity information in a number of places on the FCC.gov website, and on its Electronic Comment Filing System (ECFS) web page within the general website. Regarding comments submitted to rulemaking proceedings through ECFS, public users are informed that all information submitted with comments, including identity information, will be made public. Our review of ECFS comment data did not identify discrepancies with this practice. Although the public comment process allows interested parties to state their views about prospective rules, the lack of communication with the public about the way in which agencies treat identity information during the posting process, particularly for duplicate comments, may inhibit users\u2019 meaningful participation in the rulemaking process. While the APA does not include requirements for commenters to provide identity information, or for agency officials to include commenters identity as part of their consideration of comments, key practices for transparently reporting open government data state that federal government websites\u2014 like those used to facilitate the public comment process\u2014should fully describe the data that are made available to the public, including by disclosing data sources and limitations. As shown in Table 2, we recommended in our June 2019 report that five of the selected agencies establish a policy for posting comments, and that eight selected agencies take action to more clearly communicate their policies for posting comments, particularly with regard to identity information and duplicate comments. These agencies generally agreed with our recommendations and identified actions they planned to take in response, such as developing policies for posting duplicate comments and communicating those in various ways to public users. Since issuing our June 2019 report, all of the agencies to which we made recommendations have provided us with additional updates. Specifically, SEC completed actions that are responsive to the recommendation we made to it. In this regard, in September 2019, SEC issued a memorandum that reflects SEC\u2019s internal policies for posting duplicate comments and associated identity information. SEC has also communicated these policies to public users on the SEC.gov website by adding a disclaimer on the main comment posting page that describes how the agency posts comments. These measures will help public users better determine whether and how they can use the data associated with public comments. The other seven agencies have provided updates, but have not yet implemented the recommendations. In December 2019 and January 2020, the Bureau of Land Management (BLM), Consumer Financial Protection Bureau (CFPB), EPA, and FWS notified us that they are in the process of developing or updating policies for posting public comments as well as statements for their websites to communicate these policies to the public. Similarly, in January 2020, the Department of Health and Human Services (HHS) stated that the Centers for Medicare and Medicaid Services (CMS) would update its comment posting policy and communicate it on the CMS website. However, the excerpt of the policy language provided does not include information about how the agency posts duplicate comments. Further, CMS did not provide us with the finalized policy, and our review of the website does not indicate any changes have been made. HHS officials stated they would provide additional follow up actions by July 2020. In September 2019, EBSA also stated that it will develop a written policy regarding posting of comments, including duplicate comments, which will be available on its website. However, the agency did not provide evidence that a formal evaluation of its current practice of replicating rulemaking dockets had been conducted, and did not identify plans to do so. The Wage and Hour Division (WHD) indicated that it will add text to each webpage for any rulemaking that invites public comments that states any personal information included in the comments (including duplicate) will be posted to Regulations.gov without change. However, the preliminary text provided by officials in August 2019 does not explain WHD\u2019s policy of posting duplicate comments as a group under a single document ID, and therefore does not clearly communicate the agency\u2019s posting practices to the public. Chairman Green, Ranking Member Barr, and Members of the Subcommittee, this concludes my prepared remarks. I would be happy to answer any questions you may have at this time. For further information regarding this testimony, please contact Seto J. Bagdoyan, (202) 512-6722 or bagdoyans@gao.gov. In addition, contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this statement. Individuals who made key contributions to this testimony are David Bruno (Assistant Director), Allison Gunn (Analyst in Charge), Elizabeth Kowalewski, and Roger Gildersleeve. Individuals who contributed to the report on which this testimony is based include Enyinnaya David Aja, Gretel Clarke, Lauren Kirkpatrick, James Murphy, Alexandria Palmer, Carl Ramirez, Shana Wallace, and April Yeaney. This is a work of the U.S. government and is not subject to copyright protection in the United States. The published product may be reproduced and distributed in its entirety without further permission from GAO. However, because this work may contain copyrighted images or other material, permission from the copyright holder may be necessary if you wish to reproduce this material separately.", "summary": "Federal agencies publish on average 3,700 proposed rules yearly and are generally required to provide interested persons (commenters) an opportunity to comment on these rules. In recent years, some high-profile rulemakings have received extremely large numbers of comments, raising questions about how agencies manage the identity information associated with comments. While the APA does not require the disclosure of identifying information from a commenter, agencies may choose to collect this information. This testimony summarizes GAO's June 2019 report on public comment posting practices (GAO-19-483). In that report, GAO examined (1) the identity information collected by comment websites; (2) the guidance agencies have related to the identity of commenters; (3) how 10 selected agencies treat identity information; and (4) the extent to which the selected agencies clearly communicate their practices associated with identity information. The 10 agencies were selected on the basis of the volume of public comments they received on rulemakings. For this testimony, GAO obtained updates on the status of recommendations made to the selected agencies. The Administrative Procedure Act (APA) governs the process by which many federal agencies develop and issue regulations, which includes the public comment process (see figure below). In June 2019, GAO found that Regulations.gov and agency-specific comment websites collect some identity information\u2014such as name, email, or address\u2014from commenters who choose to provide it during the public comment process. The APA does not require commenters to disclose identity information when submitting comments. In addition, agencies have no obligation under the APA to verify the identity of such parties during the rulemaking process, and all selected agencies accept anonymous comments in practice. GAO found in the June 2019 report that seven of 10 selected agencies have some internal guidance associated with the identity of commenters, but the substance of this guidance varies. This reflects the differences in the way that the selected agencies handle commenter identity information internally. GAO also found that the selected agencies' practices for posting public comments to comment websites vary considerably, particularly for duplicate comments (identical or near-identical comment text but varied identity information). For example, one agency posts a single example of duplicate comments and indicates the total number of comments received, but only the example is available to public users of Regulations.gov. In contrast, other agencies post all comments individually. As a result, identity information submitted with comments is inconsistently presented on public websites. The APA allows agencies discretion in how they post comments, but GAO found that some of the selected agencies do not clearly communicate their practices for how comments and identity information are posted. GAO's key practices for transparently reporting government data state that federal government websites should disclose data sources and limitations to help public users make informed decisions about how to use the data. If not, public users of the comment websites could reach inaccurate conclusions about who submitted a particular comment, or how many individuals commented on an issue. In June 2019, GAO made recommendations to eight of the selected agencies regarding implementing and communicating public comment posting policies. The agencies generally agreed with the recommendations and identified actions they planned to take in response. Since the June 2019 report, one agency has implemented GAO's recommendation and seven agencies have identified additional planned actions."}
{"id": "govreport_6", "report": "To be eligible for the Medicare hospice benefit, an individual must be eligible for Medicare Part A (which covers inpatient care) and be medically certified as having a terminal illness with a life expectancy of 6 months or less if the illness runs it normal course. For individuals to receive care from a Medicare-approved hospice program, they must elect the hospice benefit by signing a statement indicating they are waiving their rights to Medicare payment for services related to curative treatment of their terminal illness. When enrolling in Medicare hospice care, beneficiaries can receive several different types of services in various settings. Most hospice beneficiaries receive hospice care in their own home, but they can also receive care in other settings, such as a nursing home, assisted living facility, hospice facility, or hospital. The Medicare hospice benefit covers a variety of services and supplies for the palliation and management of the terminal illness, including physician and nursing services, medical equipment and supplies including drugs for pain and symptom management, hospice aide and homemaker services, physical and occupational therapy, and spiritual and grief and loss counseling. A hospice interdisciplinary team (in collaboration with the beneficiary\u2019s primary care provider, if any) works with the beneficiary, family, and caregiver(s) to develop a plan of care that addresses the physical, psychosocial, spiritual, and emotional needs of the beneficiary, family members, and caregiver(s). The hospice provider must make all services under the Medicare hospice benefit available to beneficiaries as needed, 24 hours a day, 7 days a week. Although hospice care is designed for beneficiaries with a life expectancy of 6 months or less, beneficiaries can receive hospice care beyond 6 months if they continue to meet hospice eligibility requirements. In addition, beneficiaries can disenroll from the hospice benefit at any time and re-enroll in hospice care at a later time. CMS pays hospices based on the level of hospice care provided to beneficiaries on a given day. There are four levels of hospice care, which are paid at either a daily rate or an hourly rate depending on the location and intensity of services provided. (See table 1.) Each care level has a payment rate that is adjusted for geographic differences in wages, and CMS updates these payment rates annually. The most common level of care is called routine home care (accounting for 98 percent of all Medicare hospice care in 2017), and hospices receive the routine home care payment daily rate regardless of whether beneficiaries receive any services on a given day. In addition, CMS imposes two payment limitations (referred to as caps) on Medicare payment for hospice services\u2014one that limits a hospice\u2019s number of inpatient days and one that limits a hospice\u2019s total Medicare payments in a given year. In response to requirements in the Patient Protection and Affordable Care Act, CMS established the Hospice Quality Reporting Program, which currently includes two sets of data to assess the quality of hospice providers\u2019 care; CMS publishes these data on its Hospice Compare website. Medicare hospice providers are required to submit these data to CMS for all patients regardless of payer source (e.g., Medicare, Medicaid, or private insurance). The two data sets are the following: Provider-reported quality measure data. This set of data (which CMS refers to as the Hospice Item Set) is used to calculate a hospice provider\u2019s performance on quality measures, which include seven measures that reflect the percentage of all hospice patients\u2019 stays where the provider completed various key care processes, such as screening patients for pain and shortness of breath. CMS also recently implemented an eighth measure, called the composite measure, which calculates the percentage of patients\u2019 hospice stays in which the hospice provider completed all seven care process quality measures. Caregivers\u2019 experience survey data. This set of data (referred to as the Consumer Assessment of Healthcare Providers and Systems (CAHPS\u00ae) Hospice Survey) is a national survey that captures, from the caregiver\u2019s (family member or friend) perspective, the patient\u2019s experience with hospice care. The survey includes questions that are used to calculate eight quality measures based on survey responses. For example, one measure scores how well the hospice communicated with the patient\u2019s family. CMS oversees the quality of Medicare hospice care primarily through inspections\u2014referred to as surveys\u2014which are conducted by state survey agencies contracted by CMS or CMS-approved national private accrediting organizations. These surveys are used to determine whether the hospice is in compliance with federal health and safety requirements detailed in Medicare\u2019s hospice conditions of participation. A hospice must be in compliance with these conditions to participate in the Medicare program. Medicare\u2019s hospice conditions of participation include requirements related to patient care and organizational environment (e.g., the hospice must organize, manage, and administer its resources to provide necessary care). Each condition of participation is composed of standards associated with the condition, and a standard may have associated sub-components. For example, the \u201cpatient\u2019s rights\u201d condition includes standards such as \u201cnotice of rights and responsibilities\u201d and \u201crights of the patient.\u201d The \u201crights of the patient\u201d standard includes sub- components, such as the patient has the right to receive effective pain management and symptom control. There are three main types of survey inspections\u2014an initial certification survey when a provider first seeks to participate in Medicare; a re- certification survey to ensure ongoing compliance; and surveys to investigate complaints or incidents related to federal requirements. If a hospice is found to be out of compliance with hospice health and safety requirements during a survey, CMS cites the provider for non- compliance\u2014referred to as a deficiency. These deficiencies are categorized at one of two levels: Condition-level deficiencies. These deficiencies are the most serious. A condition-level deficiency is one in which the provider violates one or more standards and the deficiencies are of such character as to substantially limit the provider\u2019s capacity to furnish adequate care or which adversely affect the health and safety of patients. When a hospice provider is cited for a condition-level deficiency, CMS places the provider on a 90-day termination track (or 23 days if the situation is determined to pose \u201cimmediate jeopardy\u201d to beneficiaries) within which the provider must correct the issue(s) and the correction must be confirmed via a follow-up survey visit. If this does not happen within 90 days of the survey date, CMS terminates the hospice\u2019s Medicare provider agreement; termination is an enforcement remedy CMS uses to ensure compliance. Standard-level deficiencies. These deficiencies are less serious. A hospice provider that has a standard-level deficiency can be certified or re-certified only if the provider has submitted an acceptable plan of correction for achieving compliance within a reasonable period of time. According to CMS officials, standard-level deficiencies must also have follow-up to ensure correction, although the type of follow-up depends on the nature of the deficiency. If a standard-level deficiency is very minor and does not place any beneficiaries at risk, the follow-up may be handled through email or telephone instead of a follow-up visit. According to CMS officials, if a provider fails to submit or implement an acceptable plan of correction within a reasonable period of time acceptable to CMS, the provider is placed on the 90-day termination track noted above. For-profit and non-profit hospices served roughly the same percentage of the approximately 1.5 million Medicare hospice beneficiaries in 2017, even though for-profit hospices make up about two-thirds of all hospice providers. According to our analysis of CMS data, for-profit providers treated about 50 percent of those beneficiaries and non-profit providers treated about 48 percent in 2017. This distribution has been about the same in each year from 2014 through 2017. For example, for these years, the percentages of beneficiaries treated by for-profit providers ranged from 48.7 percent to 50.2 percent (see additional details in app. I, table 7). When comparing the beneficiary populations treated by for-profit and non- profit hospice providers, we found that they generally had similar demographic characteristics. We identified two primary exceptions to this general finding: (1) non-profit hospices had slightly higher percentages of white beneficiaries, and (2) for-profit hospices had a greater proportion of patients enrolled in both Medicare and Medicaid. See table 2 (for more detailed data, see app. I, table 8). While beneficiary demographic characteristics were generally similar, we found differences in beneficiary diagnoses between for-profit and non- profit hospices. Specifically, for-profit hospices had, on average, a greater percentage of patients with non-cancer diagnoses\u201477 percent of for-profit hospice beneficiaries compared to 69 percent of non-profit hospice beneficiaries in 2017. Our analysis found that for-profit providers received a higher proportion of Medicare hospice payments than did non-profit providers. For 2017, about $10.4 billion (58 percent) of the $17.9 billion dollars in Medicare payments were made to for-profit providers and $7.2 billion (40 percent) of payments were to non-profit providers. Our analysis found this same pattern in each year from 2014 through 2017. One reason for-profit hospices received a higher portion of Medicare hospice payments for the period we reviewed is because (as previously noted) they had, on average, a greater percentage of beneficiaries with non-cancer diagnoses, and we found non-cancer beneficiaries, on average, had longer lengths of stay. (See table 3.) Since hospices are typically paid a set amount per day of a hospice stay, longer stays generally result in higher payments. Beneficiaries with non-cancer diagnoses can often have longer lengths of stay compared to other beneficiaries because the progression of these diseases (such as dementia) can be harder to predict; this may result in beneficiaries being enrolled in hospice earlier than appropriate (meaning that their projected life expectancy may actually be longer than 6 months). For instance, one study noted that dementia beneficiaries\u2019 decline may include periods of stabilization where their health stays the same or even improves, which differs from a constant and predictable decline in most beneficiaries with terminal cancer. There are likely other factors beyond a greater percentage of beneficiaries with non-cancer diagnoses that contributed to for-profit providers\u2019 higher portion of Medicare hospice payments. We found that for-profit providers had, on average, longer lengths of stay for both cancer and non-cancer beneficiaries compared to non-profit providers. (See table 3.) For example, non-cancer beneficiaries at for-profit providers had an average length of stay of 108 days, while non-cancer beneficiaries at non- profit providers had an average length of stay of 67 days. This suggests other factors besides beneficiary diagnosis contributed to longer average length of stay for for-profit providers. (For more detailed beneficiary diagnosis data from 2014 to 2017, see app. I, table 9.) For-profit and non-profit hospice providers had similar scores on CMS\u2019s current quality measures (provider-reported measures and caregivers\u2019 experience measures assessed through a survey of the beneficiaries\u2019 caregiver). CMS uses these measures to assess the quality of care provided by hospices. In addition to CMS\u2019s current quality measures, researchers we interviewed noted that there are other care indicators that can also be used to assess the quality of care provided by hospices. According to CMS documents, CMS is working to account for other care indicators by developing additional quality measures. We assessed hospice providers\u2019 performance on these indicators and found that performance varied between for-profit and non-profit hospices. Our review of CMS data found that for 2017, both for-profit and non-profit hospices, on average, had similar scores on the seven quality measures that are provider-reported and that CMS currently uses to assess the quality of hospice care. (See table 4.) For six of the seven measures, for-profit and non-profit hospices had average scores of 94.7 percent or better. We also found that for-profits and non-profits had similar scores (83.6 percent and 87.0 percent, respectively) on a new composite measure that CMS implemented in 2017. This composite measure was designed to provide a more comprehensive evaluation of the hospice\u2019s care by determining whether the hospice provider completed all of the applicable parts of hospice care that are measured by the seven quality measures. When looking at the subset of providers with the lowest scores on the composite quality measure, we found that for-profit hospices were more often in this subset, even when accounting for differences in the number of for-profit and non-profit providers: For the composite measure, there were 329 providers (261 for-profits and 68 non-profits) in the 10th percentile of scores or lower, meaning that the providers had a composite measure score of 64.3 percent or lower. Among these providers, we found that for-profits were more likely to be within this grouping, with about 12 percent of all for-profit providers having scores in the 10th percentile or lower compared to 6 percent of all non-profit providers. We also assessed the subset of these 329 providers that had composite measure scores below 50 percent, meaning that they only completed all of CMS\u2019s seven quality measures for half or fewer of the beneficiaries they treated. We found that 130 providers (112 for-profits and 18 non-profits) had scores below 50 percent on this measure. These providers treated over 24,000 beneficiaries. In addition to the provider-reported quality measures, CMS also uses the caregivers\u2019 experience survey to assess quality of care. We analyzed CMS data on caregivers\u2019 experience surveys for 2016 to 2017 and found that caregivers\u2019 reported experience with hospice care was generally similar for both for-profits and non-profits. The survey assesses care in a number of areas, such as communication, training, and help with pain and symptoms. See table 5 (for more detailed data, see app. I, table 10). Although for-profit and non-profit providers\u2019 average scores on the caregivers\u2019 experience survey were generally similar, we found that for- profit providers were more often among those providers with the lowest scores on certain caregivers\u2019 experience measures than were non-profit providers. For example, on the rating measure that asks caregivers to give an overall rating of the hospice, 290 providers (248 for-profit providers and 42 non-profits) had scores at the 10th percentile or lower, meaning that their score was 72 percent or lower. For this measure, lower scores mean that fewer caregivers provided a rating of 9 or 10 on a 10- point scale, with 10 being the highest possible rating. We found that 15 percent of for-profit providers were among providers with scores in the 10th percentile or lower compared to 4 percent of non-profit providers. We used Medicare claims data to calculate certain measures researchers told us could be indicators of quality of care in hospice settings. (As noted previously, CMS is working to account for other care indicators by developing additional quality measures.) These indicators fall into two categories: (1) the number of beneficiaries discharged prior to death (often referred to as the live discharge rate) and (2) provider visits to provide medical and emotional support to the beneficiary and caregivers near the end of a beneficiary\u2019s life. Researchers told us that such measures can fill gaps in assessing the quality of care provided by hospices, and show greater variability across hospices than CMS\u2019s current quality measures; as previously noted, our data analysis found that providers\u2019 quality measure scores were generally very high. According to researchers we interviewed and studies we reviewed, some discharges from hospice care prior to death should be expected because, for example, patients change their mind about receiving hospice care or their condition improves and they are no longer eligible for hospice care. However, a high live discharge rate could in some cases be an indicator of poor quality of care provided or of provider misuse of the benefit, in that they may be enrolling beneficiaries who are not eligible for hospice. See text box. Live Discharges In some cases, a beneficiary may be discharged alive from hospice care prior to their death. This could be for reasons unrelated to the quality of care provided. For example, beneficiaries may reconsider their decision to start palliative treatment, and therefore leave hospice care to re-start curative treatments. In other instances, a live discharge may indicate quality of care issues. For example, a beneficiary may be unhappy with the quality of care she is receiving from her hospice provider and therefore she leaves that hospice provider to seek treatment from a different hospice provider. Given the various reasons for live discharges, we expect that hospices will have some live discharges, but interpret a high rate of live discharges as potentially suggestive of quality of care issues. We found that for-profits had higher rates of live discharges than non- profits, with 22.1 percent of beneficiaries served by for-profits being discharged alive compared to 12.0 percent of beneficiaries served by non-profits in 2017. This disparity remained true after accounting for whether beneficiaries had a cancer or non-cancer diagnosis. (See table 6; for more detailed data from 2014 to 2017, see app. I, table 11.) We found that 472 hospice providers (462 for-profit and 10 non-profit providers) had live discharge rates of 50 percent or more in 2017, meaning that half or more of their beneficiaries were discharged from hospice care prior to death. These providers provided care to about 6 percent of all beneficiaries discharged alive in 2017. According to researchers we interviewed and one of the studies we reviewed, provider visits near the end of a hospice beneficiary\u2019s life are critical to providing quality care, including for emotional support and for training the beneficiary\u2019s family members or other caregivers on the signs and process of dying. Assessing the number of visits near the end of life may provide insight into the quality of a hospice provider\u2019s care; fewer visits in that time period could indicate poor quality of hospice care. CMS is currently developing a quality measure that assesses the frequency of provider visits at the beneficiary\u2019s end of life. When analyzing CMS claims data, we found that for-profit and non-profit hospices, on average, provided a similar number of provider visits (such as nurse, doctor, social worker, or hospice aide visits) within the last 7 days of a beneficiary\u2019s life. Specifically, in 2017, for-profits and non-profits both averaged about 6 provider visits within the last 7 days of life. We also looked at the average percentage of hospice beneficiaries who received different types of provider visits either within the last 3 days of life or last 7 days of life (consistent with CMS\u2019s new quality measure) and found performance varied among for-profit and non-profit providers: 77 percent of for-profit beneficiaries and 85 percent of non-profit beneficiaries received at least one visit from registered nurses, physicians, or nurse practitioners in the last 3 days of life. 68 percent of for-profit beneficiaries and 57 percent of non-profit beneficiaries received at least two visits from medical social workers, chaplains or spiritual counselors, licensed practical nurses, or hospice aides in the last 7 days of life. We also found more for-profits than non-profits among a subset of hospices that did not provide any visits during the last 3 or 7 days of life in 2017. Specifically, our analysis shows that 83 hospice providers (80 for- profits and 3 non-profits) did not provide any visits in 2017 from registered nurses, physicians, or nurse practitioners in the beneficiaries\u2019 last 3 days of life. This means that all of the 800 hospice beneficiaries treated by these providers did not receive these types of provider visits at the end of life. In addition, we found that 58 providers (55 for-profits and 3 non- profits) did not provide any visits from medical social workers, chaplains or spiritual counselors, licensed practical nurses, or hospice aides in the last 7 days of life in 2017; all of the 613 beneficiaries treated by these providers did not receive these specific provider visits at the end of life. In our review of CMS\u2019s oversight of hospice providers, we found CMS does not instruct surveyors to review, prior to surveying hospice providers, providers\u2019 performance on CMS quality measures (those based on provider-reported quality data or caregivers\u2019 experience surveys) or other indicators of quality that could identify potential areas of concern. CMS issues guidance that surveyors use when conducting surveys to assess a hospice provider\u2019s compliance with federal health and safety requirements. According to this guidance, surveyors are to prepare for hospice surveys by reviewing documents of record including licensure records, previous survey findings and complaints, media reports, and other publicly available information about the provider. A representative for an association representing state surveyors confirmed that this is the type of information surveyors typically review prior to a hospice provider survey. However, according to CMS officials and the surveyor association, CMS does not instruct surveyors to review other information such as providers\u2019 performance on CMS quality measures or other indicators of quality that surveyors could use to identify potential areas of concern that they could focus on more closely during a survey. For example, it might be helpful for surveyors to know if a hospice provided no visits during beneficiaries\u2019 last days of life. According to CMS officials, CMS does not use such information to target hospices for additional survey review. Several studies we reviewed and researchers we interviewed noted CMS could strengthen its survey process by incorporating additional information into the survey process, such as information on how hospice providers perform on CMS quality measures or other potential indicators of quality. For example, one study suggested that hospices with poor reported beneficiary experiences based on caregivers\u2019 experience survey data could be identified for more frequent surveys and that such information could be used to identify care processes for closer review during surveys. Another study we reviewed concluded that claims- based measures could help guide surveyors to more closely review key processes of care to ensure Medicare beneficiaries receive high quality hospice care. In addition, a researcher we interviewed suggested when claims data show no visits during the last 2 days of life, the survey team could interview the deceased patients\u2019 families to see if there was any harm done by the lack of visits at the end of life. And, in July 2019, the Department of Health and Human Services\u2019 Office of the Inspector General (HHS OIG) reiterated recommendations from prior HHS OIG work that CMS analyze claims and deficiency data to identify specific patterns identified by the HHS OIG that could indicate potential issues\u2014 such as hospices that infrequently provide physician services\u2014and that CMS instruct surveyors to pay special attention to these areas during surveys. In contrast to hospice surveys, home health agency surveyors utilize information in addition to survey findings and complaints to identify potential areas of concern. According to CMS officials and the surveyor association we interviewed, home health surveyors review certain CMS quality measures to focus the survey on specific areas of concern or to identify beneficiaries who experienced potential care issues for a more detailed survey review. According to CMS officials, the agency is considering making changes to the survey process but has not yet made any decisions. CMS officials told us they last updated the survey process in 2010, and since then, they have implemented quality measures for hospice providers (provider- reported measures in 2014 and caregivers\u2019 experience survey measures in 2015). They also said that CMS is \u201ccurrently monitoring the implementation of these programs and considering the potential benefit of incorporating review of the data into the survey process.\u201d According to federal standards of internal control, agencies must identify, analyze, and respond to risks related to achieving objectives. By not utilizing additional information in the survey process that would allow it to identify providers and areas where risk of noncompliance is greatest, CMS is missing an opportunity to strengthen its ability to identify and respond to such risks and ensure the quality of care that hospice beneficiaries receive. CMS is limited to one hospice enforcement remedy\u2014termination of the Medicare provider agreement. By law, to qualify for payment under the Medicare program, hospice providers must meet the program\u2019s conditions of participation. If the agency finds a provider is not complying with the program\u2019s conditions of participation, CMS may terminate the provider\u2019s participation in the program. In the Medicare program, termination of a provider is the most significant action CMS can take to address provider non-compliance. As a result, CMS generally only terminates a hospice provider on the basis of a deficiency when the provider fails to correct a condition-level deficiency (the most severe) within the required time frame. Our review of CMS hospice survey data found termination happens rarely. Specifically, 19 hospices were involuntarily terminated from 2014 through 2017. This is less than half of 1 percent of the total number of hospices operating during this time period. In contrast to hospice care, where CMS\u2019s enforcement authority is limited to termination, Congress has given the agency authority to impose additional enforcement remedies for other provider types. Additional statutory and regulatory penalties for home health agencies and nursing homes include civil money penalties, denial of payment for all new Medicare and Medicaid admissions, and imposition of training requirements for situations where it is determined that education will likely lead to provider compliance (referred to as directed in-service training). Such remedies, if available, could enable the agency to more effectively address a broader range of hospice risks. For example, additional remedies could be used in situations that warrant a remedy other than termination or that could further incentivize providers to comply with health and safety requirements or improve their quality of care. According to federal standards of internal control, agencies must identify, analyze, and respond to risks related to achieving objectives. Because CMS lacks the authority to establish such additional remedies, the agency\u2019s ability to respond to risks and ensure quality of care for beneficiaries is limited. The HHS OIG and one researcher we interviewed have recommended CMS seek statutory authority to establish additional enforcement remedies for hospices, explaining that less severe remedies could help address performance problems that may not merit termination and incentivize agencies to improve quality of care. CMS agreed with this recommendation in March 2016 and stated it would consider submitting a request that would seek legislative authority to establish additional enforcement remedies through the President\u2019s annual budget proposal to Congress. In a July 2018 HHS OIG report, the HHS OIG again recommended CMS seek this authority. CMS neither agreed nor disagreed with this recommendation and stated again that it would consider this recommendation when developing the agency\u2019s proposals for the President\u2019s annual budget. However, a request for such legislative authority was not included in the President\u2019s fiscal year 2017, 2018, or 2019 budget proposals. The HHS OIG reiterated this recommendation in two July 2019 reports. Since 2000, the number of Medicare hospice beneficiaries has almost tripled to nearly 1.5 million in fiscal year 2017. In addition, the number of hospice providers has doubled. Given this growth, it is imperative that CMS\u2019s oversight of the quality of Medicare hospice care keeps pace with changes so that the agency can ensure the health and safety of these terminally ill beneficiaries. While recent steps have been taken to strengthen CMS\u2019s hospice quality oversight, including the requirement that hospices be re-certified every 3 years and CMS\u2019s ongoing development of new quality measures, we identified additional opportunities to strengthen CMS\u2019s oversight. Specifically, our review found that CMS could strengthen oversight by using additional information\u2014based on currently available data\u2014to identify potential quality issues that could focus and enhance the survey process. We also found that CMS\u2019s lack of authority to establish additional enforcement remedies before termination, which CMS rarely uses, limits its ability to ensure hospice providers\u2019 compliance with health and safety requirements and quality of care for beneficiaries. Congress should consider giving CMS authority to establish additional enforcement remedies for hospices that do not meet federal health and safety requirements. (Matter for Consideration 1) The Administrator of CMS should incorporate the use of additional information, such as quality measures or other information that could identify potential quality of care issues, into its survey process for overseeing hospice providers. (Recommendation 1) We provided a draft of this report to HHS for review and comment. HHS provided written comments, which are reprinted in appendix II. HHS concurred with our recommendation. HHS stated that it recognizes that meaningful quality measures can also serve as key indicators of provider quality and it will look into ways to incorporate the use of these data into the hospice survey process. In its comment letter, HHS also noted the importance of monitoring patient safety and quality of care to HHS\u2019s hospice oversight efforts and the agency provided an overview of the key efforts it has in place to perform such monitoring. For example, in addition to survey and quality measure requirements, HHS requires hospices to implement a data-driven quality assessment and performance improvement program, intended to have hospices take a proactive approach in improving their performance using objective data. HHS also provided technical comments, which we incorporated into the report as appropriate. As agreed with your office, unless you publicly announce the contents of this report earlier, we plan no further distribution until 30 days from the report date. At that time, we will send copies to the Secretary of Health and Human Services, the CMS administrator, and other interested parties. In addition, the report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staffs have any questions about this report, please contact me at (202) 512-7114 or cosgrovej@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix III. Hospice team treated patient with respect Amount of emotional and religious support provided by the hospice team The patient got the help they needed for pain and symptoms Caregiver received the training they needed Caregiver rating of hospice agency on 10-point scale with 10 being the best hospice care possible Caregiver would recommend the hospice Non-profit hospice providers\u2019 average scores Hospice team treated patient with respect Amount of emotional and religious support provided by the hospice team The patient got the help they needed for pain and symptoms Caregiver received the training they needed Caregiver rating of hospice agency on 10-point scale with 10 being the best hospice care possible Caregiver would recommend the hospice Government-owned hospice providers\u2019 average scores Hospice team treated patient with respect Amount of emotional and religious support provided by the hospice team The patient got the help they needed for pain and symptoms Caregiver received the training they needed Caregiver rating of hospice agency on 10-point scale with 10 being the best hospice care possible Caregiver would recommend the hospice 2.5 survey within three categories (top scores, middle scores, and bottom scores). These data were not available for all hospice providers; our analysis of CMS caregivers\u2019 experience survey quality measure data was for the 2,832 hospice providers that had data for the caregivers\u2019 survey. In general, the top-box scores represent the percentage of caregivers that selected the response of \u201calways\u201d for the particular measure. For the rating measure, the top-box score represents caregivers that rated the hospice provider as a 9 or 10 on a 10-point scale with 10 being the highest rating. For the recommendation measure, the top-box score represents caregivers that responded that they \u201cwould definitely recommend the hospice provider.\u201d In general, the middle-box scores represent the percentage of caregivers that selected the response of \u201cusually\u201d for the particular measure. For the rating measure, the middle-box score represents caregivers that rated the hospice provider as a 7 or 8 on a 10-point scale with 10 being the highest rating. For the recommendation measure, the middle-box score represents caregivers that responded that they \u201cwould probably recommend the hospice provider.\u201d In addition to the contact named above, Gregory Giusto, Assistant Director; Christie Enders, Analyst-in-Charge; Todd Anderson, Leia Dickerson, Rob Dougherty, Krister Friday, Barbara Hansen, Jennifer Whitworth, and Chris Wickham made key contributions to this report.", "summary": "Since 2000, there has been substantial growth in Medicare payments for hospice services and the number of Medicare beneficiaries using hospice. This growth has been accompanied by an increase in the number of providers (primarily an increase in for-profit providers), reaching approximately 4,500 providers by 2017. GAO was asked to review aspects of Medicare's hospice program. This report, among other things, (1) compares quality scores and other potential indicators of quality for for-profit and non-profit hospices; and (2) examines opportunities for strengthening CMS's oversight of hospice providers. GAO analyzed CMS data on hospice care for 2014 through 2017\u2014the latest years for which full-year data were available at the time of GAO's analysis\u2014and reviewed research on hospice care. GAO interviewed CMS officials, researchers, provider associations, a survey agency association, and a non-generalizable sample of hospice providers selected in part through referrals from other stakeholders. GAO also reviewed relevant statutes, regulations, documents, and enforcement data. Medicare's hospice benefit provides palliative care to beneficiaries with terminal illnesses and a life expectancy of 6 months or less. GAO's review of 2017 data from the Centers for Medicare & Medicaid Services (CMS) found that for-profit and non-profit hospices had, on average, similar scores on CMS's current quality measures that indicate hospice performance in areas such as pain assessment and discussion of beneficiary treatment preferences. However, for-profits were more often among the subset of providers with the lowest scores on certain quality measures GAO reviewed. In addition to analyzing providers' scores on CMS quality measures, GAO analyzed provider performance on other indicators, identified by researchers, that could signal quality issues and found performance varied among for-profit and non-profit hospices. One of the other quality indicators GAO analyzed was the rate of beneficiaries discharged from hospice prior to death, which in some cases could indicate dissatisfaction with care leading to the beneficiary's decision to leave the hospice provider. In addition, GAO examined the number of provider visits to give medical and emotional support within the last few days of a beneficiary's life. With regard to these indicators, for 2017, GAO found the following, among other things: 472 hospice providers (462 for-profits and 10 non-profits) had a high rate of discharging beneficiaries prior to death (50 percent or more were discharged). According to research, a high discharge rate could, in some cases, be an indicator of poor quality of care or of provider misuse of the benefit, in that the hospice may be enrolling beneficiares who are not eligible for hospice care. 83 providers (80 for-profits and 3 non-profits) did not have hospice staff (such as nurses, physicians, or nurse practitioners) visit beneficiaries within the last 3 days of their life\u2014a critical time in providing quality care, according to researchers GAO interviewed. CMS's oversight of the quality of care provided by hospice providers consists primarily of inspections\u2014called surveys\u2014of hospice providers. GAO found that, while CMS instructs surveyors to review previous survey findings and complaints, CMS does not instruct surveyors to use information on providers' performance on quality measures or other potential indicators of quality as part of the survey process. For example, CMS does not instruct surveyors to consider whether a hospice provided staff visits during beneficiaries' last week of life. According to research, this information could be used to enhance the survey process. GAO also found that CMS is limited to one enforcement option\u2014termination of the Medicare provider agreement\u2014which CMS uses rarely and generally only when providers fail to correct within the required time frame the most serious violations of federal health and safety requirements. According to two researchers, additional remedies, such as civil monetary penalties, could enhance CMS's oversight by addressing performance problems that do not merit termination and incentivize agencies to improve quality of care. CMS uses a range of remedies for other provider types, such as home health agencies and nursing homes, but lacks authority to impose such additional sanctions on hospices. CMS should incorporate the use of additional information that could be used to identify quality of care issues into its survey process for hospice oversight. Congress should consider giving CMS authority to establish additional enforcement remedies for hospices that do not meet federal health and safety requirements. The Department of Health and Human Services concurred with GAO's recommendation."}
{"id": "govreport_7", "report": "Federal agencies are dependent on computerized (cyber) information systems and electronic data to carry out operations and to process, maintain, and report essential information. Cybersecurity\u2014the security of these systems and data\u2014is vital to public confidence. Ensuring the cybersecurity of the nation, including protecting privacy and sensitive data, and IRS\u2019s efforts to address tax refund fraud due to identity theft are issues included in our High Risk List. IRS relies on information system security controls to protect the confidentiality, integrity, and availability of the sensitive financial and taxpayer information that resides on its systems. Federal law and guidance specify requirements for protecting federal information and systems. The Federal Information Security Modernization Act of 2014 (FISMA) is intended to provide a comprehensive framework for ensuring the effectiveness of information system security controls over information resources that support federal operations and assets. To accomplish this, FISMA requires each agency to develop, document, and implement an agency-wide information security program to provide security for the information and systems that support the operations and assets of the agency, using a risk-based approach. However, taxpayer information held by third-party providers is generally outside of these requirements, according to IRS officials. Fraudsters may target third parties, such as paid preparers and tax software providers, to steal taxpayer data\u2014defined for our purposes as personally identifiable information and other personal, financial, or federal tax data\u2014which can then be used to commit identity theft refund fraud or other types of financial crimes. Viewed broadly, identity theft tax refund fraud consists of two crimes: (1) stealing or compromising taxpayer data and (2) using stolen (or otherwise compromised) taxpayer data to file a fraudulent tax return and collect a fraudulent refund. Figure 1 presents an example of how this crime can work. In this example, a taxpayer may alert IRS of identity theft refund fraud. Alternatively, IRS can detect identity theft refund fraud through its automated filters that search for specific characteristics, as well as through other reviews of taxpayer returns. Third-party providers retain a large amount of electronic tax information, which makes them targets of various types of data theft incidents. Five common types of security incidents are shown in table 1. The number of electronically filed (e-filed) tax returns, and therefore the amount of electronically available data that are vulnerable to security incidents, has been increasing over the past several decades from 4.2 million in 1990 to 135.5 million in 2018. In 2018, approximately 90 percent of the 150.5 million filed individual income tax returns were filed with IRS electronically (see figure 2). Paid preparers prepared more than half of the e-filed returns in 2018. Multiple IRS offices have discrete responsibilities in overseeing how third- party providers secure taxpayer information, as depicted in figure 3. Oversight responsibilities are as follows: Stakeholder Liaison works with the paid preparer community to educate preparers about information security risks and guide them through the process of resolving security issues when security incidents are reported. This office is also the intake point for security incident information for paid preparers. Cybersecurity works to protect taxpayer information and IRS\u2019s electronic systems, services, and data from internal and external cybersecurity threats\u2014such as damage to computers, electronic communications systems, or information contained in those systems\u2014by implementing security practices. Criminal Investigation (CI) reviews security incident reports to determine whether criminal action has occurred and investigates any potential criminal violations of applicable laws. It also investigates large-scale tax schemes and fraud. The Return Preparer Office is responsible for matters relating to the registration and the program compliance of tax return preparers who prepare returns for compensation. The office also engages in outreach and education programs and administers IRS\u2019s Annual Filing Season program, a voluntary program to encourage noncredentialed preparers to participate in continuing education courses. Small Business/Self-Employed (SB/SE) Examination revenue agents visit e-file providers to ensure they are complying with the Authorized e-file Provider program\u2019s requirements. Electronic Products and Services Support (EPSS) administers the Authorized e-file Provider program. It is also responsible for updating IRS Publications 1345 and 3112, which outline the requirements of the program. EPSS officials reported that they must coordinate with other business units to update individual references in the publications. EPSS is the intake point for security incident information for online providers and e-Services users, according to officials. Return Integrity and Compliance Services (RICS) monitors taxpayer accounts for potential fraud to protect revenue. RICS also manages the security incident data reports that are submitted by tax software providers. RICS is the intake point for security incident information for Security Summit and Identity Theft Tax Refund Fraud - Information Sharing and Analysis Center (ISAC) members, as described below, and actively monitors ISAC alerts from the online platform for new information that may not have been reported elsewhere. While the Office of Professional Responsibility (OPR) does not have oversight responsibilities over the security of tax information at third parties, it administers the regulations that govern the practice of tax professionals who interact with IRS on behalf of taxpayers, including attorneys, certified public accountants, and enrolled agents, among others. Treasury Department Circular 230, which incorporates the regulations, directed the Commissioner to establish OPR and any other offices within IRS to administer and enforce the regulations. However, Circular 230 does not include a requirement for practitioners concerning the security of taxpayer information. In recent years, IRS has taken a number of steps to help battle identity theft refund fraud. In 2015, IRS formed the Security Summit, a public-private partnership to protect the nation\u2019s taxpayers and the tax system from identity theft refund fraud. The summit has representatives from IRS, state tax administrators, and industry partners including the software industry, tax professional associations, and payroll and tax financial product processors. IRS launched ISAC in the 2017 filing season. It aims to allow IRS, states, and tax preparation industry partners to quickly share information on identity theft refund fraud. It includes two components: an online platform controlled by IRS to communicate data on suspected fraud, and a collaborative organization governance structure comprising IRS, states, and industry. IRS uses a Rapid Response Team in partnership with states and industry members to coordinate responses to identity theft refund fraud incidents. The team aims to respond to significant threats within 24 to 72 hours of their discovery. The Rapid Response Team was deployed for six incidents in 2016, one in 2017, and was not deployed for any incidents in 2018. IRS seeks to help safeguard taxpayers\u2019 information and the electronic filing system by prescribing requirements for various types of third-party providers through its Authorized e-file Provider program. These requirements are outlined in Revenue Procedure 2007-40 and Publication 1345, Handbook for Authorized IRS e-file Providers of Individual Income Tax Returns. IRS Revenue Procedure 2007-40 states that the security of taxpayer accounts and personal information is a top priority for the agency. Further, the Revenue Procedure states that it is the responsibility of each IRS Authorized e-file Provider to have security systems in place to prevent unauthorized access to taxpayer information by third parties. Some of the requirements included in this program are applicable to all types of Authorized e-file Providers, while others are applicable to one group or another. Businesses\u2014including sole proprietors\u2014that wish to e-file tax returns on behalf of clients must apply to IRS\u2019s Authorized e-file Provider program and choose a provider type, as described in table 2. According to IRS, in 2018 there were more than 325,000 Authorized e-file Providers, some of which were paid preparers. More than 790,000 paid preparers had registered with IRS as of 2018; accordingly, not all paid preparers are Authorized e-file Providers and are therefore not covered by the requirements of the Authorized e-file Provider program. However, a business that has been approved as an electronic return originator (ERO) may employ multiple paid preparers who are not Authorized e-file Providers. Those paid preparers would be allowed to e-file returns under the supervision of their ERO employer. According to IRS Publication 3112, the activities and responsibilities for return preparation and e-filing are distinct and different from each other. Tax software providers, which IRS refers to as software developers in its Authorized e-file Provider program, develop tax return software that individuals and businesses can use to file their own returns, or that paid preparers can use when filing returns on behalf of clients. Online providers are the subset of tax software providers that allow individual taxpayers to self-prepare returns and file them with IRS. Providers that develop software for paid preparers\u2019 use do not fall under the definition of an online provider. IRS has not fully incorporated the Federal Trade Commission (FTC) Safeguards Rule into its requirements for all provider types under the Authorized e-file Provider program. The Gramm-Leach-Bliley Act provided FTC with the authority to require that financial institutions subject to its jurisdiction ensure the security and confidentiality of customer records and nonpublic personal information; protect against any anticipated threats or hazards to the security of such records; and protect against unauthorized access to or use of such records or information which could result in substantial harm or inconvenience to any customer. FTC, in turn, issued a regulation known as the \u201cFTC Safeguards Rule.\u201d The FTC Safeguards Rule applies to financial institutions including third- party providers that help taxpayers file tax returns, such as paid preparers and providers of software that allows individuals to prepare their own tax returns. The FTC Safeguards Rule requires those institutions to develop, implement, and maintain a comprehensive written information security program. The program must contain administrative, technical, and physical safeguards that are appropriate to the provider\u2019s size and complexity, the nature and scope of the provider\u2019s activities, and the sensitivity of any customer information at issue. IRS addresses the FTC Safeguards Rule through its Revenue Procedure 2007-40. This Revenue Procedure provides the procedures for the Authorized e-file Provider program, and clearly states that violations of the provisions of the Gramm-Leach-Bliley Act and the implementing rules and regulations promulgated by FTC are considered violations of the Revenue Procedure. It also states that violations may subject an Authorized e-file Provider to penalties or sanctions, including suspension or expulsion from the Authorized e-file Provider program. However, the IRS publications that provide further information on the Authorized e-file Provider program only briefly discuss the FTC Safeguards Rule, and do not provide details on the required elements of an information security program. For example: Publication 3112, IRS e-file Application and Participation, states that providers should become familiar with the Privacy and Security Rules that implement the Gramm-Leach-Bliley Act, and with other important information regarding the safeguarding of personal information available on the FTC website. The publication does not detail each of the required elements of an information security program. Publication 1345, Handbook for Authorized IRS e-file Providers of Individual Income Tax Returns, which was updated in February 2019, notes FTC\u2019s role in protecting taxpayer data and generally describes the requirement of implementing and maintaining a comprehensive information security program, including the requirement that administrative, technical, and physical safeguards be appropriate to the business\u2019s size, nature and scope of its activities, and the sensitivity of the customer information. The publication does not detail each of the required elements of an information security program. We identified other IRS publications that are not exclusively related to the Authorized e-file Provider program that discuss the requirements of the FTC Safeguards Rule, as well as other information security measures that serve as leading practices for the broader population of tax professionals. For example, in 2018, IRS updated Publication 4557, Safeguarding Taxpayer Data: A Guide for Your Business. The publication aims to help tax professionals understand basic security steps, recognize signs of data theft, respond to data losses, and understand and comply with the FTC Safeguards Rule. This publication refers to the FTC rule and tax professionals\u2019 responsibilities to create and enact security plans, and provides a checklist from FTC to help third-party providers implement the information security plans. IRS Publication 4600, Tips for Safeguarding Taxpayer Data, also discusses elements of the FTC Safeguards Rule. However, while IRS references these documents in Publications 3112 and 1345, Authorized e-file Providers are not obligated to consult or follow these documents. In addition, most paid preparers do not know about the FTC Safeguards Rule and likely do not have information security plans for their places of business, according to officials from several tax preparation industry groups. Industry group officials also told us that there are misconceptions about who should be responsible for implementing information security. For example, one industry group official said that paid preparers and EROs often think that their tax software providers will provide security services or that their computer firewall or antivirus software will be enough protection. Modifying the Authorized e-file Provider program requirements to explicitly incorporate the FTC Safeguards Rule\u2019s elements of an information security program would be consistent with Internal Control Standards. The standards call for management to consider the external requirements\u2014such as laws, regulations, and standards\u2014and incorporate these requirements into an agency\u2019s objectives when setting the standards for the compliance of other entities. IRS officials told us that they do not believe that federal law provides IRS with any authority to enforce the FTC Safeguards Rule. However, IRS has already stated in Revenue Procedure 2007-40 that compliance with the FTC Safeguards Rule is required for participation in the Authorized e- file Provider program. Modifying its requirements to explicitly state the elements of an information security program as required under the FTC Safeguards Rule would help IRS ensure that all types of Authorized e-file Providers are aware of, and comply with, the FTC Safeguards Rule, which could help them better protect taxpayers\u2019 information. While modifying the Authorized e-file Provider program may not reach paid preparers who are not part of the Authorized e-file Provider program, it will strengthen the controls for EROs, tax software providers, and online providers. IRS\u2019s Authorized e-file Provider program does not outline a set of minimum information security standards for systems used by paid preparers or Authorized e-file Providers. When we reviewed IRS\u2019s publications for Authorized e-file Providers, we found that specific information security standards were outlined for online providers, but there were no specific standards for other types of Authorized e-file Providers or paid preparers. Officials from tax preparation groups we interviewed and IRS raised issues that relate to paid preparers\u2019 system risks. First, the tax preparation industry groups that we spoke with stated that most paid preparers, especially small firms or individual preparers, did not know the steps that they should take to protect taxpayer information on their systems. IRS officials reported that paid preparers often do not know that they experienced a security incident until IRS informs them something is wrong with their filing patterns. Second, according to officials from several tax preparation industry groups, paid preparers often have several misconceptions as to what is required of them in protecting taxpayer data, causing confusion. Industry group officials we interviewed told us that IRS\u2019s current publications are not clear about requirements versus leading practices. For example, IRS publication 4557, Safeguarding Taxpayer Data, provides paid preparers with some leading practices to protect taxpayer data, but the leading practices are not legal requirements, with the exception of the FTC Safeguards Rule. An official from the Return Preparer Office explained that imposing any standards for paid preparers, whether related to competency or information security, without explicit authority would leave IRS vulnerable to legal challenges because of a recent court case that found that IRS does not have the authority to regulate the competency of paid preparers. According to IRS\u2019s Office of Chief Counsel, this ruling, combined with the lack of explicit statutory authority, prevents IRS from establishing system standards for paid preparers, because while 31 U.S.C. \u00a7 330 authorizes the Secretary of the Treasury to regulate the practice of practitioners before the Department of the Treasury, mere return preparation, including through systems practitioners use to prepare and transmit tax returns, is not considered practice before IRS. In contrast to paper filing of tax returns, certain security measures need to be taken for e-filing returns to protect the integrity of the e-file system; thus, IRS has implicit authority to regulate e-file providers insofar as their activities relate to electronically filing returns with IRS, according to IRS Office of Chief Counsel officials. These officials also noted that no single provision of the Internal Revenue Code provides IRS explicit authority to regulate the standards for e-file providers. Instead, Internal Revenue Code \u00a7 7803 gives the Commissioner of Internal Revenue broad authority to administer and supervise the internal revenue laws, and \u00a7 6011 authorizes IRS to require returns and regulate the form of such returns. When taken as a whole, these provisions of the Internal Revenue Code show congressional intent to provide the Secretary of the Treasury with broad authority to administer the method for, and requirements surrounding, the e-filing of federal tax returns, according to IRS officials. Nevertheless, having explicit authority to establish security standards for the systems of Authorized e-file Providers may help IRS better ensure the protection of taxpayers\u2019 information and mitigate the risk of legal challenges to IRS\u2019s ability to do so. IRS Office of Chief Counsel officials also noted that for several years the Department of the Treasury has sought additional authority for IRS to regulate all tax return preparers. For example, this request was included in the most recent (fiscal year 2020) Congressional Budget Justification. The justification for this additional authority specifically refers to the competency of tax return preparers, but does not mention security standards for the systems that those preparers use. Similarly, we have previously suggested that Congress consider granting IRS the authority to regulate the competency of paid preparers (that suggestion did not cover regulating the security of paid preparers\u2019 systems). As of April 2019, Congress had not provided such authority. Without Congress providing IRS with explicit authority to regulate the security requirements for the systems of paid preparers or Authorized e- file Providers, Congress and IRS have limited assurance that the processes used by paid preparers or Authorized e-file Providers are adequately protecting taxpayers\u2019 information against electronic data breaches and potential identity theft tax refund fraud. Having such explicit authority would enable IRS to establish minimum security requirements and help ensure improved taxpayer information security by paid preparers and Authorized e-file Providers. IRS does not have a robust set of information security requirements for all tax software providers in the Authorized e-file Provider program. Instead, IRS has limited security requirements for the subset of tax software providers designated as online providers outlined in IRS Publication 1345, as we discuss in the next section. In Publication 4164, Modernized e-File Guide for Software Developers and Transmitters, IRS also provides some information on \u201csecurity directive rules of behavior for accessing IRS business systems\u201d while transmitting returns to IRS. However, this document does not provide a specific list of controls to for these providers to follow. IRS has been working with the Security Summit to implement a subset of the NIST Special Publication 800-53 security and privacy controls for the industry members of the Security Summit, which represents a subset of all tax software providers. The Security Summit partners agreed voluntarily to implement about 140 tax-related controls over a 3-year period and provide self-assessments related to the implementation of those controls. IRS reported in October 2018 that 15 of the 21 Security Summit industry partners had voluntarily certified that they implemented the NIST controls in years 1 and 2 of the rollout schedule. IRS officials reported that they later determined three of the other 21 industry partners are financial institutions that do not handle taxpayer data; thus the standards are not applicable to them. IRS officials told us that they are actively following up with the remaining three providers to determine why they have not completed and submitted the self-assessment, and to what degree they have implemented the subset of NIST security controls. While this is an important and significant first step, the 15 industry partners in the Security Summit that are voluntarily adhering to the NIST security controls represent about a third of all of the tax software providers that IRS has approved to be a part of the Authorized e-file Provider program. According to IRS, these 15 Security Summit partners transmitted about 132.6 million (98.8 percent) of all of the electronically filed returns in 2018; the other two-thirds of tax software providers in the Authorized e-file Provider program transmitted about 1.6 million (1.2 percent) electronically filed returns. A Security Summit membership criterion states that only those providers that filed more than 50,000 returns with IRS during a filing season can be members, but not all tax software providers meet this threshold. Internal Control Standards state that managers consider external requirements when defining objectives, such as those set by standard- setting bodies designed to comply with laws, regulations or standards. Management should incorporate those requirements into its objectives and sets those requirements through the established standards of conduct, oversight structure, organizational structure and expectations of competence. By statue, NIST is responsible for developing information security standards and guidelines, including minimum requirements for federal information systems. According to Special Publication 800-53, the controls outlined provide a holistic approach to information security and risk management by providing organizations with the breadth and depth of security controls necessary to fundamentally strengthen their information systems and the environments in which those systems operate\u2014contributing to systems that are more resilient in the face of cyber attacks and other threats. While the guidelines in this publication are applicable to all federal information systems, other organizations are encouraged to consider using the guidelines, as appropriate. The applicability of the selected NIST controls is evidenced by the adoption of those controls by the Security Summit partners. While most returns are filed through tax software providers that are voluntarily adhering to the security controls, these controls are not required and do not apply to all tax software providers. Additionally, IRS officials that are a part of the Security Summit stated that they cannot enforce the subset of NIST controls with the remaining Security Summit partners because the controls were set up in a voluntary program. IRS officials from multiple offices did not have a clear reason as to why this subset of NIST controls has not been incorporated into the requirements for the entire population of tax software providers in the Authorized e-file Provider program, even though some security standards had been incorporated into the Authorized e-file Provider program for a limited set of providers (online providers) as discussed in the next section. In addition, as previously discussed, IRS can prescribe the requirements to which Authorized e-file Providers must adhere when e-filing returns for taxpayers. Incorporating fundamental security controls into its Authorized e-file Provider program would give IRS greater assurance that tax software providers have identified and addressed information security risks consistent with professional standards. This missed opportunity to update the requirements for tax software providers by adopting the subset of NIST controls is due, in part, to IRS\u2019s lack of a centralized leadership over the security of taxpayer information collected by paid preparers and tax software providers. As previously discussed, multiple IRS offices have discrete responsibilities for overseeing the security of taxpayer information while at third parties; however, no one office is responsible for, or has the authority to provide, the strategic vision, oversight, or coordination over all aspects. Further, while IRS offices coordinate to some extent, there is not a formalized governance structure, such as a steering committee, that would help provide this level of leadership, coordination, and collaboration to the agency. According to Internal Control Standards, an agency\u2019s organizational structure provides management\u2019s framework for planning, directing, and controlling operations to achieve agency objectives. Management develops an organizational structure with an understanding of overall responsibilities, and assigns these responsibilities to discrete units to enable the organization to operate in an efficient and effective manner and reliably report quality information. A sound internal control environment requires that the agency\u2019s organizational structure clearly defines key areas of authority and responsibility, and establishes appropriate lines of reporting. Without setting and requiring the same security standards for all tax software providers, IRS does not have assurance that these providers have an equivalent level of standards in place to adequately protect taxpayer information. Further, in continuing to operate a voluntary security controls program, IRS does not have assurance that those software providers who are currently adhering to the standards will continue to do so in the future. Finally, without centralized leadership in this area, it is unclear how IRS will adapt to changing security threats in the future and ensuring those threats are mitigated. Online providers\u2014tax software providers that allow individuals to prepare their own tax returns\u2014have additional requirements for security and privacy that they must follow, as outlined in Publication 1345. IRS established six security, privacy, and business standards for online providers, including requirements for developing information privacy and security policies and reporting security incidents. Compliance with these six standards for online providers became mandatory on January 1, 2010; however, IRS has not substantially updated them since then (see appendix II for the text of the six security, privacy, and business standards). These additional requirements do not apply to paid preparers, EROs, or providers of tax software used by paid preparers. Without updating standards regularly, the standards can become outdated and lose their ability to protect information from known vulnerabilities as technology changes. For example, IRS\u2019s current guidance refers to an outdated encryption standard. Specifically, IRS requires online providers to use, at minimum, Secure Sockets Layer 3.0 and Transport Layer Security (TLS) 1.0. However, NIST Special Publication 800-52 and industry leading practices recommend the use of TLS 1.1 as the minimum level of encryption due to known weaknesses of using TLS 1.0 to encrypt data in transmission. While the standard allows for use of later encryption versions, it refers to a minimum encryption standard that has known weaknesses. As a result, IRS and taxpayers have limited assurance that their taxpayer data are protected according to NIST guidelines and industry leading practices. Recommended controls outlined in NIST Special Publication 800-53 and our Fraud Risk Framework call for continuous monitoring and regular fraud risk assessments, respectively, to help determine the effectiveness of controls in a program. Internal Controls Standards also calls for management to periodically review the policies, procedures, and related activities for continued relevance and effectiveness in achieving the entity\u2019s objectives or addressing related risks. When we asked why the six standards in Publication 1345 had not been updated since 2010, a senior Wage and Investment Division official stated that the publication is subject to an annual review by multiple IRS offices, but no office had identified the need to update the standards as part of these reviews. An Electronic Products and Support Services (EPSS) official told us that the standards were initially developed based on the latest technology at the time. However, according to this official, technology can become obsolete quickly, and adapting standards to keep pace with technological changes can require a lot of resources. Not updating the requirements for online providers again points to a missed opportunity due to IRS\u2019s lack of a centralized leadership over the security of taxpayer information at paid preparers and tax software providers. In this case, centralized leadership may have identified the need to update the standards. Without periodically reviewing and updating the standards themselves, IRS has limited assurance that the standards have kept pace with technological changes, and therefore, that the online providers are protecting the taxpayer\u2019s data. IRS uses a variety of outreach tools to communicate with third-party providers, such as paid preparers and tax software providers, about information security risks. IRS tries to educate these tax professionals about ways to improve information security practices and the benefits of doing so. For example, IRS informs paid preparers, tax software providers, and others about the importance of reporting security incidents in a timely manner to help ensure that action can be taken quickly to help protect their clients and avoid fraudulent returns being filed. Similarly, Stakeholder Liaison advises paid preparers about the steps to take to ensure that their systems are no longer vulnerable to compromise, according to Stakeholder Liaison officials. Below are examples of IRS\u2019s recent communication efforts. IRS and the Security Summit collaborated on tax professional outreach campaigns. For example, in 2018, they launched the Tax Security 101 campaign, which provided tax professionals with basic information on how to protect taxpayer data. Each year, IRS sponsors nationwide tax forums largely targeted toward paid preparers such as enrolled agents, certified public accountants, and noncredentialed preparers. The 2018 forum included five seminars focused on securing taxpayer information, such as \u201cData Privacy and Cybersecurity for Tax Professionals\u201d and \u201cData Compromises\u2014It\u2019s Not a Matter of \u2018If\u2019 but \u2018When.\u2019\u201d IRS hosts webinars throughout the year to inform tax professionals and taxpayers about various topics, including information security. For instance, in October 2018, IRS hosted a webinar called \u201cProtect Your Clients, Protect Yourself: Tax Security 101.\u201d The webinar covered common security threats, signs of data theft, ways to report taxpayer data theft to IRS, and tax preparers\u2019 obligations to create a written information security plan consistent with the FTC Safeguards Rule. Stakeholder Liaison has participated in over 1,000 virtual and in- person events since June 2015 where data security was a primary topic or featured message, according to Stakeholder Liaison officials. Further, the officials reported that there were over 165,000 attendees at these events. IRS uses social media outlets such as YouTube and Twitter to provide information to tax professionals. For example, in July and October 2017, IRS released two YouTube videos about information security for tax professionals titled \u201cWhy Tax Professionals Need a Security Plan\u201d and \u201cWhat to Do After a Tax Professional Data Compromise.\u201d Similarly, IRS\u2019s tax professional Twitter account, @IRStaxpros, releases information about information security (see figure 4). Though IRS has various ways to disseminate information to tax professionals, it faces a challenge reaching paid preparers who are not affiliated with larger industry groups or who do not visit the IRS.gov website, according to both IRS officials and industry group officials. According to Return Preparer Office officials, many paid preparers are not linked to standard tax communication channels, such as direct communications from IRS through news releases or email alerts. IRS and industry group officials told us one barrier to reaching these paid preparers is preparers\u2019 belief that their businesses are too small to be a target for fraudsters. IRS officials recognize the challenges and said that they continue to address them by speaking with tax professionals about how to increase paid preparers\u2019 awareness of information security risks, such as by making materials easy for preparers to read. IRS\u2019s monitoring program is primarily focused on EROs\u2019 adherence with multiple aspects of the Authorized e-file Provider program, such as requirements for Earned Income Tax Credit due diligence, advertising, and electronic signatures. The monitoring program also calls for monitoring of physical information security, which is not required as part of the Authorized e-file Provider program. The Internal Revenue Manual (IRM) details mechanisms and practices for monitoring Authorized e-file Providers, including EROs and online providers. As part of this monitoring, Small Business/Self-Employed (SB/SE) conducts field visits, the number of which more than doubled in the past few years, from almost 300 in 2015 to about 650 in 2018. SB/SE revenue agents visit providers to monitor their operations and to advise providers of any program violations. IRS uses monitoring visits to investigate allegations, complaints, and warnings against Authorized e-file Providers, as well as to determine general compliance with program requirements. While any provider type could undergo a monitoring visit, IRS officials informed us that they primarily conduct field monitoring visits for EROs, which are selected using risk-based criteria. According to these officials, SB/SE coordinates with other IRS offices to provide field monitoring on an as-needed referral basis for other types of Authorized e-file Providers. IRS officials reported that they were unable to confirm the specific number of recent referral monitoring visits but said there were likely fewer than five referrals in the past couple of years. However, the IRM section detailing the monitoring visits provides little direction for monitoring of information security standards from IRS Publication 1345. The IRM lists monitoring techniques for security, but they focus largely on physical security rather than cybersecurity controls for the electronic aspects of information security. For example, the IRM suggests that agents ask about access to physical files or office keys rather than about how providers send emails containing taxpayer information. According to our Fraud Risk Framework, agencies should use a risk- based approach to evaluate outcomes and adapt activities to improve fraud risk management. As fraudsters increasingly target paid preparers and tax software providers through cybersecurity attacks, risk-based monitoring and evaluation of cybersecurity controls could help IRS identify fraud risks and potential control deficiencies among third-party providers. IRS officials said that the SB/SE revenue agents who conduct monitoring visits do not have the technical expertise to effectively monitor information security or cybersecurity controls. For example, an IRS official stated that the IRM monitoring techniques ask about physical security instead of cybersecurity because revenue agents can verify whether filing cabinets are locked or whether computer passwords are visible, but they cannot verify cybersecurity controls, such as whether a provider\u2019s information security policies are consistent with government and industry guidelines. Further, an SB/SE official said that, while SB/SE is responsible for monitoring Authorized e-file Providers, cybersecurity is not part of SB/SE\u2019s role. However, we believe there are opportunities for revenue agents to ask basic cybersecurity questions and, at a minimum, use monitoring visits to help promote awareness of leading practices designed to help protect taxpayer information. For example, revenue agents could ask providers if they have secured their office\u2019s wireless capabilities, use encryption for sensitive business information, have a designated official in case of a security incident, or know their assigned stakeholder liaison, among other things. Additionally, opportunities exist to leverage resources across IRS to monitor cybersecurity controls. For instance, Cybersecurity has technical expertise that SB/SE could leverage to help monitor these requirements, according to a Cybersecurity official. Without effective monitoring of information security standards or cybersecurity controls, IRS has limited assurance that EROs\u2019 systems are adequately protecting taxpayers\u2019 information. If these third parties do not adequately protect that information, taxpayers will face increased risk of both tax-related and non-tax-related identity theft. Improved monitoring could help IRS ensure that it is more effectively detecting and responding to changing fraud risks among providers. Additionally, updating documentation of monitoring activities, as needed, such as the IRM and internal guidance, along with staff training, would provide IRS with better assurance that the greatest risk areas are addressed appropriately. IRS conducts limited monitoring of the online provider subset of tax software providers enrolled in the Authorized e-file Provider program. However, these monitoring efforts are not part of the systematic Authorized e-file Provider monitoring program for EROs described above, nor are they documented in the IRM or relevant job aids. According to EPSS officials, IRS does not currently monitor all of the standards for online providers. IRS staff can remotely monitor three of the six security, privacy, and business standards for online providers through electronic means, according to EPSS officials (see table 3). EPSS officials stated that the other three standards cannot be monitored remotely (see appendix II for the full text of the six security, privacy, and business standards). For two of the three standards that cannot be monitored remotely, EPSS officials said it would be feasible for online providers to send the results of vulnerability scans (standard 2 in table 3) and privacy seal vendor certifications (standard 3 in table 3) to IRS for monitoring purposes. However, according to these officials, EPSS does not have dedicated staff who could review these results. Similarly, SB/SE, which conducts Authorized e-file Provider monitoring, does not have the technical expertise to review these results, as previously discussed. In addition, IRS cannot monitor the requirement to report security incidents, according to officials, because there is no way for the agency to know whether security incidents have occurred but were not reported. However, every fiscal year, IRS asks online providers to self-certify that they are meeting all six of the security, privacy, and business standards in IRS Publication 1345, according to an EPSS official. To self-certify, providers answer \u201cyes\u201d or \u201cno\u201d questions about whether they have complied with each standard. According to this official, companies generally indicate that they are meeting all of the standards. In addition to inconsistent monitoring of online provider requirements, IRS has not recently assessed the information security risks among all third- party provider types. IRS initially implemented the Authorized e-file Provider monitoring program described above only for EROs because they presented the greatest risk for fraud, according to an EPSS official. However, IRS\u2019s monitoring practices and the associated IRM section have not been updated since 2011, and still reflect IRS\u2019s initial assumption that EROs present the greatest risk for fraud among the different provider types. Additionally, while IRS assessed the security and privacy risks of tax software providers, the assessment did not compare these risks to those presented by EROs. In 2009, we recommended that IRS assess the extent to which the reliance on tax software creates significant risks to tax administration, including the security and privacy of taxpayer information. IRS agreed with our recommendation and in 2011 received the results of a third-party risk assessment to determine, in part, the security and privacy risks presented by large and small software providers. The assessment found that security presented the biggest overall risk among the areas reviewed\u2014security of information, privacy of information, accuracy of returns, and reliability of systems\u2014due, in part, to security being the least adequately controlled risk area by small software providers. This assessment was not designed to review the risks for other Authorized e-file Provider types, such as EROs. Our Fraud Risk Framework requires agencies to plan regular fraud risk assessments and suggests tailoring those assessments to the program. Effective managers plan to conduct such assessments at regular intervals and when there are changes to the program or operating environment, such as changes in technology that could result in increased security incidents. As part of a risk assessment, managers may examine the suitability of existing fraud controls. Such examination can help managers identify areas where existing control activities are not suitably designed or implemented to reduce risks to a tolerable level. By conducting a risk assessment for the Authorized e-file Provider program and identifying the provider types that present the greatest risks for fraud, IRS can better determine whether changes to the monitoring program are needed for each provider type. If the agency determines that changes are needed, updating documentation of monitoring activities\u2014 such as the IRM, internal guidance, and job aids, along with staff training\u2014would provide IRS with better assurance that the greatest risk areas are addressed appropriately. Multiple offices within IRS use information on security incidents to track trends in fraud schemes, which helps them to protect taxpayer information and to prevent the filing of fraudulent tax returns. For example, when Stakeholder Liaison receives reports about a security incident involving a paid preparer, staff collect additional information about the incident, including the cause of the incident and whether taxpayer information was compromised. Stakeholder Liaison can analyze the data to show geographical information, like the states most affected by breaches; the paid preparer types most affected by incidents; and the method of attack of incidents; among other things, according to a Stakeholder Liaison official. This official said that Stakeholder Liaison also uses this information to produce daily management reports to keep leadership apprised of the number of incidents reported daily, as well as the cumulative number of affected preparers and taxpayers during the year and a comparison to data from the previous year. Return Integrity and Compliance Services (RICS) officials use a risk- based method to determine the necessary mitigation and treatment plans following a security incident. For example, RICS officials might assess a security incident as high risk, meaning that a taxpayer\u2019s personal, financial, and tax data were compromised. For such an incident, RICS officials place the affected Taxpayer Identification Numbers (TIN) on Dynamic Selection Lists\u2014lists of TINs affected in breaches and at risk of tax-related identity theft\u2014to monitor future tax return filings for potential fraud. On the other hand, for low-risk incidents\u2014incidents where fraudsters may have accessed information like street address or date of birth but not Social Security numbers\u2014RICS may compare victims\u2019 current tax returns with prior returns to look for differences that could indicate possible identity theft. According to RICS officials, the office also runs individuals\u2019 information through fraud filters to help identify returns with a high likelihood of identity theft. Criminal Investigation\u2019s (CI) Cybercrimes unit shares security incident information with the field offices where the incident occurred, according to CI officials. Area coordinators evaluate the incident information and determine whether a criminal case should be developed. If so, coordinators develop a fraud scheme package and provide it to the agent assigned to the case to help identify other potential incidents resulting from similar schemes, according to CI officials. IRS has primarily tracked information on security incidents in its RICS Incident Management Database since December 2016, according to RICS officials. Security incidents can be categorized in a number of ways, such as when hackers infiltrate third-party providers\u2019 systems. Between 2017 and 2018, there was an overall decrease in the number of reported high-risk security incidents that led to confirmed identity theft victims across all types of security incidents. However, the number of reported security incidents from third-party providers increased about 50 percent during this same period, as shown in table 4. In turn, the number of taxpayers affected by the security incidents at third-party providers also increased. However, IRS does not have comprehensive information about the incidents because, in part, its reporting requirements do not apply to all third-party providers. For example, the Authorized e-file Provider program requires only online providers to report security incidents to IRS as soon as possible but no later than the next business day after confirmation of the incident. The information that online providers are to report includes details about the security incident and the affected taxpayers\u2019 accounts. If paid preparers or EROs experience a security incident at their place of business, they are not required to report any information to IRS about the incident; instead, IRS encourages paid preparers to share security incident information with IRS through Stakeholder Liaison. Additionally, IRS cannot track incidents that third-party providers do not report, according to IRS officials. IRS officials and industry representatives stated that some third-party providers may not report security incidents for fear of punishment from IRS (e.g., penalties, sanctions, or removal from the Authorized e-file Provider program) or negative impacts to their business reputation. IRS has other voluntary reporting mechanisms for tax software providers or other members of the tax preparation industry. For example, members of the Security Summit can use a voluntary reporting mechanism to submit information to RICS. Some members of the Security Summit can use an additional voluntary reporting system in the ISAC online platform, which sends alerts about security incidents to others in the platform. IRS also recently revised some of its requirements that could affect paid preparers\u2019 reporting of security incidents while using other IRS services. For example, in October 2018, the agency updated its user agreement for e-Services, a suite of web-based tools that allow paid preparers, among others, to complete transactions online with IRS. This update included a requirement to report any unauthorized use of the e-Services account or any other breach of security as soon as users become aware of the incident. According to Internal Control Standards, agencies should use quality information, both internal and external, to achieve objectives. For example, agencies should obtain data on a timely basis so that they can be used for effective monitoring. Additionally, recommended controls in NIST Special Publication 800-53 require reporting of suspected security incidents by federal agencies and their subordinate organizations. Though IRS conducts a yearly review of requirements for Authorized e- file Providers to find needed updates, the incident reporting requirement has not been identified as needing updates since 2010, according to a senior Wage and Investment official. This is another instance where centralized leadership could have identified a need to update the incident reporting requirements. According to an EPSS official, IRS originally applied this incident reporting requirement to only online providers because these providers stored a large amount of data and carried the highest risk of data loss. Similarly, IRS officials said the reporting requirement for online providers does not apply to providers of tax software used by paid preparers because those software providers do not collect or store taxpayer information on their systems. Instead, the taxpayer information is stored on a paid preparer\u2019s hard drive. If a security incident occurred at the business of a paid preparer who uses tax software, then the preparer, not the tax software provider, would report that incident to IRS, according to IRS officials. While voluntary reporting mechanisms and updating of user agreements for IRS\u2019s website are important steps, without a clear and standardized reporting requirement for all types of providers, IRS will not have assurance that third-party providers consistently report their security incidents in a timely manner. IRS needs this information to better understand the size and scope of information security incidents, which it uses to protect compromised individual taxpayer accounts and prevent identity theft refund fraud. Security incident information can be reported to IRS through various channels from the public to IRS offices, and the data are ultimately stored in the RICS Incident Management Database regardless of the office that initially received the information. Figure 5 depicts the flow of information from the public to IRS offices, as well as the flow of information between the offices and to IRS databases. While RICS has documented its information intake, tracking, and storage processes in the RICS Incident Management Plan, IRS does not have a comprehensive document that describes these processes across the different IRS offices. For example, incident information submitted to EPSS and Stakeholder Liaison eventually moves to RICS to be tracked in the Incident Management Database. Additionally, RICS officials told us that they track each of these reported incidents separately and that the main repository should not contain duplicate reports of the same incidents, though multiple databases may contain information about the same incident. RICS officials added that, before a new incident is added to the Incident Management Database, staff conduct a query in the database to ensure that the incident was not already added. However, IRS has not documented how the security incident data processes should flow, relying instead on informal communication efforts of the staff and the assumption that staff know where the data belong and will provide that information to the appropriate offices. Internal Control Standards state that management should develop and maintain documentation of its internal control system and implement control activities through policies. The standards also state that documentation of responsibilities through policies and periodic review of activities can contribute to the effectiveness of implementation. This limited nature of the documentation may be due to the newness of some of these data processes. For example, a Stakeholder Liaison official told us that the data intake process for Stakeholder Liaison and entry into the Return Preparers Database started at the beginning of 2018. Prior to that, a Stakeholder Liaison manager stored information about security incidents in an individual email account because there was no mechanism for storing the data in a systematic manner. Further, a senior Wage and Investment Division official stated that the processes to intake, store, and share the data among the different IRS offices continue to evolve, and that documents describing these practices may quickly become obsolete. While these processes may still be evolving, documenting them can help IRS combat identity theft by helping to ensure that security incidents are properly recorded and monitored in the IRS systems. Documenting the processes may also allow for more complete data, as the data would follow a specific routing and review process. This would reduce the risk of the data not following the various channels they go through now. Such documentation can also help IRS retain organizational knowledge, mitigate the risk of having that knowledge limited to a few personnel, and ensure that the agency implements these processes effectively in the future. Tens of millions of taxpayers use third-party providers, such as paid preparers or tax software providers, to comply with their federal income tax obligations. It is critical that taxpayers\u2019 information, which includes personally identifiable and other sensitive information, be kept secure to maintain public confidence and avoid data breaches that expose that information for use by fraudsters. Identity theft is a constantly evolving crime, but IRS\u2019s information security standards for third-party providers\u2019 systems have not kept pace with the changing environment. One reason for this is that IRS lacks the explicit authority to require minimum standards for the systems of paid preparers and Authorized e-file Providers. Without this authority, Congress and IRS have limited assurance that the processes used to collect, store, and submit taxpayers\u2019 returns adequately protect taxpayers\u2019 information against electronic data breaches and potential tax refund fraud. Modifying its Authorized e-file Provider program requirements to explicitly state the elements of an information security program as required under the FTC Safeguards Rule would help IRS ensure that Authorized e-file Providers are aware of, and comply with, the rule. Doing so could also help these providers better protect taxpayers\u2019 information. Additionally, IRS is missing an opportunity to capitalize on the achievements of Security Summit members to help ensure that tax software providers have an equivalent level of standards in place to adequately protect taxpayer information. The lack of centralized leadership at IRS with responsibility for coordinating all aspects of protecting taxpayer information held by third- party providers has enabled missed opportunities. Such designated leadership could help ensure greater collaboration between the various IRS offices that have roles to play in this area. This leadership could have also ensured that security standards for online providers in the Authorized e-file Provider program would have been updated. Instead, IRS introduced these standards in 2010 and has not subsequently updated them. Incorporating cybersecurity into its monitoring visits for EROs would provide IRS with greater assurance that EROs\u2019 systems are adequately protecting taxpayers\u2019 information from an increased risk of both tax- related and non-tax-related identity theft. Further, ensuring that IRS is using a risk-based approach to review all types of Authorized e-file Providers would provide assurance that the greatest risk areas of fraud are addressed appropriately. Finally, IRS\u2019s efforts to protect taxpayer information at third-party providers would also be strengthened by greater consistency in requirements across provider types for reporting security incidents. Greater consistency would help to ensure IRS is obtaining timely and reliable information from third-party providers so IRS can better understand the size and scope of security incidents\u2014data it uses to protect compromised individual taxpayer accounts and prevent identity theft refund fraud. Documenting the intake, storage, and sharing of the security incident data would also help IRS ensure that the security incidents are properly recorded and monitored. Congress should consider providing IRS with explicit authority to establish security requirements for the information systems of paid preparers and Authorized e-file Providers. (Matter for Consideration 1) We are making the following eight recommendations to IRS. The Commissioner of Internal Revenue should develop a governance structure or other form of centralized leadership, such as a steering committee, to coordinate all aspects of IRS\u2019s efforts to protect taxpayer information while at third-party providers. (Recommendation 1) The Commissioner of Internal Revenue should modify the Authorized e- file Provider program\u2019s requirements to explicitly state the required elements of an information security program as provided by the FTC Safeguards Rule. (Recommendation 2) The Commissioner of Internal Revenue should require that all tax software providers that participate in the Authorized e-file Provider program follow the subset of NIST Special Publication 800-53 controls that were agreed upon by the Security Summit participants. (Recommendation 3) The Commissioner of Internal Revenue should regularly review and update the security requirements that apply to tax software providers and other Authorized e-file Providers. (Recommendation 4) The Commissioner of Internal Revenue should update IRS\u2019s monitoring programs for electronic return originators to include techniques to monitor basic information security and cybersecurity issues. Further, IRS should make the appropriate revisions to internal guidance, job aids, and staff training, as necessary. (Recommendation 5) The Commissioner of Internal Revenue should conduct a risk assessment to determine whether different monitoring approaches are appropriate for all of the provider types in the IRS\u2019s Authorized e-file Provider program. If changes are needed, IRS should make appropriate revisions to the monitoring program, internal guidance, job aids, and staff training, as necessary. (Recommendation 6) The Commissioner of Internal Revenue should standardize the incident reporting requirements for all types Authorized e-file Providers. (Recommendation 7) The Commissioner of Internal Revenue should document intake, storage, and sharing of the security incident data across IRS offices. (Recommendation 8) We provided a draft of this report to the Commissioner of Internal Revenue for review and comment. In its written comments, which are summarized below and reproduced in appendix III, IRS agreed with three of the recommendations and disagreed with five of the recommendations. IRS also provided technical comments, which we incorporated as appropriate. IRS agreed with our recommendations to regularly review and update the security requirements that apply to the tax software provider and other Authorized e-file Providers; standardize the incident reporting requirements for all types of Authorized e-file Providers; and document intake, storage, and sharing of the security incident data across IRS offices. IRS did not provide additional detail on the actions it plans to take to address these recommendations. IRS disagreed with five of our recommendations, generally citing for all of them the lack of clear and explicit authority it would need to establish security requirements for the information systems of paid preparers and others who electronically file returns. For our recommendation to develop a governance structure or other form of centralized leadership, IRS stated it would require statutory authority that clearly communicates its authority to establish security requirements for the information systems of paid preparers and others who electronically file tax returns. Further, IRS stated that without such authority, implementing the recommendation would be an inefficient, ineffective, and costly use of resources. We disagree that convening a governance structure or other centralized form of leadership would require additional statutory authority or be inefficient, ineffective, and costly. As discussed in the report, IRS has seven different offices across the agency working on information security-related activities that could benefit from centralized oversight and coordination, such as updating existing standards, monitoring Authorized e-file Provider program compliance, and tracking security incident reports. We continue to believe that establishing a governance structure would help provide this level of leadership, coordination, and collaboration to IRS\u2019s current efforts and therefore help alleviate the missed opportunities that we identified in the report, such as updating outdated security standards. Further, IRS could choose a leadership mechanism that it determines to be low cost and most efficient to gain a higher degree of coordination. Without this structure, it is unclear how IRS will adapt to changing security threats in the future and ensure those threats are mitigated. In our draft report, we made a recommendation that IRS modify the Authorized e-file Provider program to be consistent with the FTC Safeguards Rule. In its response, IRS stated that it did not have explicit authority to establish policy consistent with the FTC Safeguards Rule or enforce compliance with it. However, IRS clearly states in its Revenue Procedure 2007-40 that violations of the provisions of the Gramm-Leach- Bliley Act and the implementing rules and regulations promulgated by FTC are considered violations of the revenue procedure and may subject an Authorized e-file Provider to penalties or sanctions. Therefore, we believe IRS has already incorporated compliance with the FTC Safeguards Rule as part of its Authorized e-file Provider program. The intent of this recommendation is not to suggest that IRS develop new policies related to the elements of the Safeguards Rule. Instead, we believe IRS has the opportunity to explicitly state in its requirements for Authorized e-file Providers the elements of an information security program, as listed in the Safeguards Rule. This action will help third party providers become aware of their specific legal obligations to protect taxpayer data under the Gramm-Leach-Bliley Act. As such, we clarified text in the body of the report and the text of the recommendation to better reflect our intent. For our recommendation to require all tax software providers that participate in the Authorized e-file Provider program to follow the subset of NIST Special Publication 800-53 controls that were agreed upon by the Security Summit participants, IRS stated that it does not have the statutory authority for such a requirement. However, under its existing authority, IRS has already established some information security requirements for a portion of tax software providers\u2014those that are online providers. IRS has the opportunity to further establish standards for all tax software providers by incorporating the subset of NIST controls into its Authorized e-file Provider program, which would capitalize on the work it has completed with the Security Summit members. We continue to believe that without setting and requiring the same security standards for all tax software providers, IRS does not have assurance that these providers have an equivalent level of standards in place to adequately protect taxpayer information. For our recommendation that IRS update its monitoring programs for electronic return originators, IRS stated it does not have the statutory authority to establish policy on information security and cybersecurity issues, nor to enforce compliance if noncompliance is observed. However, as we reported, IRS already monitors physical aspects of information security, which goes beyond existing Authorized e-file Provider program requirements. Since most individuals now file tax returns electronically, having checks for physical security without comparable checks for cybersecurity does not address current risks, as cyber criminals and fraudsters are increasingly attacking third-party providers, as IRS has noted. We believe that incorporating some basic cybersecurity monitoring into the visits would provide IRS the opportunity to help inform the most vulnerable third-party providers of additional guidance and resources. For our recommendation to conduct a risk assessment to determine whether different monitoring approaches are appropriate for all of the provider types in the Authorized e-file Provider program, IRS stated that changes to the monitoring program would not have value to the overall program performance absent statutory authority. We disagree with this conclusion. As discussed in the report, IRS does not currently systematically monitor the existing security requirements for online providers, nor does it conduct information security or cybersecurity monitoring for all types of Authorized e-file Providers. We believe that IRS could conduct a risk assessment of its current monitoring program within existing statutory authority and make necessary changes that would provide better assurance that all types of providers are receiving some level of oversight and that IRS is addressing the greatest risk areas appropriately. We are sending copies to the Chairmen and Ranking Members of other Senate and House committees and subcommittees that have appropriation, authorization, and oversight responsibilities for IRS. We are also sending copies of the report to the Commissioner of Internal Revenue and other interested parties. In addition, this report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact me at (202) 512-9110 or Lucasjudyj@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs are on the last page of this report. GAO staff who made key contributions to this report are listed in appendix IV. Our objectives were to (1) assess what is known about the taxpayer information security requirements for the systems used by third-party providers, (2) describe Internal Revenue Service\u2019s (IRS) outreach efforts to third-party providers on the requirements, (3) assess IRS\u2019s monitoring processes for ensuring third-party providers\u2019 compliance with the requirements, and (4) assess IRS\u2019s requirements for third-party provider security incident reporting and how IRS uses that information. To assess what is known about the taxpayer information security requirements for the systems used by third-party providers, such as paid preparers and tax software providers, we reviewed applicable laws and regulations such as the Gramm-Leach-Bliley Act and relevant portions of the Internal Revenue Code, including 26 U.S.C. \u00a7 6011. This section of the Internal Revenue Code prescribes the filing of income tax returns, as well as the electronic filing requirements for returns prepared by paid preparers. We reviewed 26 U.S.C. \u00a77803, which provides that the IRS Commissioner has the authority to administer and manage the execution and application of tax laws, while balancing the rights of, among other things, confidentiality and privacy of the taxpayer. We also reviewed the Federal Trade Commission\u2019s (FTC) Safeguards Rule, which requires financial institutions, including tax return preparers, affiliates, and service providers, to ensure the security and confidentiality of customer records and information. This rule applies to those who are significantly engaged in providing financial products or services that include preparation and filing of tax returns. We reviewed IRS Revenue Procedure 2007-40, which informs Authorized e-file Providers of their obligations to IRS, taxpayers, and other participants in the Authorized e-file Provider program and outlines the rules governing filing electronically with IRS. We reviewed IRS publications describing the obligations in IRS\u2019s Revenue Procedure 2007-40 and the requirements of the Authorized e- file Provider program, including IRS Publication 3112, IRS e-file Application and Participation, and IRS Publication 1345, Handbook for Authorized IRS e-file Providers of Individual Income Tax Returns. We assessed these documents to determine if the requirements for third- party providers were incorporating the laws and following leading practices as outlined by Standards for Internal Control in the Federal Government (Internal Control Standards) and A Framework for Managing Fraud Risk in Federal Programs (Fraud Risk Framework). The Fraud Reduction and Data Analytics Act of 2015, and Office of Management and Budget guidance implementing its provisions, affirm that agencies should adhere to the leading practices identified in our Fraud Risk Framework. We also compared the standards published in Publication 1345 for online providers to the National Institute of Standards and Technology (NIST) Special Publication 800-52: Guidelines for the Selection, Configuration, and Use of Transport Layer Security (TLS) Implementations to determine if the standards were following leading practices. We reviewed the subset of NIST Special Publication 800-53: Security and Privacy Controls for Federal Information Systems and Organizations controls that the Security Summit members agreed to voluntarily implement. We also reviewed other IRS publications that provide third-party providers with descriptions of leading practices in keeping taxpayer information safe, including IRS Publication 4557, Safeguarding Taxpayer Data: A Guide for Your Business; IRS Publication 4600, Tips for Safeguarding Taxpayer Data; IRS Publication 5293, Protect Your Clients; Protect Yourself: Data Security Resource Guide for Tax Professionals; and IRS Publication 5294, Protect Your Clients; Protect Yourself: Data Security Tips for Tax Professionals. In assessing these documents, we identified the extent of consistency among publications. We interviewed IRS officials who were responsible for various aspects of IRS\u2019s security requirements for paid preparers and tax software providers. We conducted semistructured interviews with the following 10 industry groups and related organizations that represented a cross section of the tax preparation industry to determine their knowledge about existing information security requirements. American Coalition for Taxpayer Rights American Institute of Certified Public Accountants Council for Electronic Revenue Communication Advancement Electronic Tax Administration Advisory Committee Federation of Tax Administrators National Association of Tax Professionals National Society of Tax Professionals We reviewed IRS organization documents, including organizational charts and associated Internal Revenue Manual (IRM) provisions for the offices that have responsibilities for securing taxpayer information. We reviewed the stated missions of the offices of Electronic Products and Services Support (EPSS); Small Business/Self-Employed; Return Integrity and Compliance Services (RICS); Criminal Investigation (CI); Return Preparer Office; Office of Professional Responsibility; Cybersecurity; and Stakeholder Liaison. We also interviewed officials from these offices to determine how they coordinated the responsibilities for overseeing the security of taxpayer data among the offices. We compared IRS activities to the Internal Control Standards that identify controls that help an entity adapt to shifting environments, evolving demands, changing risks, and new priorities. To describe the outreach efforts IRS takes for third-party providers, we reviewed IRS outreach documents such as publications, news releases, social media posts, emails, webinars, and online education campaigns. We interviewed IRS officials and conducted semistructured interviews with 10 industry groups and related organizations to determine IRS\u2019s communication efforts related to security standard enforcement and identify potential challenges that IRS faces in its outreach. To assess IRS\u2019s monitoring processes for ensuring third-party providers\u2019 compliance with information security requirements, we reviewed the agency\u2019s monitoring procedures for the Authorized e-file Provider program per Rev. Proc. 2007- 40; IRS Publication 3112, IRS e-file Application and Participation; and IRS Publication 1345, Handbook for Authorized IRS e-file Providers of Individual Income Tax Returns. We reviewed the IRM section related to Monitoring the IRS e-file Program, monitoring checklists, and related job aides to determine the extent to which monitoring practices address security requirements in IRS Publication 1345. We assessed IRS\u2019s monitoring efforts against our Fraud Risk Framework\u2019s principles to combat fraud in a strategic, risk- based manner. We also interviewed the IRS officials responsible for overseeing the monitoring program. To assess IRS\u2019s requirements for third-party provider reporting of security incidents and how IRS uses that information, we reviewed IRS guidance about security incident reporting requirements. We analyzed IRS data on the number and type of security incidents tracked in the RICS Incident Management Database from 2017 and 2018, the only data available following its creation in December 2016. We interviewed RICS officials about the quality of data in this database and determined that the data were sufficiently reliable to describe a minimum count of security incidents. Specifically, we asked about the responsibilities of officials collecting and using the data, the procedures in place to capture all reported data, and controls for ensuring the accuracy of the data and resolving any errors, among other things. We reviewed IRS guidance and program user agreements to determine security incident reporting requirements for third-party providers. We reviewed IRS process documentation and interviewed IRS officials from EPSS, RICS, CI, Return Preparer Office, Cybersecurity, and Stakeholder Liaison to determine the collection, routing, and storage processes for security incident information. We assessed IRS\u2019s processes and documentation practices against leading practices outlined in NIST Special Publication 800-53 and Internal Control Standards. We interviewed IRS officials to identify ways that IRS uses this security incident information. We conducted semistructured interviews with the 10 industry groups and related organizations listed above to determine their knowledge about existing security incident reporting requirements. We conducted this performance audit from November 2017 to May 2019 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. The Internal Revenue Service (IRS) mandated that online providers adhere to six privacy, security, and business standards as part of the Authorized e-file Provider program, as listed in table 6. These standards have not been updated since they were developed in 2010. In addition to the contact named above, Jeff Arkin (Assistant Director), Robyn Trotter (Analyst-in-Charge), Christina Bixby, Alyssia Borsella, Mark Canter, Jehan Chase, Larry Crosland, Ann Czapiewski, James Andrew Howard, Michele Fejfar, and Robert Gebhart made key contributions to this report.", "summary": "Third-party providers, such as paid tax return preparers and tax preparation software providers, greatly impact IRS\u2019s administration of the tax system. If these third parties do not properly secure taxpayers\u2019 personal and financial information, taxpayers will be vulnerable to identity theft refund fraud and their sensitive personal information will be at risk of unauthorized disclosure. IRS estimates that it paid out at least $110 million in identity theft tax refund fraud during 2017, and at least $1.6 billion in identity theft tax refund fraud during 2016. GAO was asked to review IRS\u2019s efforts to track, monitor, and deter theft of taxpayer information from third parties. Among other things, this report assesses what is known about the taxpayer information security requirements for the systems used by third-party providers, IRS\u2019s processes for monitoring compliance with these requirements, and IRS\u2019s requirements for third-party security incident reporting. GAO analyzed IRS\u2019s information security requirements, standards, and guidance for third-party providers and compared them to relevant laws, regulations, and leading practices, such as NIST guidance and Standards for Internal Control in the Federal Government . GAO reviewed IRS\u2019s monitoring procedures and its requirements and processes for third-party reporting of security incidents, and compared them to Internal Control Standards and GAO\u2019s A Framework for Managing Fraud Risk in Federal Programs . GAO also interviewed IRS and tax industry group officials. Federal law and guidance require that the Internal Revenue Service (IRS) protect the confidentiality, integrity, and availability of the sensitive financial and taxpayer information that resides on its systems. However, taxpayer information held by third-party providers\u2014such as paid tax return preparers and tax preparation software providers\u2014generally falls outside of these requirements, according to IRS officials. In 2018, about 90 percent of individual taxpayers had their tax returns electronically filed by paid preparers or used tax preparation software to prepare and file their own returns. IRS seeks to help safeguard electronic tax return filing for various types of third-party providers through requirements under its Authorized e-file Provider program. However, IRS\u2019s efforts do not provide assurance that taxpayers\u2019 information is being adequately protected. Paid Preparers. IRS has not developed minimum information security requirements for the systems used by paid preparers or Authorized e-file Providers. According to IRS\u2019s Office of Chief Counsel, IRS does not have the explicit authority to regulate security for these systems. Instead, the Internal Revenue Code gives IRS broad authority to administer and supervise the internal revenue laws. The Department of the Treasury has previously requested additional authority to regulate the competency of all paid preparers; GAO has also suggested that Congress consider granting IRS this authority. Congress has not yet provided such authority. Neither the Department of the Treasury request nor the GAO suggestion included granting IRS authority to regulate the security of paid preparers\u2019 systems. Having such authority would enable IRS to establish minimum requirements. Further, having explicit authority to establish security standards for Authorized e-file Providers\u2019 systems may help IRS better ensure the protection of taxpayers\u2019 information. Tax Software Providers. As part of a public-private partnership between IRS and the tax preparation industry, 15 tax software providers voluntarily adhere to a set of about 140 information security controls developed using guidance from the National Institute of Standards and Technology (NIST). However, these controls are not required, and these providers represent only about one-third of all tax software providers. Additionally, IRS established six security, privacy, and business standards for providers of software that allows individuals to prepare their own tax returns (as opposed to software that paid preparers use). However, IRS has not substantially updated these standards since 2010, and they are, at least in part, outdated. For example, IRS cites an outdated encryption standard that NIST recommends not using due to its many known weaknesses. A key factor contributing to missed opportunities to address third-party cybersecurity is IRS\u2019s lack of centralized leadership. Consequently, IRS is less able to ensure that third-party providers adequately protect taxpayers\u2019 information, which may result in identity theft refund fraud. IRS monitors compliance with its electronic tax return filing program requirements for those paid preparers who electronically file returns; however, IRS\u2019s monitoring has a limited focus on cybersecurity issues. For example, the monitoring techniques largely focus on physical security (e.g., locked filing cabinets) rather than verifying that preparers have an information security policy consistent with NIST-recommended controls. Without effective monitoring of cybersecurity controls, IRS has limited assurance that those paid preparers\u2019 systems have adequate controls in place to protect clients\u2019 data. IRS recently began collecting information on high-risk security incidents, such as hackers infiltrating third-party provider systems. Reported incidents increased from 2017 to 2018, the only years for which IRS has data. However, IRS does not have a full picture of the scope of incidents because of inconsistent reporting requirements, including no reporting requirements for paid preparers. GAO suggests that Congress consider providing IRS with explicit authority to establish security requirements for paid preparers\u2019 and Authorized e-file Providers\u2019 systems. GAO is also making eight recommendations, including that the Commissioner of Internal Revenue Develop a governance structure or other form of centralized leadership to coordinate all aspects of IRS\u2019s efforts to protect taxpayer information while at third-party providers. Require all tax software providers to adhere to prescribed information security controls. Regularly review and update security standards for tax software providers. Update IRS\u2019s monitoring programs to include basic cybersecurity issues. Standardize incident reporting requirements for all types of third-party providers. IRS agreed with three recommendations, including the above recommendations to regularly review and update security standards for tax software providers, and standardize incident reporting requirements. IRS disagreed with five recommendations\u2014including the other three listed above\u2014generally citing the lack of clear and explicit authority it would need to establish security requirements for the information systems of paid preparers and Authorized e-file Providers. GAO believes that IRS can implement these recommendations without additional statutory authority."}
{"id": "govreport_8", "report": "The Child Care and Development Block Grant (CCDBG) Act, as amended, is the main federal law governing state child-care programs for low-income working families. The act was reauthorized in 2014, and the reauthorization included a focus on improving the overall quality of child- care services and development of participating children. In September 2016, OCC published new rules (CCDF regulations) to provide clarity to states on how to implement this law and administer the program in a way that best meets the needs of children, child-care providers, and families. The CCDBG Act and CCDF regulations allow states flexibility in developing CCDF programs and policies that best suit the needs of children and parents within that state. According to OCC, these new rules also align child-care requirements with new Head Start regulations, including certain requirements for background checks, annual monitoring, and prelicensure inspections for some CCDF providers. OCC also added regulatory requirements for state lead agencies to describe in their State Plans effective internal controls that are in place to ensure integrity and accountability including 1. processes to ensure sound fiscal management, 2. processes to identify areas of risk, 3. processes to train child-care providers and staff of the lead agency and other agencies engaged in the administration of the CCDF about program requirements and integrity, and 4. regular evaluation of internal control activities. Lead agencies are also required to describe in their State Plans the processes that are in place to identify fraud or other program violations, and to investigate and recover fraudulent payments and to impose sanctions in response to fraud. OCC is a program office within ACF that works with the states to administer the CCDF program. OCC and states each have responsibility for overseeing and protecting the integrity of the CCDF program. Each state must develop, and submit to OCC for approval, a State Plan that identifies the purposes for which CCDF funds will be spent for a 3-year grant period and designates a lead agency responsible for administering child-care programs. To administer CCDF funds, federal law and regulations require that states report their CCDF expenditures and data on the number of children served by CCDF subsidies. The current reporting structure as described by OCC and ACF officials is shown in figure 1. To request funding from the CCDF, states submit a State Plan for administering their CCDF programs to OCC. OCC provides states with a Plan Preprint, which serves as a template and includes instructions and guidance on developing the State Plans and providing information required by law and regulations. Further, OCC has used the Plan Preprint to request additional information from the states. The Plan Preprint developed for fiscal years 2019\u20132021 State Plans consists of eight sections and is the first to include the new CCDF regulatory requirements, added in September 2016 as required by the 2014 reauthorization. One of the new requirements is for state lead agencies to describe in their State Plans effective internal controls that are in place to ensure integrity and accountability. In addition, OCC modified the Plan Preprint for fiscal years 2019\u20132021 State Plans to add the instruction requesting states to report information about the results of their program-integrity and fraud- fighting activities, in addition to providing descriptions of the activities themselves. The Secretary of Health and Human Services, through OCC, has the responsibility to approve State Plans that satisfy the requirements, and review and monitor state compliance with the approved State Plan. According to OCC officials, the Program Operations Division within OCC, in partnership with the OCC regional program unit staff (regional offices), reviews the State Plans and approves those that they determine have satisfied the requirements of the CCDBG Act and CCDF regulations. The CCDF has been designated as a high-priority program, as defined by OMB, under the Improper Payments Elimination and Recovery Improvement Act of 2012 (IPERIA), meaning that it is a program susceptible to significant improper payments. Federal statutes require federal agencies to evaluate programs for improper-payment risk and, for programs susceptible to significant improper payments, to report on actions taken to reduce improper payments. CCDF regulations implement these requirements by requiring states to calculate and report estimates of their improper payments, including proposed actions to address sources of error. These reports are developed by the states on a 3-year rotational cycle, and HHS reports the aggregate results in its Agency Financial Report. The CCDF gross improper payment estimate for fiscal year 2019 is approximately $325 million, and the estimated improper payment rate is 4.53 percent. OCC oversees states\u2019 compliance with the prescribed procedures for estimating improper-payment error rates by approving the preliminary documents, approving any changes to the case samples, conducting the Joint Case Reviews, and reviewing and approving the final State Improper Payments Report and CAP submissions. If a state reports an error rate at or above 10 percent, it must also submit a CAP, which includes detailed descriptions of specific activities planned to reach a targeted reduction in errors. It must then submit an update on its progress and a new CAP the following year if it has not completed the proposed corrective actions or if the error rate is still at or above 10 percent. The improper-payment reporting process is illustrated in figure 2. In fiscal year 2019, OCC launched a formal Monitoring System to review a selection of states annually over the course of the 3-year State Plan period. According to OCC officials, the three main purposes of the Monitoring System are to: (1) ensure compliance with the CCDBG Act, CCDF regulations, and the approved State Plans; (2) identify state technical-assistance needs; and (3) identify promising practices to inform continuous quality improvement. The Monitoring System focuses on 11 topic areas, which include program integrity and accountability. In addition, other topic areas include disaster preparedness, consumer education, and health and safety requirements. OCC officials told us that monitoring is completed on a rolling basis, and that they plan to monitor one-third of states each fiscal year, from fiscal years 2019 to 2021. According to OCC officials, they scheduled the monitoring to ensure that a state will not be submitting an improper- payment report in the same year that it participates in the monitoring. Figure 3 provides additional details regarding the OCC Monitoring System process, which includes an on-site visit to monitored states. Fraud and \u201cfraud risk\u201d are distinct concepts. Fraud risk exists when individuals have an opportunity to engage in fraudulent activity, have an incentive or are under pressure to commit fraud, or are able to rationalize committing fraud. Although the occurrence of fraud indicates there is a fraud risk, a fraud risk can exist even if fraud has not yet been identified or occurred. For example, suspicious billing patterns or complexities in program design may indicate a risk of fraud even though fraud has not been identified or occurred. When fraud risks can be identified and mitigated, fraud may be less likely to occur. According to federal standards and guidance, executive-branch agency managers are responsible for managing fraud risks and implementing practices for combating those risks. Specifically, federal internal control standards state that management should consider the potential for fraud when identifying, analyzing, and responding to risks. As part of these standards, management assesses risks the entity faces from both external and internal sources. In addition, in July 2015, GAO issued the Fraud Risk Framework, which provides a comprehensive set of key components and leading practices that serve as a guide for agency managers to use when developing efforts to combat fraud in a strategic, risk-based way. The Fraud Risk Framework describes leading practices in four components, as shown in figure 4. The Fraud Reduction and Data Analytics Act of 2015, enacted in June 2016, required OMB to establish guidelines for federal agencies to create controls to identify and assess fraud risks, and design and implement antifraud control activities. The act further required OMB to incorporate the leading practices from the Fraud Risk Framework in the guidelines. In July 2016, OMB published guidance about enterprise risk management and internal controls in federal executive departments and agencies. Among other things, this guidance affirms that managers should adhere to the leading practices identified in the Fraud Risk Framework. As part of its oversight of states\u2019 CCDF programs, OCC reviewed and approved State Plans for the current grant period (fiscal years 2019\u2013 2021). However, OCC has not established written policies to guide staff review and approval of these State Plans, a process that occurs every 3 years. OCC\u2019s lack of established policies limits its ability to ensure that staff follow appropriate protocols for consistency when reviewing and approving State Plans and to retain organizational knowledge in the event of staff turnover, which OCC noted as occurring during each review period. Further, OCC requested that states report information about the results of states\u2019 program-integrity activities. However, most of the State Plans that it approved did not provide the results of states\u2019 program- integrity activities as requested. OCC officials told us that they plan to continue to request that states report on the results of their program- integrity activities, but OCC has not identified what it considers to be \u201cresults\u201d of program-integrity activities. Without taking additional steps to define its informational needs and encourage states to report the results of their program-integrity activities, OCC will not have this information to help determine whether states are effectively ensuring the integrity of the CCDF program. To provide oversight of states\u2019 CCDF program-integrity activities, OCC reviewed and approved State Plans for the current grant period, covering fiscal years 2019\u20132021. To do so, OCC officials described to us a process that began with a high-level review of the draft State Plans submitted through an electronic system. After an initial review for completeness, OCC staff focused on the contents of the State Plans including states\u2019 responsiveness to each requirement. For example, one requirement is to describe the processes that the state will use to identify risk in its CCDF program. OCC officials also stated that they consider clarity, consistency, and compliance when assessing State Plans. OCC officials also explained that they reviewed the responses to determine whether they were sufficiently detailed, and sought clarification from the states when necessary. OCC officials stated that, prior to the final approval of the State Plans, staff completed a validation form that consists of a table listing the State Plan subsections with checkboxes next to each subsection. Figure 5 outlines the timeline for review and approval of State Plans. OCC has developed a draft procedure for the State Plan review and approval process, but had neither finalized written policies before beginning its review of the fiscal years 2019\u20132021 State Plans, nor finalized written policies for future review periods that occur every 3 years. Instead, OCC officials told us that for the review and approval process completed in 2018, they provided their staff a variety of training materials and draft documents that encouraged discussion among those involved. These documents contained information and guidance on the process, such as explaining the overall operational processes for reviewing and approving State Plans and general roles and responsibilities. However, none of the documents were finalized as OCC\u2019s written policies for staff to follow when implementing the fiscal years 2019\u20132021 State Plan review and approval process, or for subsequent review periods. In response to our request for finalized policies pertaining to how OCC reviewed and approved State Plans, OCC provided documents that have substantial limitations for explaining to OCC staff how they should review and approve State Plans. For example, OCC provided what it characterized as a three-page summary protocol, which, in part, contained a historical record of what occurred during the recently completed review period rather than guidance that would help OCC achieve its State Plan review objectives on a continuous basis. Specifically, the protocol describes the regular internal meetings and interactions that OCC staff had from September 2018 to December 2018. As such, the protocol does not describe the process that OCC staff should follow, or the meetings that should occur, when reviewing and approving State Plans in future years (i.e., on a continuous basis). OCC also developed in August 2018 a more-detailed draft procedure for reviewing and approving State Plans. The draft procedure contains information on the communication process between the central and regional offices, recognizes that there may be variation in internal processes among regional offices and from one review period to the next, and includes guidance on steps for resolving questions about State Plans, among other guidance. Unlike the three-page summary protocol, the draft procedure explicitly states its applicability to future review periods as well as the current State Plan review period, and therefore would have provided guidance for staff on a continuous basis had a finalized version been shared with staff and established as OCC\u2019s written policies. However, because of the volume of work and differences in caseloads among regional offices, OCC officials stated that they did not share a finalized procedure with staff and that staff were neither expected nor required to use the draft procedure when conducting their review of State Plans for the fiscal years 2019\u20132021 review period. As such, this draft procedure did not represent the formal policies for staff to follow in performing their roles. In explaining why it relies on the three-page summary protocol and draft procedure rather than finalized written policies to guide its State Plan review and approval process, OCC officials stated that OCC needs flexibility in its policies during the review period. Specifically, there are staffing changes in both the central and regional offices for each State Plan review period, and having flexibility within the framework provided by the three-page summary protocol allows them to accommodate those changes. OCC officials noted that some of the processes are unique to each of the 10 regional offices because of differences in their structure, staffing, and caseloads. Likewise, OCC officials stated that the regional offices need flexibility to continuously adjust processes and timelines so that they can accommodate varying responsiveness from states, and evaluate the State Plans without undermining the flexibility afforded to states through the block grant. However, it is possible for OCC to establish written policies to guide processes that are common from one review period to the next, and across all regions, while still maintaining the necessary flexibility to accommodate staffing changes and regional differences, as it had already begun to do by developing its August 2018 draft procedure. In this regard, Standards for Internal Control in the Federal Government states that management should implement control activities through policies. In doing so, management communicates the policies to personnel so that personnel can implement the control activities for their assigned responsibilities. Further, Standards for Internal Control in the Federal Government includes minimum documentation requirements, such as that management develop and maintain documentation of its internal control system. An internal control system is a continuous built-in component of operations that provides reasonable assurance that an entity\u2019s objectives will be achieved. Internal control is not one event, but a series of actions that occur throughout an entity\u2019s operations. Further, internal control is recognized as an integral part of the operational processes management uses to guide its operations, and internal control is built into the entity as a part of the organizational structure to help managers achieve the entity\u2019s objectives on an ongoing basis. As such, documentation of the internal control system should reflect a continuous, built-in component of operations rather than a historical record of a past event. Documentation also provides a means to retain organizational knowledge and mitigate the risk of having that knowledge limited to a few personnel. OCC\u2019s lack of established written policies limits its ability to ensure that staff follow appropriate protocols on a continuous basis when implementing the State Plan review and approval process, and limits its ability to provide a means to retain organizational knowledge and mitigate the risk of having that knowledge limited to a few personnel. Without finalizing written policies, an effort that could include leveraging its previously developed August 2018 draft procedure, OCC risks losing that knowledge each time there are staffing changes among central and regional offices. In response to a 2016 HHS OIG report, OCC has attempted to collect information about the results of states\u2019 program-integrity and fraud- fighting activities by adding a new instruction to the fiscal years 2019\u2013 2021 Plan Preprint requesting states to report such information in their State Plans. Specifically, the HHS OIG recommended that collecting data on program-integrity and fraud-fighting results would be an important step in monitoring states\u2019 efforts to safeguard the CCDF program. Additionally, OCC officials told us that obtaining information on the results of program-integrity activities is important for understanding national trends and helping to inform OCC\u2019s technical assistance to states and ensure states\u2019 accountability over their program-integrity activities. However, our review of 51 approved State Plans found that 43 State Plans (about 84 percent) did not report the results of program-integrity activities as requested (see fig. 6). The other eight states (about 16 percent) reported the results of program-integrity activities. State Plans must meet the requirements set forth in the law and the CCDF regulations to be approved. OCC officials told us that the State Plans were approved without the information on the results of program- integrity activities because, although there are instructions in the Plan Preprint for states to report this information, the CCDF regulations do not require it. Further, OCC officials told us that when OCC submitted the Plan Preprint to OMB for approval under the Paperwork Reduction Act, OCC had indicated that the program-integrity results would be collected on an informational basis, and states would not be required to provide this information. According to an OCC official, only portions of the Plan Preprint with instructions for states to report on the results of program- integrity activities were requested on an informational basis, and all other information in that section was required for approval of the State Plans. OCC officials also told us that OCC will continue to request that states report on the results of their program-integrity activities in the State Plans, but OCC has not defined what information it needs regarding the \u201cresults\u201d of states\u2019 program-integrity activities and has not communicated the need to states or its staff. OCC officials told us that they will ensure that states submit this information by providing guidance to states on the purpose of collecting this information. However, OCC was not able to provide us with a definition or examples of what it considers to be \u201cresults\u201d of program- integrity activities that would be helpful for ensuring states\u2019 accountability over their program-integrity activities. In addition, OCC officials said that OCC did not communicate to states that the information about the results of program-integrity activities was being requested on an informational basis only. According to OCC officials, OCC did not specifically communicate its intention to states because it wanted states to provide a response, if possible. Similarly, OCC had not developed any specific internal criteria for its staff to use when reviewing State Plans to determine whether certain responses were sufficient for their informational needs, such as to better understand national trends. OCC officials also stated that there was no internal written guidance explaining to OCC staff that such information was not required for State Plan approval. Rather, this standard was communicated to staff during weekly meetings. Standards for Internal Control in the Federal Government states that management should use quality information to achieve the entity\u2019s objectives. In doing so, management identifies the information requirements needed and defines the information requirements at the relevant level and requisite specificity for appropriate personnel. Further, Standards for Internal Control in the Federal Government states that management should internally and externally communicate the necessary quality information to achieve the entity\u2019s objectives. In this context, after defining its informational needs regarding the results of program-integrity activities, OCC\u2019s internal and external communication could include communication to the states, which are requested to include this information in the State Plans, and to its staff who will be responsible for analyzing this information. Until OCC defines what information it needs regarding program-integrity activity results, it will be limited in its ability to obtain quality information. By not communicating informational needs to states and staff, OCC will continue to lack quality information about the results of states\u2019 program-integrity efforts and will not be able to use that information to analyze national trends and help ensure states\u2019 accountability over their program-integrity activities, as described. Since 2013, seven states with improper-payment rates at 10 percent or above have submitted 14 corrective action plans (CAP) to OCC for review. However, OCC does not have any documented criteria to guide the review of the CAPs submitted by states to ensure the proposed actions are aimed at root causes of improper payments and are effectively implemented. OCC also has not documented the procedures it uses to follow up with states subject to CAPs, but said it is planning to. Federal improper-payment statutes require federal agencies to review programs susceptible to significant improper-payment risks and develop actions to reduce improper payments. For example, the Improper Payments Elimination and Recovery Act of 2010 (IPERA) specifically requires agencies administering programs that are susceptible to significant improper payments, such as the CCDF, to report on actions the agency is taking to reduce improper payments. Because the CCDF is administered by states, this requirement is implemented in CCDF regulations by requiring states reporting improper-payment error rates at or above 10 percent to develop and implement CAPs. The OMB guidance implementing IPERA states that agencies should ensure that each corrective action is specifically aimed at a root cause of improper payments and that the actions are effectively implemented to prevent and reduce improper payments. According to this guidance, a root cause is something that would directly lead to an improper payment and, if corrected, would prevent the improper payment. In the proposed rulemaking in which OCC introduced the CAPs, OCC stated that the CAPs are intended to be comprehensive and detailed, so as to improve upon the descriptions of corrective actions already reported on a 3-year cycle, which sometimes lack detail or specificity. OCC officials told us that OCC reviewers use their CAP Review Tool to evaluate the CAPs for approval, which also lays out the protocol for conducting reviews. However, the CAP Review Tool does not require reviewers to document whether the corrective actions proposed by states are aimed at root causes of improper payments, or effectively implemented. Further, the written review procedure that accompanies the CAP Review Tool does not contain guidance for reviewers on evaluating whether corrective actions are aimed at root causes and are effectively implemented. OCC officials explained to us that, in their view, states are in the best position to identify the most-feasible approach to corrective actions based on their individual circumstances. We acknowledge that states should have flexibility to identify corrective actions based on their individual circumstances. However, according to OMB guidance, it is federal agencies that are to ensure that corrective actions are aimed at root causes of improper payments and effectively implemented. Further, in the proposed rulemaking in which OCC introduced the CAPs, OCC stated that it intended the CAPs to be used for OCC to hold states accountable as part of its compliance with IPERA. Accordingly, without providing additional guidance to its reviewers, OCC will lack assurance that states\u2019 proposed corrective actions are aimed at root causes and effectively implemented. OCC officials also stated that the majority of the seven states subject to CAPs reduced their error rates over time, specifically to below 10 percent. OCC officials explained that this determination is based on the submission of the State Improper Payment Report for the next required reporting cycle or on states\u2019 voluntarily conducting a review of a sample of cases and submitting the results to OCC to demonstrate they had reduced their error rate to below 10 percent. We did not independently corroborate OCC\u2019s determination because assessing the reliability of the self-attested internal error-rate reviews conducted by certain states and reviewing this information was outside the scope of our work. However, as part of our review of the 14 CAPs that have been submitted to OCC in response to OCC\u2019s improper-payment reviews since 2013, we found that one state was required to submit CAPs for 3 consecutive years and consistently proposed the same error-rate reduction targets, with different dates. This observation underscores the need to ensure the corrective actions a state proposes are specifically aimed at root causes of improper payments and are effectively implemented. OCC does not have guidance in place for its reviewers to determine whether the ongoing corrective actions a state proposes to reduce improper payments will be specifically aimed at root causes of improper payments and effectively implemented. This could leave the CCDF program at continued risk of improper payments. OCC does not have written policies for its CAP follow-up process or documentation that follow-up has been completed for past CAPs. OCC officials told us that they plan to develop such written policies, but officials did not specify a timeline for completion. OCC officials described their process used to monitor states while they are subject to a CAP, which includes additional contact when the same state has been subject to CAPs for consecutive years. This CAP follow-up process is illustrated in figure 7. According to OCC officials, OCC intends to develop written policies for the CAP follow-up process but did not provide a time frame for completion. This will include, at a minimum, a written protocol for the activities illustrated above, which will be included in the next revision of the instructions given to states for improper-payment reporting. According to OCC officials, each region currently has its own process for documenting discussions with CAP states. Having established written policies for the CAP follow-up process will help ensure that OCC\u2019s oversight and monitoring of CAPs is carried out consistently. OCC officials told us that their Monitoring System, initiated in fiscal year 2019, plays a part in OCC\u2019s role to ensure that states\u2019 program-integrity activities are effective. According to OCC officials, OCC uses two tools as part of its Monitoring System\u2014a Compliance Demonstration Packet and Data Collection Tool. States complete the Compliance Demonstration Packet to outline how they propose to demonstrate compliance with regulatory requirements and implementation of the approved State Plans throughout the Monitoring System\u2019s phases. For example, to show effective internal controls are in place to ensure integrity and accountability, states may provide OCC with state or local policies and manuals (previsit phase), and may submit to interviews or provide system demonstrations (on-site visit phase). OCC staff use the Data Collection Tool to record comments about the evidence observed, and to note whether additional follow-up is needed. Both of these tools contain language indicating that the effectiveness of states\u2019 program-integrity and fraud-fighting activities are evaluated by OCC staff. For purposes of the Monitoring System, OCC officials said that states have broad flexibility to propose, in the Compliance Demonstration Packet, what documents and evidence to provide. In addition, states have the flexibility to propose how the state will demonstrate compliance with regulatory requirements. This includes the requirement to describe in its State Plan effective program-integrity control activities, which includes fraud-fighting activities. OCC officials further told us that OCC does not collect the same set of information or evidence across the country. Rather, OCC collects state-specific information based on what each individual state proposes. For example, the Compliance Demonstration Packet allows states to propose an approach for demonstrating their compliance with the requirement to describe in their State Plans effective internal controls that are in place to ensure integrity and accountability. OCC officials said the primary purpose of the Monitoring System is to ensure that states are in compliance with CCDF regulations and implementing the State Plans as approved, rather than to make an assessment of the efficacy of the State Plans. When we asked OCC officials how they determine whether a state has provided appropriate and adequate documentation for the purposes of the Monitoring System, these officials told us that staff develop specific questions for each state and look for evidence showing that states are implementing the State Plans as approved. For example, OCC officials might look for evidence of a state\u2019s implementation of certain program-integrity activities described in its approved State Plan to verify that the activities described are in place. OCC officials also stated that staff decide what is acceptable through consensus and attempt to build consistency through internal discussions regarding the appropriateness of the material that states provide. However, there are no specific criteria to guide OCC staff\u2019s assessment of the effectiveness of states\u2019 program-integrity activities during these discussions. For example, there are no specific criteria to help OCC staff assess whether states\u2019 implemented control activities are effective at identifying areas of risk. OCC officials stated that the CCDF regulations and the approved State Plans are the most-detailed criteria that they use to assess data collected for the Monitoring System. However, neither the CCDF regulations nor the State Plans include specific criteria for assessing whether the control activities are effective. OCC is responsible for monitoring states\u2019 compliance with the CCDF regulations, and these regulations explicitly require that states describe in their State Plans \u201ceffective internal controls that are in place to ensure integrity and accountability.\u201d According to Standards for Internal Control in the Federal Government, an effective internal control system has a monitoring component that is effectively designed, implemented, and operating. Additionally, a leading practice of the Fraud Risk Framework is to examine the suitability of existing fraud controls. Managers who effectively implement an antifraud strategy monitor and evaluate the effectiveness of preventive activities in this strategy and take steps to help ensure external parties with responsibility over fraud control activities effectively implement those activities. Without developing and using criteria to assess whether states\u2019 program-integrity control activities are effective, OCC cannot ensure that states\u2019 internal controls for program integrity are effective. Likewise, without examining the suitability of, and monitoring the effectiveness of, the states\u2019 fraud control activities, OCC will be challenged in effectively implementing an antifraud strategy to minimize the risk of fraud in the CCDF program. OCC developed the Grantee Internal Controls Self-Assessment Instrument (Self-Assessment Instrument) in 2010 and makes the technical-assistance tool available to the states through its website. In response to a 2016 HHS OIG report, ACF officials said that OCC would use the Self-Assessment Instrument to address the report\u2019s recommendations to request that states examine the effectiveness of their program-integrity and fraud-fighting activities, and examine with states the benefits of expanding such activities. The Self-Assessment Instrument contains five sections: (1) Eligibility Determination and Review; (2) Improper Payment Case Review Process; (3) Fraud and Overpayment Prevention, Detection, and Recovery; (4) Federal Reporting; and (5) Audits and Monitoring. According to OCC officials, as of August 2019, 19 states have completed the Self-Assessment Instrument since its inception. OCC officials stated that use of the Self-Assessment Instrument is based entirely on states\u2019 self-identified risks, and states are free to choose which, if any, of the sections to complete. OCC officials have noted benefits as a result of states completing the Self-Assessment Instrument. Specifically, OCC officials said that states have improved their implementation processes and policies, and improper-payment error rates have decreased. In addition to making the tool available to states, OCC officials told us that OCC also provides technical assistance in completing the Self-Assessment Instrument, which may include an on-site facilitated discussion. The facilitated discussion may cover areas including control activities to identify and prevent fraud, and strategies to investigate and collect improper payments. Following the on-site facilitated discussion, an OCC contractor compiles a report summarizing state-identified issues to address in states\u2019 policies and procedures, according to one OCC official. However, OCC officials told us that states are not required to act on this report. In addition to the Self-Assessment Instrument, OCC has recently coordinated on the development of the Fraud Toolkit, which is a series of electronic spreadsheets that states can use to respond to questions about their fraud risk management activities\u2014such as staff training, procedures for addressing suspected fraud, and program administration. The tools assign risk levels to these areas based on the state\u2019s responses, and will also include recommended next steps for each of those areas and generate a report to summarize overall risk. For example, data from these tools would indicate whether states\u2019 CCDF program staff are trained to identify forms, such as wage stubs or employer letters that may have been forged or altered. The data would also indicate whether the state has a fraud referral process in place to expedite investigations. OCC makes the Fraud Toolkit available for states to use upon request. However, other than making the tool available, OCC officials said that OCC does not usually have any further involvement in states\u2019 use of the tool. OCC officials told us that they do not plan to use either the Self- Assessment Instrument or the Fraud Toolkit to collect data about states\u2019 CCDF programs because both the Self-Assessment Instrument and the Fraud Toolkit are intended as primarily technical-assistance tools rather than monitoring tools or data-collection instruments. OCC officials also told us that, to formally collect information from states\u2019 use of such tools, they would need to seek approval from OMB. OCC officials stated that OCC\u2019s goal is to develop technical assistance that best meets the needs of the states, and not to impose additional reporting requirements on the states. Officials also noted a concern that states could cease to participate in or accept technical assistance if such assistance is seen as increasing reporting requirements. However, according to OCC officials, OCC has not conducted a cost-benefit analysis of collecting such information. Leading practices in the Fraud Risk Framework are to monitor and evaluate the effectiveness of preventive activities; collect and analyze data; and adapt activities to improve fraud risk management. Further, although external parties\u2014in this case, the state lead agencies\u2014may be responsible for specific fraud control activities, Standards for Internal Control in the Federal Government states that management should establish and operate monitoring activities to monitor the internal control system and evaluate the results. As part of these standards, management retains responsibility for monitoring the effectiveness of internal control over the assigned processes performed by external parties. Management is responsible for meeting internal control objectives, and may decide how the entity evaluates the costs versus benefits of various approaches to implementing an effective internal control system. However, cost alone is not an acceptable reason to avoid implementing internal controls, and cost-benefit considerations support management\u2019s ability to effectively design, implement, and operate an internal control system that balances the allocation of resources and other factors relevant to achieving the entity\u2019s objectives. By not evaluating the feasibility of collecting information from the Self-Assessment Instrument or the Fraud Toolkit\u2014 such as evaluating the feasibility of doing so during its Monitoring System process\u2014OCC may be missing an opportunity to monitor the effectiveness of the internal control system to help states adapt control activities to improve fraud risk management. As described above, OCC has developed several program-integrity activities that could help assess and manage fraud risk if they were part of an antifraud strategy. For example, the improper-payment reporting process and Monitoring System are not specific to fraud but may generate information relevant to fraud risks. However, according to OCC officials, ACF has not completed a fraud risk assessment for the CCDF, which would provide a basis for the development of an antifraud strategy that describes the program\u2019s approach for addressing prioritized fraud risks identified, as described in the Fraud Risk Framework. The Assess component of the Fraud Risk Framework calls for federal managers to plan regular fraud risk assessments and to assess risks to determine a fraud risk profile. Furthermore, Standards for Internal Control in the Federal Government states that management should consider the potential for fraud when identifying, analyzing, and responding to risks. Leading practices for planning fraud risk assessments include tailoring the fraud risk assessment to the program and planning to conduct the assessment at regular intervals and when there are changes to the program or operating environment. The leading practices also include identifying the tools, methods, and sources for gathering information about fraud risks and involving relevant stakeholders in the assessment process. The Fraud Risk Framework also identifies leading practices for conducting fraud risk assessments and documenting the program\u2019s fraud risk profile, as illustrated in figure 8. As discussed in the Fraud Risk Framework, the fraud risk profile provides a basis for managers to develop and document an antifraud strategy that describes the program\u2019s approach for addressing prioritized fraud risks identified. According to ACF, there is currently a process in place at the ACF level that will lead to the development of a Fraud Risk Assessment. Specifically, ACF is in the process of developing a Fraud Risk Assessment template, which will include a program fraud risk profile. The CCDF will be part of the pilot program for this effort. The Fraud Risk Assessment template will consider the Fraud Risk Framework as well as guidance contained in OMB Circular A-123, Management\u2019s Responsibility for Enterprise Risk Management and Internal Control, according to OCC officials. These officials also stated that ACF will leverage its previously developed and implemented risk assessments, including the Program Risk Assessment that was completed for the CCDF between fiscal years 2011 and 2016 as part of the HHS Program Integrity Initiative. However, according to ACF, the development of a Fraud Risk Assessment template is currently on hold due to competing priorities. The ACF stated the agency expects to resume the process by December 2019, and OCC expects that the draft template will be completed by the end of the first quarter of fiscal year 2020. Because the CCDF is serving as the pilot for the new template, OCC expects that the initial assessment of the program will be complete by the end of the third quarter of fiscal year 2020. Until ACF finalizes its template and conducts a risk assessment for the CCDF, ACF will not be able to develop a fraud risk profile for the CCDF. The fraud risk profile is an essential piece of the antifraud strategy and informs the specific control activities managers design and implement. Although there is currently a process in place for ACF to develop a fraud risk assessment template, until ACF carries out the assessment of the CCDF and develops an associated fraud risk strategy, it will lack assurance that OCC\u2019s program-integrity activities are suitable and targeted at prioritized fraud risks. Both state lead agencies and OCC play an important role in overseeing and protecting the integrity of the CCDF program. However, OCC has not finalized written policies that describes how staff should implement or document the State Plan review and approval process, which is an important part of OCC\u2019s oversight of the CCDF program. OCC\u2019s lack of established written policies limits its ability to ensure that staff follow appropriate protocols when implementing the State Plan review and approval process, and limits its ability to retain organizational knowledge in the event of staff turnover, which OCC noted as occurring during each review period. In addition, most of the State Plans submitted to OCC for the fiscal years 2019\u20132021 grant period did not contain information on the results of their states\u2019 program-integrity activities. OCC also has not defined or communicated what it considers to be the \u201cresults\u201d of program- integrity activities for states, which are requested to include this information in State Plans, or for its staff who will be responsible for analyzing this information. Until OCC defines its informational needs regarding program-integrity activity results and communicates this information to the states and its own staff, OCC may continue to lack quality information to help ensure states\u2019 accountability of their program- integrity activities. Further, OCC does not have documented criteria to guide the review of the CAPs to ensure the proposed corrective actions are aimed at root causes of improper payments and are effectively implemented to prevent and reduce improper payments. Without criteria for its staff to use in reviewing the CAPs, OCC does not have assurance that the corrective actions a state proposes to reduce improper payments will be specifically aimed at root causes of improper payments and effectively implemented, leaving the CCDF program at continued risk of improper payments. OCC also does not have written policies for its CAP follow-up process or documentation that follow-up has been completed for past CAPs. In addition, OCC officials told us that they plan to develop a written protocol for this process, but did not specify a timeline for completion. Having established written policies for the CAP follow-up process will help ensure that OCC\u2019s oversight and monitoring of CAPs is carried out consistently. OCC\u2019s Monitoring System process does not currently contain criteria to assess the effectiveness of states\u2019 program-integrity control activities, including fraud-fighting activities. Without developing and documenting criteria to assess whether states\u2019 program-integrity control activities are effective, OCC cannot ensure that such program-integrity control activities are effective. In addition, OCC does not plan to collect any data from its technical-assistance tools that could potentially help it to monitor and evaluate the effectiveness of states\u2019 program-integrity activities. However, OCC has not evaluated the benefits of using these tools to collect information on program-integrity activities against any costs of doing so\u2014 such as the cost of seeking OMB approval to do so. By not evaluating the feasibility of collecting information from technical-assistance tools to monitor the effectiveness of states\u2019 program-integrity control activities, OCC may be missing an opportunity to help states adapt control activities to improve their fraud risk management. All of the foregoing program-integrity oversight and monitoring activities could contribute to a strategy for managing fraud risks in the CCDF. However, OCC has not completed a fraud risk assessment or risk profile for the program. Although there is currently a process in place for ACF to develop a fraud risk assessment template, until ACF completes this template and carries out the assessment of the CCDF, it will lack a robust antifraud strategy and assurance that OCC\u2019s current program-integrity activities are suitable and targeted at prioritized risk. We are making the following nine recommendations, eight to the Director of OCC and one to the Assistant Secretary for ACF: The Director of OCC should establish internal written policies to effectively implement and document the State Plan review and approval process for future review and approval periods. (Recommendation 1) The Director of OCC should define the informational needs related to the results of program-integrity activities. (Recommendation 2) The Director of OCC should communicate externally to the states its informational needs related to the results of states\u2019 program-integrity activities. (Recommendation 3) The Director of OCC should communicate internally to staff its informational needs related to the results of states\u2019 program-integrity activities. (Recommendation 4) The Director of OCC should develop documented criteria to guide the review of CAPs submitted by states to ensure that proposed corrective actions are aimed at root causes of improper payments and are effectively implemented. (Recommendation 5) The Director of OCC should timely complete its effort to develop established written policies for the CAP follow-up process to ensure that OCC\u2019s oversight and monitoring of CAPs is carried out consistently. (Recommendation 6) The Director of OCC should develop and document criteria to assess the effectiveness of states\u2019 program-integrity control activities. (Recommendation 7) The Director of OCC should evaluate the feasibility of collecting information from the Grantee Internal Controls Self-Assessment Instrument (Self-Assessment Instrument) and Fraud Toolkit, such as during its Monitoring System process, to monitor the effectiveness of states\u2019 program-integrity control activities. (Recommendation 8) The Assistant Secretary for ACF should ensure that ACF conducts a fraud risk assessment to provide a basis for the documentation and development of an antifraud strategy that describes the CCDF program\u2019s approach to address prioritizing fraud risks identified. (Recommendation 9) We provided a draft of this report to HHS for review and comment. In its comments, reproduced in appendix I, HHS concurred with our recommendations. HHS also provided technical comments, which we incorporated as appropriate. As agreed with your offices, unless you publicly announce the contents of this report earlier, we plan no further distribution until 30 days from the report date. At that time, we will send copies to the Secretary of Health and Human Services and appropriate congressional committees. In addition, the report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staffs have any questions about this report, please contact me at (202) 512-6722 or bagdoyans@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix II. In addition to the contact named above, Jonathon Oldmixon (Assistant Director), Erica Varner (Analyst in Charge), Yue Pui Chin, and Daniel Dye made key contributions to this report. Other contributors include James Ashley, Maria McMullen, George Ogilvie, and Sabrina Streagle.", "summary": "The CCDF is administered as a block grant to the states by OCC, an agency within the Department of Health and Human Services (HHS). Recent reports by the HHS Office of the Inspector General show that OCC's monitoring of CCDF state program-integrity efforts remains a challenge. CCDF has also been designated as a program susceptible to significant improper payments, as defined by the Office of Management and Budget. GAO was asked to review CCDF program-integrity efforts. This report discusses, among other things, the extent to which OCC provides oversight of (1) states' CCDF program-integrity activities, including encouraging that all requested information is included within State Plans; and (2) improper-payment risks and relevant corrective actions in states' CCDF programs. GAO analyzed 51 approved CCDF State Plans, including from the District of Columbia, for the fiscal years 2019\u20132021 grant period. GAO also reviewed OCC policies and procedures and compared them to relevant laws, regulations, and Standards for Internal Control in the Federal Government , and interviewed relevant federal officials. The Child Care and Development Fund (CCDF) provided states more than $8 billion in federal funds in fiscal year 2019. The Office of Child Care (OCC) oversees the integrity of the CCDF, which subsidizes child care for low-income families. A key part of OCC's oversight includes reviewing and approving State Plans. OCC requested but did not require states to describe in their State Plans the results of their program-integrity activities, which describe the processes that states use to identify fraud risk. Further, OCC has not defined or communicated what information it considers to be the \u201cresults\u201d of program-integrity activities to the states and its own staff. Without defining and communicating its informational needs, OCC may continue to lack quality information that could help ensure states' accountability over their program-integrity activities. OCC oversees states' improper payment risks through a process that includes a requirement for states to submit corrective action plans (CAP) when they estimate their annual payment error rates are at or above 10 percent. Since 2013, seven states have submitted 14 CAPs. These CAPs describe states' proposed actions for reducing improper payments. However, OCC does not have documented criteria to guide its review and approval of the CAPs to ensure the proposed corrective actions are aimed at root causes of improper payments and are effectively implemented. Without developing this guidance, OCC does not have assurance that proposed corrective actions are specifically aimed at root causes of improper payments, leaving the CCDF program at continued risk of improper payments. GAO is making nine recommendations, including that OCC define and communicate its informational needs on the results of states' program-integrity activities, and that OCC develop criteria to guide the review of CAPs to ensure that proposed corrective actions are aimed at root causes of improper payments and are effectively implemented. HHS concurred with our recommendations and provided technical comments, which GAO incorporated as appropriate."}
{"id": "govreport_9", "report": "According to the Senate Committee on Homeland Security and Governmental Affairs report concerning PMIAA, the purpose of PMIAA is to improve program and project management in certain larger federal agencies. The act includes requirements for OMB, OPM, and the 24 agencies listed in the CFO Act. PMIAA requires OMB\u2019s Deputy Director for Management or the designee to, among other things: adopt government-wide standards, policies, and guidelines for program and project management for executive agencies; engage with the private sector to identify best practices in program and project management that would improve federal program and project management; conduct portfolio reviews of agency programs not less than annually, to assess the quality and effectiveness of program management, in coordination with Program Management Improvement Officers (PMIO); establish a 5-year strategic plan for program and project conduct portfolio reviews of programs on our High-Risk List. The two types of portfolio reviews required by PMIAA\u2014the portfolio reviews of agency programs and the portfolio reviews of programs identified as high risk on our High-Risk List\u2014are separate requirements. For purposes of this report, we define programs, projects, and portfolios consistent with how those terms are defined in OMB\u2019s PMIAA strategic plan. OMB defines program as the functions or activities which agencies are authorized and funded by statute to administer and enforce. Programs typically involve broad objectives. OMB views projects as temporary efforts with defined scopes to create products or services to improve the efficient and effective implementation of programs. Because programs are comprised of projects, programs inherently address the projects subsumed within them. Consequently, our discussions of programs throughout this report also pertain to projects. Finally, OMB defines portfolios as organized groupings of programs whose coordination in implementation enables agencies to achieve their objectives. The act also established the Program Management Policy Council (PMPC), an interagency forum for improving agency practices related to program management. OMB\u2019s Deputy Director for Management chairs the PMPC. The PMPC responsibilities include advising OMB on the development and applicability of government-wide standards for program management transparency. Furthermore, the act requires PMPC members \u201cto discuss topics of importance to the workforce,\u201d such as workforce development needs and major challenges across agencies in managing programs. As chair of the PMPC, OMB\u2019s Deputy Director is required to preside at meetings, determine agendas, direct the work, and establish and direct its subgroups, as appropriate. The act requires the PMPC to meet not less than twice per fiscal year. Additionally, OPM\u2019s Director, in consultation with OMB\u2019s Director, is required to issue regulations that: identify key skills and competencies needed for a program and a project manager in an agency; establish a new job series, or update and improve an existing job series, for program and project management within agencies; and establish a new career path for program and project managers within an agency. Overall, OPM\u2019s role in implementing PMIAA is to establish a new job series or update an existing job series by providing the occupational standards that agencies will need to develop a trained and competent workforce with the program and project management experience, knowledge, and expertise to solve management challenges and support agency decision-making. The act requires OPM to establish new\u2014or revise existing\u2014occupational standards in consultation with OMB. Occupational standards are included within OPM\u2019s classification guidance, which is provided to agencies to assist in classifying positions. This guidance helps agencies to determine the proper occupational series, position title, and grade of each position. The act requires OMB\u2019s Deputy Director of Management to oversee implementation of the standards, policies, and guidelines for executive agencies. OMB implemented some PMIAA requirements using existing processes put in place to implement GPRAMA. We previously reported that GPRAMA provides important tools that can help decision makers address challenges facing the federal government, such as the annual reviews of progress on agency strategic objectives conducted during strategic reviews and the implementation of federal government priority goals. Federal government priority goals, also known as cross-agency priority (CAP) goals, are written by OMB in partnership with agencies. GPRAMA requires OMB to coordinate with agencies to develop CAP goals, which are 4-year outcome-oriented goals covering a number of complex or high-risk management and mission issues. For example, OMB directed agencies to align their noninformation technology major acquisition programs with relevant strategic objectives so they could assess progress for the PMIAA required program portfolio reviews concurrent with required GPRAMA strategic reviews. GPRAMA also requires OMB to present a program inventory of all federal programs by making information available about each federal program on a website. Finally, GPRAMA required OMB to establish a number of CAP goals intended to cover areas where increased cross-agency collaboration is needed to improve progress towards shared, complex policy or management objectives across the federal government. OMB uses CAP goals to address issues outlined in the President\u2019s Management Agenda. For example, OMB wrote a CAP goal to improve management of major acquisitions across the government which complements PMIAA and its required activities. PMIAA requires the OMB Deputy Director, as chair of the PMPC, to conduct portfolio reviews of programs from our High-Risk List. The PMPC is also required to review programs we identify as high risk and to make recommendations for actions to be taken by the Deputy Director for Management of OMB or a designee. See figure 1 below for an overview of roles and responsibilities of OMB, OPM, the PMPC, and agencies. Agencies responsible for PMIAA implementation have taken steps to complete some requirements, but actions remain to fully implement the law (see Table 1). OMB met the PMIAA requirement \u201cto establish a five-year strategic plan for program and project management.\u201d The plan OMB developed details three key strategies to implement PMIAA: (1) coordinated governance, (2) regular OMB and agency engagement reviews, and (3) strengthening program management capacity to build a capable program management workforce. The three strategies focus on areas such as clarifying key roles and responsibilities, identifying principles-based standards, and identifying plans for enhancing workforce capabilities. The plan describes the roles and functions of the PMIOs, the PMPC, and the requirements of the agency implementation plans. It outlines a phased approach for implementing PMIAA actions with milestones occurring throughout the 5- year period. We found that OMB followed several strategic planning leading practices in the creation of the PMIAA strategic plan. First, the plan incorporates general goals and objectives for agencies\u2019 implementation of PMIAA with three corresponding strategies explaining OMB\u2019s overall approach. OMB followed a second leading practice by gathering input from stakeholders. OMB staff told us they solicited input from congressional staff, and members of external organizations like the Federal Program and Project Management Community of Practice (FedPM CoP). Agencies\u2019 staff also confirmed to us that they had input into the OMB plan. Third, OMB demonstrated interagency collaboration in its efforts to establish and lead the PMPC and its efforts to work with the FedPM CoP to address any issues identified by agencies. Finally, the plan included a timeline with quarterly milestones to track completion of PMIAA\u2019s activities and to gauge progress toward achieving the desired results of PMIAA. PMIAA required OMB to establish standards and policies for executive agencies consistent with widely accepted standards for program and project management planning and delivery. A consistent set of government-wide program management standards and policies is important because it helps ensure that agencies utilize key program management practices to improve the outcomes of government programs. OMB published in June 2018 a set of standards for program and project management as part of OMB\u2019s PMIAA strategic plan. OMB\u2019s strategic plan directed agencies to apply these 15 standards to internal management processes for planning, implementing, and reviewing the performance of programs and activities. OMB staff told us they decided to develop this set of standards rather than adopt an existing set of consensus-based standards, such as the widely accepted standards for program and project management from the Project Management Institute (PMI). PMI is a not-for-profit association that provides global standards for, among other things, project and program management. The PMI standards are utilized worldwide and provide guidance on how to manage various aspects of projects, programs, and portfolios and are approved by the American National Standards Institute (ANSI). OMB staff told us that they decided not to specifically adopt the PMI standards because they wanted to allow agencies to use a range of standards that agencies had already developed and were using to manage their programs, such as standards developed in-house by NASA for their space flight programs. OMB further directed CFO Act agencies that the 15 standards and application of them should be incorporated or aligned with existing agency-specific program management policies and practices, and tailored to reflect program characteristics. OMB staff told us that they chose the approach to provide more principle-based standards, as opposed to specific standards, to be flexible enough for a range of government agencies to apply them. OMB\u2019s standards are similar in definition to PMI standards, but they are less detailed by comparison. Our analysis of OMB\u2019s standards shows that OMB uses similar definitions for all 10 of PMI\u2019s program management standards and nine out of 10 of PMI\u2019s project management standards, such as risk management and change management. However, OMB program and project management standards are less detailed when compared to PMI\u2019s standards in the following ways: OMB standards do not provide a minimum threshold against which agencies can gauge to what extent they have met each standard. PMI\u2019s Standard for Program Management provides the definition of a standard but also what components are required for an entity to confirm that the standard has been met. For example, meeting the program financial management standard in PMI requires a financial management plan to be developed, along with its related activities. This plan allows entities applying the standard to confirm whether they have met the standard for program financial management or not. OMB\u2019s standards do not distinguish between how the standards apply differently to programs and projects while PMI has separate detailed standards for program management and for project management. The project management standards from PMI provide details on how the standards apply to more granular tasks, such as establishing a quality management or communication plan for a specific project. OMB\u2019s standards do not distinguish between how the standards relate to each other during a program or project while PMI\u2019s Standard for Program Management details how project standards help build on each other during a program. For example, a program scope management plan is needed to determine the type of schedule management planning that is necessary to accomplish the delivery of the program\u2019s outputs and benefits. OMB provides minimal guidance on how standards apply differently across the life cycle of a program or project while PMI\u2019s Standard for Program Management provides information detailing when a specific standard should be utilized in different ways during the life cycle of a program. For example, in the beginning of a program, risk management should be planned and an initial risk assessment created. Later, during program implementation, risk management tasks focus on monitoring, analyzing risk, and responding to risk. If the standards had the additional detail, it would be possible to determine if agencies are meeting them and properly applying them to programs and projects. Our work on the Digital Accountability and Transparency Act of 2014 (DATA Act) standards has emphasized the necessity for a governance structure with a clear set of policies and procedures for developing and maintaining standards over time that are consistent with leading practices. A governance structure is important because it helps ensure that the standards are developed, maintained, adjusted, and monitored over time. The DATA Act is similar to PMIAA because PMIAA gives OMB responsibility to develop standards for program management, and the DATA Act gives OMB and the Department of the Treasury responsibility for establishing data standards for the reporting of federal funds. These standards specify the data to be reported under the DATA Act and define and describe what is to be included in each element with the aim of ensuring that information will be consistent and comparable. Several governance models exist that could inform OMB\u2019s efforts to help ensure that the standards are developed, maintained, adjusted, and monitored over time. These models define governance as an institutionalized system of decision rights and accountabilities for planning, overseeing, and managing standards. Many of these models promote having a common set of key practices that include establishing clear policies and procedures for developing, managing, and enforcing standards. A common set of key practices endorsed by standards setting organizations including the National Institute of Standards and Technology, ANSI, and the American Institute of Certified Public Accountants recommend that governance structures should include the key practices shown in the text box below. Key Practices for Governance Structures 1. Delineating roles and responsibilities for decision-making and accountability, including roles and responsibilities for stakeholder input on key decisions. 2. Obtaining input from stakeholders and involving them in key decisions, as appropriate. 3. Developing and approving standards. 4. Making decisions about changes to existing standards and resolving conflicts related to the application of standards. 5. Managing, controlling, monitoring, and enforcing consistent application of standards. OMB staff told us they did not have any additional documentation about the governance structure used to develop the program management standards and how OMB will further develop and maintain them. We compared available information about OMB\u2019s governance structure for developing and maintaining program management standards to the five key practices on governance structures and found OMB\u2019s governance structure is incomplete in each of the five key practices. OMB has not delineated roles and responsibilities for decision-making and accountability, including responsibilities for stakeholder input on key decisions. OMB\u2019s strategic plan notes that one role of the PMPC is to help further develop the program management standards. However, OMB has not provided information on how roles and responsibilities will be assigned to continue developing standards in the future. Without clearly delineated roles and responsibilities, there is a risk of confusion which could impede action and accountability for future improvements to program management standards. Further, having clearly delineated roles and responsibilities is particularly important during periods of transition when administrations change. OMB has an incomplete plan for how it will obtain input from stakeholders and involve them in decision-making. OMB received input from stakeholders on the standards it developed in 2018, though the strategic plan states that standards will be further developed with the PMPC in the fourth quarter of fiscal year 2020. However, the strategic plan does not give details on how the PMPC and others will further develop standards. Without robust and comprehensive outreach to individuals who will use or otherwise be affected by the standards, the opportunity to learn from stakeholder experience and perspectives, or anyone who will use or otherwise be affected by the standards, may be diminished. OMB has an incomplete process for developing and approving program management standards. OMB developed and approved the existing standards by obtaining stakeholder input and releasing their approved standards in its strategic plan. However, the strategic plan does not provide documentation on how that process was structured and how it will function in the future. Thus, it is unclear how OMB plans to further develop the standards and what responsibilities and resources will be required from OMB, the PMPC, and agencies under the leadership of the agency PMIOs. OMB has not defined a process for making decisions about changes to existing standards and describing how conflicts related to the application of standards would be resolved. Therefore, it is unclear if or how the standards will be periodically reassessed and updated as circumstances change and leading practices in program and project management are identified. Also, lack of consensus on standards and conflict over how to use them can lead to weakened acceptance and inconsistent application. OMB has not defined a process for managing, controlling, monitoring, and enforcing consistent application of standards. OMB has not developed or directed any type of review or oversight process to determine the adequacy of existing or newly developed standards agency use to manage programs. Having such a process could help agencies to achieve a balance between consistent application of standards and flexible application to account for differences in programs, agency missions, and other factors. However, OMB staff told us that they consider the PMIAA program portfolio review process as a way to help monitor and enforce program standards, as they have a view into how each agency is applying standards for their particular portfolio of programs. Additionally, OMB has given agencies flexibility in using existing agency standards and flexibility to adopt or develop new ones. Without a review mechanism, OMB lacks reasonable assurance that agencies\u2019 efforts to use existing standards or develop new ones will align with government-wide efforts to improve program and project management. Also, establishing an approach to monitoring agencies\u2019 efforts would help identify opportunities to improve program management standards. Without having a governance structure for the program standards, the potential exists that standards will develop in an ad hoc manner, may be applied inconsistently or not at all, and may not be updated to reflect new developments in program management. Further, having a governance structure for managing efforts going forward better positions OMB to sustain progress on program standards as they change over time. PMIAA requires agencies and OMB to regularly review portfolios of programs to assess the quality and effectiveness of program management and identify opportunities for performance improvement. To conduct these portfolio reviews, OMB Circular A-11 notes that agencies and OMB are to use a set of broadly applicable program management principles, practices, and standards associated with successful program outcomes, in addition to more specific standards based on the type of program under review. As a way to help agencies acclimate to the requirements of PMIAA, OMB leveraged two components of the GPRA Modernization Act of 2010 (GPRAMA): the strategic review and a cross-agency priority (CAP) goal. OMB guidance stated that agencies\u2019 portfolio reviews of programs would be conducted and integrated to the extent practical with strategic reviews. Furthermore, OMB staff told us that the implementation of PMIAA and the CAP goal for improving management of major acquisitions (CAP Goal 11) shared complementary goals and strategies. For example, the CAP Goal 11 action plan includes the routine monitoring of federal program management progress. Consequently, OMB staff said they decided that the first PMIAA program portfolio reviews would focus on major acquisitions. Excerpt from OMB Cross-agency Priority Goal 11 from 2018 President\u2019s Management Agenda: Improve Management of Major Acquisitions Federal agencies will ensure that contracts supporting transformative and priority projects meet or beat delivery schedules, provide exceptional customer service, and achieve savings or cost avoidance for the taxpayer. The Challenge: Major acquisitions\u2014which vary in size by agency but often exceed $50 million\u2014account for approximately one-third of annual federal spend on contracts. These large contracts frequently support projects meant to transform areas of critical need. Yet major acquisitions often fail to achieve their goals because many federal managers lack the program management and acquisition skills required to successfully manage and integrate large and complex acquisitions into their projects. These short- comings are compounded by complex acquisition rules that reward compliance over creativity and results. The Strategies: Agencies will pursue three strategies: 1) strengthen program management capabilities in the acquisition workforce; 2) use modern and innovative acquisition flexibilities; and 3) track investments using portfolio, program, and project management principles. In 2018, OMB conducted a pilot project involving program portfolio review focused on noninformation technology (IT) major acquisition programs. According to OMB staff, the pilot project gave agencies the opportunity to complete \u201cdry runs\u201d for the PMIAA-required portfolio reviews and to provide lessons learned in anticipation of the fiscal year 2019 portfolio reviews. OMB planned for the results from the pilot to provide information for internal dialogue and decision-making about subsequent portfolio reviews. Further, according to OMB\u2019s strategic plan, the purpose of the pilot was (1) to determine how well agency program portfolios of non-IT major acquisitions were performing throughout the life cycle of the investment using a set of standards and practices, and (2) to refine the process of coordinating program portfolio reviews as a component of OMB agency strategic reviews. For the pilot, OMB staff directed agencies to assess the cost, schedule, and performance of agency-selected acquisition portfolios. One result from the pilot was that agencies demonstrated a range of maturity in their abilities to collect data for these required program portfolio measures from their various departments and program types. OMB staff told us pilot agencies found it easier to compile data on major construction projects compared to service contracts. Consequently, an agency doing many of these projects might be more advanced than an agency for which major acquisitions focus on services. Department of Veterans Affairs (VA) staff shared their lessons learned from their participation in pilot portfolio reviews, as seen in the text box below. OMB staff said that they determined that the portfolio review process worked sufficiently well for the pilot agencies and continued their planned strategy of focusing solely on non-IT major acquisition programs for fiscal year 2019 portfolio reviews. Example of Department of Veteran Affairs (VA) Lessons Learned from Pilot Portfolio Review The VA looked at the effectiveness of portfolio management during the Office of Management and Budget noninformation technology major acquisition pilot portfolio review by focusing on the agency\u2019s adherence to best practices in assessing project performance and progress. VA officials said this pilot informed their decision-making and was successful in the following ways: 1. The pilot helped VA determine logical ways to manage a portfolio by showing what data were helpful to make impactful decisions. 2. VA learned how best to display the data on cost, schedule, scope, and quality of outcomes on a dashboard to make it accessible and comparable across the agency. 3. VA learned that it needs to collect better quality data so that project management principles can be instituted and aligned across the agency. A well-developed and documented pilot program can help ensure that agency assessments produce information needed to make effective program and policy decisions. Such a process enhances the quality, credibility, and usefulness of evaluations in addition to helping to ensure the effective use of time and resources. We have identified five leading practices that, taken together, form a framework for effective pilot design, as seen in the text box below. OMB fulfilled the first leading practice of establishing objectives in its design of the PMIAA pilot program portfolio review. OMB\u2019s PMIAA strategic plan and the CAP Goal 11 Action Plan stated the objectives of the pilot. In addition to the two objectives listed in the PMIAA strategic plan, the CAP Goal 11 Action Plan lists seven pilot objectives, as seen in the text box below. PMIAA Pilot Program Portfolio Review Objectives 1. Perform portfolio management preparation activities 2. Identify first portfolio of major acquisitions 3. Align portfolio with agency strategic goals 4. Collect performance data for each item in the portfolio 5. OMB officials said that they did not structure the pilot to follow the remaining four leading practices for effective pilot design. However, OMB said that it learned that the pilot agencies demonstrated several program management capabilities. They also learned that it would be important to tailor portfolio reviews to the agency and the program to account for significant differences in the types of acquisitions and the level of program management maturity. Despite identifying lessons learned from its pilot program portfolio review, in neglecting to fully follow leading practices, OMB may have missed opportunities to make additional improvements for fiscal year 2019 portfolio reviews. Going forward, as OMB expands the portfolio reviews to other types of program areas beyond non-IT major acquisitions, it has the opportunity to develop and learn from additional pilots. Although OMB staff have not yet determined if they will do additional pilots for program management in the future, they could decide to pilot the portfolio reviews of grants that they plan to initiate in fiscal year 2020. For fiscal year 2019, OMB directed all agencies to select portfolios of non-IT acquisition programs and align them with relevant strategic objectives as part of their internal agency strategic review processes. In spring 2019, OMB expected agencies to discuss one to two of these major-acquisition portfolio reviews during their strategic reviews with OMB. OMB expected agencies to track the cost, schedule, and performance of their selected major acquisition programs. However, OMB reports that not all agency program portfolio reviews were completed because OMB was behind in scheduling the reviews due to the partial government shutdown. According to documents we reviewed and what OMB staff told us, in October 2019 OMB completed agency program portfolio reviews with ten agencies: the Departments of Commerce, Homeland Security, Housing and Urban Development, Labor, and Transportation; the General Services Administration, the Social Security Administration, NASA, the National Science Foundation, and the US Agency for International Development. OMB staff also told us that they also held preparatory meetings with agencies to set expectations for future portfolio reviews. OMB reported that these one-on-one meetings were held with 12 agencies as of October 2019 to discuss their initial portfolio structures and other transformative initiatives. Portfolio reviews in 2020 are to expand in scope to include grants, and also will continue acquisition portfolio reviews as part of the agency\u2019s routine management processes. However, OMB has not yet identified other program areas, such as research and development or benefit programs, to be included in future portfolio reviews. Standards for Internal Control in the Federal Government states that effective information and communication are vital for an entity to achieve its objectives. Specifically, management should externally communicate necessary quality information to achieve its objectives. Increasing communication to agencies about specific program areas, portfolio review procedures, and expectations beyond 2020 could help ensure continued progress to implement PMIAA more broadly. Furthermore, communicating such procedures with specific time frames could help agencies better direct their efforts to improve the portfolio review processes. GPRAMA requires OMB to make a list of all federal programs identified by agencies publicly available, on a central government-wide website. The implementation of the program inventory is a critical tool to help decision makers better identify and manage programs across the federal government. Among other things, the completion of the program inventory would provide agencies and Congress with a comprehensive list of programs, so it would be clear how many programs agencies are managing and how they relate to their strategic objectives and portfolios of programs at each agency. Having a program inventory could also help ensure a match between the number of agency programs and needed program manager resources. Agencies continue to struggle with challenges defining their programs. Officials from three of the five selected agencies we spoke with told us that they have not yet identified all of their programs and projects. In our first report on the program inventory in October 2014, we noted similar issues. For example, agencies were not using the same program definition approach across their subcomponents or offices, which limited comparability of their own programs. We made eight recommendations in that report to the Director of OMB to update relevant guidance to help develop a more coherent picture of all federal programs and to better ensure information is useful for decision makers. As of October 2019, OMB had not taken any actions in response to the eight recommendations. While OMB has provided a timetable for action in its June 2019 A-11 guidance, this does not complete the recommendation. In September 2017, we made two recommendations to OMB to make progress on the federal program inventory. First, we recommended that OMB consider using a systematic approach for the program inventory, such as the one we developed from principles of information architecture. Information architecture\u2014a discipline focused on organizing and structuring information\u2014offers an approach for developing a program inventory to support a variety of uses, including increased transparency for federal programs. OMB staff told us that they considered our information architecture approach and noted that a structured information architecture format is used on USASpending.gov. However, OMB staff told us they had not yet determined how the information architecture format of USASpending.gov\u2014which is focused on spending data\u2014could be used to meet additional information reporting requirements and our past recommendations related to the inventory. We made a second recommendation that OMB should revise and publicly issue OMB guidance\u2014through an update to its Circular A-11, a memorandum, or other means\u2014to provide time frames and associated milestones for implementing the federal program inventory. As mentioned above, OMB did provide a timetable but it does not have milestones. According to the timetable, beginning with the 2021 budget cycle, agencies\u2019 program activities will be used for the inventory\u2019s program-level reporting requirements. This will allow OMB and agencies to present program-level spending data by leveraging what is reported on USASpending.gov as required by the DATA Act. However, OMB\u2019s guidance does not cover other inventory information reporting requirements, or the actions we recommended in October 2014. We will continue to monitor progress. We continue to believe it is important for OMB to implement our program inventory recommendations. Such an inventory could be a critical tool to help decision makers better identify and manage fragmentation, overlap, and duplication across the federal government. Additionally, fully taking action on these recommendations would assist agencies in identifying programs, better prepare for future PMIAA portfolio reviews, and help match resources to agencies\u2019 program management needs. Further, OMB developed three different definitions for what constitutes a \u201cprogram\u201d or \u201cprogram activity\u201d that it provided to agencies in its PMIAA, GPRAMA, and DATA Act guidance, respectively. OMB developed each of these definitions independently and in response to three different statutory requirements. OMB staff told us that these three requirements differ in their legislative intent. The definitions and their associated guidance are in the table below. OMB has not reconciled these overlapping, yet divergent, definitions of what constitutes a \u201cprogram\u201d or \u201cprogram activity.\u201d According to Standards for Internal Control in the Federal Government, management should ensure that specific terms are fully and clearly set forth so they can be easily understood. Standards for Internal Control in the Federal Government also states that management should design processes that use entities\u2019 objectives and related risks to identify information requirements needed to achieve objectives and address risks. OMB has defined what constitutes a \u201cprogram\u201d or \u201cprogram activity\u201d in PMIAA, GPRAMA, and the DATA Act each, but its three different program definitions and approaches to determining what is a \u201cprogram,\u201d could cause confusion for agencies. Agency officials from the Department of Energy told us they are already experiencing confusion over how to appropriately apply the applicable program definition to identify their programs for PMIAA. Agency officials from Treasury told us that different definitions for programs could contribute to confusion as they work to implement PMIAA within the Department. The inconsistent approaches may increase the burden on agencies as they work to identify, maintain, and report on three sets of differently defined programs. Conversely, clarifying the definitions could help agencies and OMB identify synergies across the three laws and increase transparency. For example, providing explanations of how the term \u201cprogram\u201d or \u201cprogram activity\u201d is used across the three statutory definitions and developing a crosswalk to show similarities and differences could provide more clarity for agencies. Then, spending and performance data can be aligned with agency strategic goals, which could be monitored, reviewed, and reported in a streamlined manner. OPM followed PMIAA requirements to create policy and guidance. Specifically, according to documents we reviewed, OPM (1) worked with subject matter experts to develop program and project management skills and competencies, (2) updated the program management 0340 job series and created guidance for identifying project management positions, (3) plans to release a career path for program and project managers by the end of calendar year 2019, and (4) plans to create a unique job identifier code that can be used to pinpoint program and project managers in any job series. These efforts will form the foundation needed by agencies to strengthen resource and talent management. Competency modeling. Since enactment of PMIAA, OPM identified skills and competencies which will be required for program and project managers. According to documents we reviewed, OPM met with subject matter experts and human capital staff in agencies to help identify the skills needed to develop the competency model. OPM also conducted a literature review looking at prior competency studies and industry practices to help identify and support program and project management competencies. OPM also drew from Project Management Institute resources, such as the Project Management Body of Knowledge and the Standard for Program Management, as part of identifying its competencies. The resulting competencies are in two categories: general and technical. General competencies focus on interpersonal or general on-the-job skills such as teamwork and problem solving. Technical competencies more narrowly focus on particular skills needed to run programs and projects, such as risk management and cost-benefit analysis. OPM documents stated that agencies will need to determine the applicability of these competencies to positions within their agency. Agencies must determine if staff meet the competencies, and if not, staff will have the opportunity to develop them or must move to a different job series, according to OPM staff. OPM staff also said additional competency assessment steps are needed to finalize the model. Agencies will be given time to consider the competency model. In addition, OPM will use subject matter expert panels to further develop the model, according to OPM documents we reviewed. Updated job series. To implement job series requirements in PMIAA, OPM staff conducted an occupational study and determined that pre- existing classification policy was sufficient for classifying program management work rather than creating a new job series classifying program management positions, according to OPM staff. Prior to OPM updating the program management 0340 job series for PMIAA, the classification standard was not developed, as it did not contain competencies describing what qualifications staff were required to meet as a program manager. In May 2019, OPM released the updated job series classification guidance designed to assist agencies in determining which employees fit in the job series. OPM also released guidance for classifying project managers to help agencies specifically identify project managers in any occupational job series. According to the memorandum sent by the Acting Director of OPM to agencies with the OPM classification guidance, agencies are required to implement the policy and guidance to covered positions by May 1, 2020. Career path. OPM staff told us that they have developed a career path for program and project managers that is currently in internal review. They said that the value of the updated career path is that it will highlight training and skills needed to progress in a program management career. According to the presentation given by OPM at the 2019 April PMPC meeting, the career path will contain: (1) a career progression outline for employees to move among and across jobs in program and project management, (2) help for employees and supervisors to plan and sequence appropriate career training and development for each general and technical competency, and (3) a list of common degrees and certifications completed by program and project managers, among other things. Staff told us they plan to release the program and project management career path for agency comment by the end of calendar year 2019. Job identifier for program managers and project managers. Because program and project managers are found in other job series outside the 0340 program management series, OPM is developing a job identifier code that can be attached to any job series for the purposes of identifying program and project managers. OPM staff told us that program managers classified to the 0340 series means that the position does not have a specialization. If the position requires specialized expertise, the position would be classified to a specialized occupational series but would also have a program management job identifier code. For example, since a grants managers is also a program manager, \u201cgrants manager (program management)\u201d would be his or her official title. Project management positions will also use a job identifier to identify project managers in any occupational series. The job identifier will allow employees with a specialization to be designated program and project managers, while still maintaining their original career path. OPM staff told us they plan to complete this project in 2020. Our analysis of OPM Enterprise Human Resources Integration data shows that the 0340 job series included about 15,000 employees across all 24 CFO Act agencies in fiscal year 2018. However, OPM reported that not all employees in this job series are actually program and project managers; conversely, many program and project managers are working outside of the 0340 job series. Selected agencies reported varying degrees of difficulty identifying program and project managers. For example, NASA staff reported that they were able to identify almost all their program and project managers. In contrast, the Department of the Treasury reported that it faces challenges identifying the number of program and project managers outside of the program management job series, as this would require a resource-intensive manual effort, made more challenging by the agency\u2019s large, complex, and decentralized structure. The Department of Energy (DOE) staff said they have not completed the count of their program managers. The Departments of Commerce and Veterans Affairs also report they do not know the number of program and project managers in their departments, respectively. The Department of Commerce staff told us that they cannot accurately identify the number of program and project managers until they can use the job identifier that they expect OPM to release in 2020. Further, Commerce officials told us they are also continuing to work to identify program managers and engaged the Project Management Institute (PMI) to request a list of those within Commerce who have the Project Management Professional (PMP) certification. PMI was able to provide Commerce details about the numbers of PMPs at Commerce, but PMI declined to share the names of those individuals with the PMP certification. In OPM\u2019s 2018 Federal Workforce Priorities report, OPM recognizes that not all agencies have adequately analyzed workload demands, staffing levels, or current and future skills needs\u2014all steps in workforce planning. As part of the OPM human capital framework, agencies are required to develop a human capital operating plan which is an agency\u2019s human capital implementation document. These plans are to describe how agencies will execute the human capital strategies needed to implement the agency\u2019s strategic plan and Annual Performance Plan (APP). Agencies are also required to include program specific strategies (e.g., hiring, closing skills gaps, etc.) in the APPs as appropriate. Effective workforce planning can help agencies focus on determining how many program and project managers they have, how many they may need, what skills gaps exist, and what training and other strategies can help address skills gaps. OPM\u2019s workforce planning model is comprised of five steps: 1. Set strategic direction; 2. Analyze workforce, identify skills gaps, and conduct workforce 3. Develop action plan; 4. Implement action plans; and 5. Monitor, evaluate, and revise. The discussion below describes how OPM and agencies are working to strengthen the program management workforce in the context of OPM\u2019s workforce planning model. Some activities may span more than one phase of workforce planning. Set strategic direction. The PMIAA strategic plan establishes direction for agencies to build its program management capacity and capability with its third strategy, \u201cStrengthening Program Management Capacity to Build a Capable Program Management Workforce.\u201d Setting strategic direction also involves linking work activities to the objectives of a strategic plan. OPM\u2019s planned activities, such as updating the classification standards and creating a job identifier, are critical to executing this strategy so agencies can identify their workforce and build program management capacity through training, career paths, and mentorship opportunities. Analyze workforce, identify skills gaps, and conduct workforce analysis. OPM and agencies are in the early stages of identifying who their program and project managers are and what human capital strategies might be needed to address agencies\u2019 needs. Documents we reviewed showed that OPM also worked with the Chief Human Capital Officers Council, the Chief Administrative Officers Council and others to develop competencies. These competencies provide a foundation for the subsequent assessment of program and project manager skills. Develop action plan. In their PMIAA implementation plans, some agencies have identified available training and possible recruitment and hiring strategies. In OPM\u2019s model, agencies need to complete their workforce analysis before they can develop their action plans. Implement plan. This step is dependent on agencies developing action plans. However, OPM and agencies have already started to develop staff in the absence of plans. For example, OPM is working with agencies to identify program management training matching desired competencies to be placed in an online training repository that will be accessible to all agencies. OPM staff told us that agencies would provide the trainings from their learning management systems and offer them for interagency access. OPM is developing this training and development repository which will house agency-owned courses and also identify mentors in project and program management, according to OPM staff. OPM will house the repository on its training and development policy wiki at https://www.opm.gov/wiki/training/index.aspx. Each PMIO is to also establish a website with agency-specific program management tools and resources. Additionally, OMB recognized that the Federal Program and Project Management Community of Practice (FedPM CoP), scaled up from a community of practice housed in DOE, could be an important partner in supporting PMIAA implementation. As of April 2019, more than 1,000 managers had joined the FedPM CoP as indicated in its briefing to the PMPC. The FedPM CoP has identified several project management-related documents that are now available on the PMIAA portal. To further develop program managers, OMB is working with agencies to improve mentoring and recognition efforts. To improve mentoring government-wide, OMB reports that PMIOs will work with agency chief human capital offices to develop and implement a mentoring strategy for agency program managers. OMB also plans to take existing mentorship programs established in more functionally aligned-management fields (e.g., information technology, acquisition) and expand them to include a broader range of management career paths. To improve recognition efforts in acquisitions, the Chief Acquisition Officer Council plans to establish an annual award to recognize federal program manager excellence. Monitor, evaluate, and revise. This step cannot begin until agencies develop and implement their workforce action plans. As agencies begin to monitor their implementation of these plans, they will need to determine if any skills gaps exist in the program and project manager occupational series. OPM regulations require agencies to describe in their human capital operating plans agency-specific skills and competency gaps that must be closed through the use of agency selected human capital strategies. Agencies must also have policies and programs that monitor and address skills gaps within government wide and agency-specific mission-critical occupations. OPM has not yet determined if program and project management occupations are experiencing mission-critical skills gaps across the government, and OPM staff noted that agencies are not specifically required to report program and project manager skills gaps in their annual human capital operating plans. OMB and OPM both missed statutory deadlines to fulfill requirements in PMIAA. In June 2018, OMB issued the required PMIAA agency implementation guidance in the PMIAA strategic plan, 6 months after the statutory deadline of December 2017. According to OMB staff, this delay was due to their own research project to (1) build sufficient knowledge in program and project management; and (2) increase stakeholder support in Congress and with agencies for its approach. Specifically, OMB met with experts from PMI, academics, consulting firms, federal chief senior level officer (CXO) councils, and other agency officials to increase its own understanding of program and project management principles. OMB staff told us that they used the collected information to draft initial guidance, which they then shared with congressional stakeholders and executive branch agency officials to obtain feedback and incorporate changes. OMB staff also told us that it was a transition year from one administration to another administration, and this transition was an additional factor in delaying completion of the guidance. None of the selected agencies\u2019 staff identified an impact from the delayed guidance. OPM officials told us they missed the statutory deadline to complete their required activities after the issuance of OMB guidance. The release of the policy and guidance was due to the partial government shutdown from December 22, 2018 to January 25, 2019, along with a 3-month delay due to OPM\u2019s own internal review and clearance process. As a result, OPM released the key skills and competencies needed for program and project management on April 5, 2019, and the classification guidance for the program manager job series 0340 and project manager interpretative guidance on May 2, 2019. OPM officials told us that agencies have 1 year from the date of issuance to comment on any language in the guidance. None of the selected agencies\u2019 staff identified an impact from OPM\u2019s delays, although one agency expressed concern that the pace of their efforts to identify program and project managers is dependent on OPM completing the job identifier. Figure 2 shows the delays in releasing OMB and OPM guidance. OMB officials established the PMPC in 2018 and fulfilled requirements that it meet at least twice per year. By September 2018, the 24 CFO Act agencies had all appointed a PMIO and held three PMPC meetings, in September 2018, April 2019, and September 2019. Selected agenda items for these PMPC meetings included: status updates on OPM completing program and project manager competencies, job series, and career path; breakout sessions to discuss PMIAA implementation approaches with discussion of PMPC priorities and focus for 2020. At the April 2019 PMPC meeting, for example, staff from the Department of Veterans Affairs and the National Science Foundation shared some best practices, such as how to improve the tracking performance of portfolios, programs, and projects. According to OMB documents we reviewed, OMB plans to: convene the PMPC in the first quarter of each calendar year to prepare for upcoming OMB and agency strategic review meetings; use the PMPC meeting in the third quarter of the calendar year to review findings and outcomes from the most recent strategic review; update program and project management standards based on its findings and feedback at the PMPC meeting in the fourth quarter of 2020; use the PMPC to develop revised strategies, initiatives, and priorities to be reflected in an updated 5-year strategic plan at the PMPC meeting in the fourth quarter of 2021; and use the PMPC to focus on improving our high-risk areas at some future point. At the September 2019 PMPC meeting, OMB informed agencies of PMIAA implementation resources placed on OMB\u2019s online portal for PMIAA and discussed OMB\u2019s observations on portfolio reviews completed in 2019. One observation was the need to reinforce better visualization of performance data. In addition, OPM updated the PMPC on the status of its required PMIAA workforce efforts. The PMPC decided its primary focus for the year 2020 should be on the third strategy of the PMIAA strategic plan to build a capable workforce. Officials from the selected agencies that we interviewed provided us some suggestions on how OMB can improve the functionality of the PMPC. Table 3 illustrates the range of these suggestions: The PMPC met twice in 2019, as required by PMIAA, and has not established any working groups to help execute its significant responsibilities to share leading practices, develop standards, and help improve the workforce. Agencies have taken initial steps to incorporate requirements into program efforts. According to OMB guidance, agencies were to report in implementation plans how they are institutionalizing PMIAA efforts\u2014 especially PMIO responsibilities\u2014into existing program and project management practices. OMB requested that agencies include 10 specific elements in their implementation plans, such as: identification of the agency PMIO, identification of major acquisition portfolios, and strategies and actions for enhancing training and improving recruitment and retention of program and project managers. These plans were due to OMB by November 30, 2018. We reviewed PMIAA draft implementation plans for 22 of the 24 CFO Act agencies and determined the extent to which agencies included the required elements in their plans. In its PMPC meeting in April 2019, OMB reported that a majority of agencies only partially included OMB requirements in their draft implementation plans. OMB told us they have not directed agencies to address missing requirements nor have they required agencies to finalize their draft implementation plans. They told us that they view the implementation plans as an opportunity for each agency to engage with OMB and discuss how they will implement PMIAA. OMB staff told us that their view is that if implementation plans provide value to agencies, they may stay in draft form and do not need to be final. Overall, draft implementation plans for these agencies provided some but not all information required to fully meet the directives from OMB. Our analysis of the plans shows that on average, agencies fully met six out of 10 requirements for their implementation plans. For example, almost all agencies met the requirements for identifying the PMIO (21 out of 22). However, 11 out of 22 agencies did not provide complete information on major acquisition portfolios. Table 4 shows how agencies\u2019 implementation plans varied in meeting the requirements. Seven of 24 agencies reported in our questionnaire that they were creating either task forces or new or restructured offices to direct PMIAA implementation within their agencies. For example, DOE reported establishing a new office to support its PMIO. The Department of the Treasury and NASA reported creating an intra-agency cross-functional core team to discuss and design PMIAA implementation strategies. OPM reported establishing an enterprise program management office to drive the standardization of program and project management processes internally. Agencies selected PMIOs in existing leadership positions to leverage resources and agency processes to implement PMIAA. All agency PMIOs reported having additional leadership responsibilities beyond their PMIO roles. OMB documentation and information gathered from CFO Act agencies shows: every PMIO has at least one additional CXO role within its agency; thirty-eight percent of PMIOs have an additional performance management role; eight of 24 PMIOs have an additional budgetary role; and four of the 24 PMIOs have an explicit additional program or acquisition role. In the past, we have met with senior management officials from OMB and applicable agencies to discuss where additional management attention could be beneficial to addressing high-risk areas identified on our High- Risk List. We also reported that these trilateral meetings, which began in 2007 and pre-dated PMIAA\u2019s 2016 enactment, have continued across administrations and have been critical for progress that has been made in addressing high-risk areas. According to PMIAA, OMB\u2019s Deputy Director of Management is to conduct annual portfolio reviews of the most at-risk agency programs, as designated by our High-Risk List. OMB officials view the trilateral meetings as their method for holding the portfolio review meetings for high-risk areas as required under PMIAA. Our High-Risk List is comprised of programs as well as functions and operations. Consequently, in our assessment of OMB\u2019s implementation of PMIAA, we consider programs, functions, and operations on our High-Risk List as relevant for OMB\u2019s portfolio review of areas on our High-Risk List. OMB used three strategies intended to meet PMIAA\u2019s high-risk requirements. OMB (1) expanded its strategic reviews in 2018 to include a review of some high-risk areas, (2) continued to use the long-standing trilateral meetings to review high-risk areas with agency leaders and with us, and (3) held ad hoc meetings with agencies outside of the strategic review and trilateral meetings. In preparation for the 2018 strategic reviews, OMB issued Memorandum M-18-15 directing agencies to provide several items in advance of their strategic review meetings with OMB. Requested items included updates from agencies on areas identified on our High-Risk List in which agencies disagreed with our recommendations or faced implementation barriers preventing progress. These materials were to be discussed during strategic review meetings. Thirteen CFO Act agencies reported submitting high-risk updates to OMB prior to these meetings, and eight agencies reported discussing their high-risk areas with OMB during the meetings. OMB guidance from June 2019, communicated in OMB\u2019s Circular No. A- 11, did not include the statement from Memorandum M-18-15 that high- risk areas would be discussed during strategic review meetings. OMB staff felt that a broader approach could yield better results for addressing high-risk areas. Guidance in Circular No. A-11 maintained that agencies should submit updates about high-risk programs to OMB for the Deputy Director\u2019s high-risk portfolio review, but it did not specify what should comprise agency updates about high-risk programs. Also, OMB staff told us that they requested that agencies provide topics for discussion at strategic review meetings, and that agencies could provide agenda items related to our High-Risk List. OMB staff said they addressed only a few of the high-risk issues during strategic reviews, both during the review process and the strategic review meetings. Discussions about high-risk issues during strategic review meetings generally focused on government-wide high-risk areas, if relevant, such as \u201cEnsuring the Cybersecurity of the Nation\u201d and \u201cImproving the Management of Information Technology (IT) Acquisitions and Operations.\u201d However, OMB and agencies also discussed high-risk areas in instances when agencies provided strategic review meeting agenda topics related to our High-Risk List. For example, Treasury staff told us they spoke with OMB this year about high-risk areas as part of the strategic review process. Treasury is directly responsible for the Enforcement of Tax Laws high-risk area and shares responsibility with other agencies for other high-risk areas, such as the government-wide areas on cybersecurity and strategic human capital. OMB has held a limited number of trilateral meetings with agencies and us about high-risk areas as part of the high-risk portfolio reviews. Between March 2018 and October 2019, OMB addressed the following five high-risk areas in trilateral meetings with applicable agencies and us: 2020 Decennial Census, Managing Federal Real Property, Government-wide Personnel Security Clearance Process, Ensuring the Cybersecurity of the Nation, and NASA Acquisition Management. OMB has not held meetings to address the remaining 30 high-risk areas on our High-Risk List. OMB staff told us they plan to hold additional meetings in the next year but that they are unlikely to be able to schedule all remaining meetings within our 2-year cycle for updating the High-Risk List. OMB staff said that it is sometimes challenging to coordinate and convene trilateral meetings given the high-ranking officials who must attend and finding available times across schedules. OMB also told us that they plan to meet with agencies for all high-risk areas eventually, but that they prioritize meetings aligned with our priority areas and the President\u2019s Management Agenda. We evaluate progress made on high-risk areas every 2 years to determine if new areas should be added to our High-Risk List and if areas on the list should be removed due to progress to address the risks. Top leadership commitment is one of the five criteria we use to assess whether progress is being made to address and ultimately remove areas from our high-risk list. As we have reported in our March 2019 High-Risk Series report, leadership commitment is the critical element for initiating and sustaining progress, and leaders provide needed support and accountability for managing risks. Leadership commitment is vital if agencies are to adequately address high-risk areas, and trilateral meetings have been critical in focusing leadership attention in the past. Because OMB officials have met on only five of 35 high-risk areas, it remains to be seen if they will meet on all high-risk areas in the future. Convening the trilateral meetings on all high-risk areas in the 2-year reporting cycle, would better position OMB to enhance the leadership commitment needed to make greater progress on the remaining high-risk areas. Staff from OMB said that they sometimes have briefings related to agencies\u2019 high-risk areas separate from the annual strategic review meetings and high-risk trilateral meetings. These meetings happen on an ad hoc basis and are typically initiated by agency officials. Officials from some of our selected agencies corroborated that the discussion at the strategic review meetings and trilateral meetings is not the full extent of OMB\u2019s interaction with agencies about high-risk areas throughout the year. For example, VA officials said that high-risk areas are frequently agenda items in meetings with OMB. NASA officials said they spoke with OMB about NASA\u2019s high-risk areas after submitting material as part of the strategic review process. The PMPC, chaired by the Deputy Director for Management of OMB, did not address our High-Risk List during its three meetings nor did it make recommendations to OMB about addressing high-risk areas, as required. The PMPC meetings have lasted 60 to 90 minutes each and the High-Risk List has not appeared as an item on any of the PMPC meeting agendas. OMB staff said PMPC meetings at this point in PMIAA implementation primarily act as forums in which agencies can share program management practices. Rather than focusing meeting time on high-risk areas, OMB staff asserted that the best use of the PMPC is primarily as a forum for agencies to share program and project management best practices. Consequently, the PMPC has not satisfied all PMPC requirements as delineated in PMIAA, including for high-risk areas to be addressed. OMB created a dashboard to identify measures of cost, schedule, and performance that agencies should use to track their selected non-IT major acquisition programs for the first PMIAA program portfolio review. OMB partnered with the General Services Administration to complete a prototype of a dashboard to show cost, schedule, and performance data from each program or project within a portfolio of programs. The dashboard also provides a short description of each program or project and its strategic alignment to the agency\u2019s relevant strategic goal. Staff from OMB\u2019s Office of Federal Procurement Policy said the dashboard could provide them with some visibility and improved transparency for major acquisitions programs. According to the PMIAA strategic plan, the dashboard would display the agency portfolio and summarize performance for each item in the portfolio, similar to the portfolio reviews of IT programs required by the Federal Information Technology Acquisition Reform Act. Initially, according to OMB, it plans to request summary information for each portfolio, and restrict the dashboard to authorized government employees. Moving forward, OMB staff said that as the portfolio management process matures, a portion of the dashboard may be available to the public, similar to the IT dashboard. OMB staff told us they are in conversation with agencies about how to overcome difficulties in collecting data for the dashboard. According to OMB, the results from the pilot portfolio review showed that agencies experienced challenges with collecting high-quality data. OMB staff said there will likely be more metrics for large construction projects because management practices for them are more mature than for other types of programs, such as services. OMB is working with agencies to see how they can retrieve cost, schedule, and performance data that could provide early warning indicators of potential problems with programs. Agencies reported in our questionnaire they are considering various ways to measure implementation of PMIAA. A little more than half of agencies responding to our PMIAA questionnaire provided ideas on how to measure implementation of PMIAA, such as tracking completion of their identified PMIAA milestones, developing their own survey as a baseline measure, or using their agency implementation plan outcomes to measure results. Six agencies\u2019 questionnaire responses noted that they are planning to use existing metrics to assess program performance, either through internal processes or their annual strategic review process. For example, Treasury plans to focus in the near term on tracking completion of milestones of PMIAA implementation, such as major program and project alignment to department strategic objectives, development of an information-sharing site for program and project management resources, and workforce capabilities, among other things. VA anticipates developing outcome measures associated with successful program execution and is leveraging measures from existing plans, such as their Acquisition Human Capital Plan. OMB staff told us that they have no plans to identify measures to assess outcomes of PMIAA because it is too early and agencies are in the early stages of implementation. Rather than tracking anything specific, they told us that OMB looks at whether agencies\u2019 PMIOs are engaged, if agencies are using training material and mentorship programs, the involvement of chief senior level officers, and if there is funding in the budget for program management certificate programs. However, OMB has not identified specific measures to track any of these areas. In collaboration with OMB, VA developed a program management maturity model survey identify capability gaps, obtain insights, and enable benchmarking of program management capabilities. It surveyed agencies\u2019 level of maturity on a range of program management capabilities, such as talent management, governance, and portfolio management. Maturity assessment surveys can be useful tools for measuring progress to develop capacity in areas such as program management, according to subject matter specialists. Periodically measuring maturity can help agencies institutionalize continuous assessment and improvement. PMI also supports using such tools to identify trends that can help pinpoint actions needed and opportunities to learn from more mature organizations. We have found that ongoing performance measurement can serve as an early warning system to management and as a vehicle for improving accountability to the public. We have previously reported that providing baseline and trend data can help to assess an agency\u2019s performance more fully because the data show progress over time and decision makers can use historical data to assess performance. As OMB and agencies move forward with PMIAA implementation, it will be critical to measure how agencies are maturing or building their capacity in the areas of program and project management. Such measures could include showing how OMB\u2019s program management standards and principles are integrated into agencies\u2019 programs and policies, the improvement of data quality used to track agency program outcomes in the program portfolio reviews, and improvement in program manager skills. Although not required by PMIAA, it is a good practice for OMB and agencies to consider ways to measure the effects of the act. Without establishing such measures to assess PMIAA outcomes, it will be challenging to gauge how agencies are making progress to identify trends, or to help agencies improve data quality. The program and project management standards OMB developed are less detailed than accepted standards and are missing several elements that would have made them more useful. For example, the OMB standards do not provide a minimum threshold against which agencies can gauge to what extent they have met each standard. Further, OMB\u2019s current governance structure is insufficient for further developing and maintaining program management standards. Although OMB received input from stakeholders to develop the standards and plans to update them in partnership with the PMPC in 2020, OMB does not have a governance structure that assigns roles and responsibilities to further develop, approve, maintain, or monitor standards. Having such a governance structure for managing efforts going forward could help sustain the program standards as they change over time. OMB did not follow most leading practices for designing pilots and may have missed opportunities to make improvements for fiscal year 2019 portfolio reviews. OMB has not determined if it plans to conduct additional pilot efforts. Going forward, as OMB expands the portfolio reviews to other types of program areas beyond non-IT major acquisitions, it has the opportunity to develop and learn from additional pilots. Although OMB staff have not yet determined if they will do additional pilots for program management in the future, they could decide to pilot the portfolio reviews of grants that they plan to initiate in fiscal year 2020. OMB has not identified other program areas beyond non-IT major acquisitions and grants to be included in future portfolio reviews. Communicating to agencies about specific program areas, portfolio review procedures, time frames, and expectations beyond 2020 could help agencies better direct their efforts to improve the portfolio review processes and help ensure continued progress to implement PMIAA more broadly. As of October 2019, OMB had not taken any actions in response to the recommendations in our September 2017 report and has not yet fully established an inventory of federal programs. Such an inventory of programs could be a critical tool to help agency officials identify and manage programs across the federal government. Furthermore, if OMB were to fully implement our recommendations and complete the required inventory of federal programs, it would assist agencies to match resources to agencies\u2019 program management needs and assist agencies in preparing for future PMIAA portfolio reviews. Furthermore, OMB provides three different definitions for a \u201cprogram\u201d in its guidance for PMIAA, GPRAMA, and the DATA Act. Having different definitions of what constitutes a program could lead to confusion among agencies. It could also cause increased burden on agencies as they work to identify, maintain, and report on three sets of differently defined programs. Meetings between OMB, relevant agencies, and us have been critical for past progress on high-risk areas. However, OMB has held these trilateral meetings to address only five of 35 high-risk areas since it began implementing PMIAA. These meetings could both demonstrate and improve the commitment of agency leadership to high-risk areas across the federal government. As we have reported, leadership commitment is a key tenet in agencies\u2019 ability to address high-risk areas. Without convening trilateral meetings on each high-risk area, OMB might miss opportunities to make progress toward addressing high-risk areas by improving leadership commitment to addressing them. The PMPC did not address our High-Risk List during its meetings nor has it made recommendations to OMB about high-risk areas. The High-Risk List has not appeared as an item on any of the PMPC meeting agendas. OMB staff asserted that the best use of the PMPC\u2019s limited meeting time is as a forum for agencies to share program management best practices. In choosing to focus on program management practices rather than high- risk areas, the PMPC has not satisfied all PMPC requirements as delineated in PMIAA. Having measures to assess outcomes of PMIAA, such as establishing a baseline of information on programs or collecting trend data, can help OMB ensure that it has established a framework to effectively guide and assess PMIAA\u2019s implementation. Assessment measures would also allow OMB to better target efforts to improve project management and the capabilities of managers. We are making a total of eight recommendations to OMB. Specifically: The Deputy Director for Management of OMB, in conjunction with the PMPC, should develop program and project management standards to include (1) a minimum threshold for determining the extent to which agencies have met the standards, (2) how standards apply differently at the program and project levels, (3) how standards are interrelated to work in a synchronized way, and (4) how standards should be applied across the life cycle of a program or project. (Recommendation 1) The Deputy Director for Management of OMB, in conjunction with the PMPC, should create a governance structure to further develop and maintain program and project management standards that fully aligns with key practices for governance structures. (Recommendation 2) The Deputy Director for Management of OMB should, when expanding PMIAA to additional program types, design pilot efforts to follow leading practices so that OMB can optimize its efforts to improve and broaden portfolio reviews across a full range of program types. (Recommendation 3) The Deputy Director for Management of OMB should communicate program areas and timeframes, and expectations pertinent to annual program portfolio reviews, to be reviewed in future program portfolio reviews. (Recommendation 4) The Deputy Director for Management of OMB should clarify for agencies how the different definitions of a \u201cprogram\u201d relate to each other in OMB guidance. (Recommendation 5) The Deputy Director for Management of OMB should convene trilateral meetings between OMB, relevant agencies, and us for addressing all high-risk areas during each two-year high-risk cycle (Recommendation 6). The Deputy Director for Management of OMB, in conjunction with PMPC, should ensure PMPC meeting agendas include time for discussing high- risk areas during meetings and provide time for the PMPC to make recommendations to OMB about addressing high-risk areas. (Recommendation 7) The Deputy Director for Management of OMB, in conjunction with PMPC, should establish measures to assess outcomes of PMIAA, such as establishing a baseline of information on programs or collecting trend data. (Recommendation 8) We provided a draft of this product for comment to OMB, OPM, and the five selected agencies. OMB neither agreed nor disagreed with the recommendations and stated that it would take them into consideration when making future updates to its policies and guidance for agencies for improving program and service delivery. In addition, OMB, OPM, Commerce, NASA, Treasury, and Veterans Affairs provided technical comments which we incorporated as appropriate. Energy responded that it had no comments. We are sending copies of this report to congressional committees, the Acting Director of OMB and Director of OPM, The Secretaries of the Departments of Commerce, Energy, Treasury, and Veterans Affairs, the Administrator of NASA, and other interested parties. In addition, the report is available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact me at (202) 512-6806 or Jonesy@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix II. This report examines: (1) the steps taken by the Office of Management and Budget (OMB), the Office of Personnel Management (OPM), and the Chief Financial Officer Act of 1990 (CFO Act) agencies to implement the Program Management Improvement Accountability Act (PMIAA); (2) the extent to which OMB is using or planning to use portfolio reviews required in PMIAA to address issues on our High-Risk List; and (3) the extent to which OMB provided methods for agencies to assess the results of PMIAA. To examine the steps taken by OMB, OPM, and CFO Act agencies to implement PMIAA, we reviewed agency documents, designed and disseminated a questionnaire to the 24 CFO Act agencies, and analyzed their responses. We also selected five PMIAA CFO Act agencies as case studies. We reviewed documentation from OMB, including the OMB PMIAA strategic plan and actions taken, as well as Cross Agency Priority goal 11 quarterly reports, and screen shots of PMIAA documents on OMB Max portal. We interviewed OMB staff to gain insight into their approach to implementing PMIAA. To examine the OMB standards for program and project management, we used criteria from the Project Management Institute (PMI) for Standard for Program Management and the Project Management Body of Knowledge. In addition, we reviewed documentation from OPM regarding their PMIAA plans and documents for the update of the 0340 job series. We further analyzed Enterprise Human Resources Integration (EHRI) data from fiscal year 2018 from OPM to identify employees in current program management 0340 occupational series. We also interviewed OPM officials regarding their role in implementing PMIAA. We interviewed outside subject matter specialists to provide their views on federal program and project management. Specifically, we met with staff from PMI and Professor Janet Weiss from the University of Michigan\u2014who had conducted a study on how to improve federal program management\u2014as she had been recommended by the Congressional Research Service, OMB, and the IBM Center for the Business of Government. To examine the steps agencies had taken, we requested PMIAA implementation plans from all 24 CFO Act agencies. CFO Act agencies were to submit PMIAA implementation plans to OMB by November 30, 2018. We collected implementation plans between November 29, 2018, and April 16, 2019. We received 22 out of 24 implementation plans. We did not review plans from the Department of Health and Human Services or the Environmental Protection Agency because they had not completed their plans at the time of our review. Two analysts independently reviewed separate implementation plans. These reviews were then verified by another analyst. Implementation plans were evaluated on whether they fully met, partially met, or did not meet the 10 requirements provided in the OMB implementation guidance, such as how the major acquisition portfolios aligned to relevant strategic objectives, or whether the agency had existing training for program and project managers. We also disseminated a questionnaire to all CFO Act agencies to collect information on PMIAA implementation. This questionnaire was pre-tested by two CFO Act agencies and two members of the Federal Program and Project Management Community of Practice and revised for clarity. The questionnaire was sent to all 24 CFO Act agencies on February 4, 2019, and responses collected between February 11 and April 22, 2019. All 24 agencies responded to the questionnaire. Agency officials were asked questions on: 1. the steps their agency has taken to implement PMIAA, 2. the challenges their agency faces in implementing PMIAA, 3. efforts to address high-risk issues, and 4. plans to measure PMIAA outcomes, if any. We selected five agencies for case studies and analyzed further documentation and interviewed agency officials to provide illustrative examples of PMIAA implementation at the agency level. We assessed whether: agencies had responsibility for a program, function, or operation on our 2019 High-Risk List; OMB considered them further along in PMIAA implementation compared to other agencies; the agency reported it was selected for the OMB pilot of noninformation technology acquisition program portfolio reviews; agency officials reported actions taken to direct internal program management training or workforce development in their questionnaire responses or OMB required implementation plans; and agency officials reported any actions to implement PMIAA beyond the requirements listed in the OMB PMIAA strategic plan. To achieve of a range of PMIAA experiences, we selected five agencies that met varying numbers of the criteria. The Department of Commerce was chosen because all four selection criteria were met, the Department of Energy met three, the Department of Veterans Affairs met two, and the Department of the Treasury and the National Aeronautics and Space Administration each met one. We interviewed and reviewed documents from each of the agencies. We asked questions about steps agencies were taking and their interactions with OMB and OPM to help them implement PMIAA. We also asked these agencies to suggest any ways in which OMB and OPM could improve implementation. To assess the OMB PMIAA strategic plan, we reviewed leading practices on strategic planning from our body of work. We also considered testimonial evidence from OMB staff. Specifically, we reviewed prior reports on leading strategic planning practices and requirements for agencies to use in strategic planning. We selected relevant criteria from the Government Performance and Results Act of 1993 (GPRA) and the GPRA Modernization Act, that not only pertained to agency strategic plans, but also were relevant as for strategic planning principles. Specifically, we selected criteria from the following categories: (1) mission statement; (2) general goals and objectives; (3) strategies for accomplishing goals and objectives; (4) input from stakeholders; (5) interagency collaboration; 6) milestones and metrics to gauge progress. To determine the extent to which the leading practice was included in the strategic plan, we assessed documentary evidence from the PMIAA strategic plan and testimonial evidence from OMB staff as defined below: A practice was categorized as fully met if the evidence fulfilled all aspects of the definition. A practice was categorized as partially met if the evidence fulfilled some, but not all, aspects of the definition, or if the evidence was judged to fulfill the general meaning of the definition, while not technically meeting it fully. A practice was categorized as not met if no evidence was found relevant to the criterion, or if evidence did not fulfill any aspects of the definition. In addition, we reviewed documents from and interviewed selected agencies on what measures OMB was developing for evaluating PMIAA implementation. We also asked these agency officials what kinds of evaluative measures would be useful to monitor the successful implementation of PMIAA from their perspective. In addition, we assessed the pilot of the required PMIAA program portfolio reviews against the five leading practices we identified from our work on designing pilots. We determined that the design fully met the criteria when we saw evidence that all aspects of a leading practice were met. When we were unable to assess whether all aspects of a leading practice were met without additional information, we determined that the design partially met the criteria. Finally, when we saw no evidence of a leading practice, we determined that the criteria were not met. To examine OMB\u2019s standards for program and project management, we selected two sets of criteria for program and project management criteria from PMI. PMI standards are generally recognized as leading practices for program and project management. To select program management standards, we identified 10 PMI program management activities. To select project management standards, we identified 10 project management knowledge areas. Further, PMI\u2019s leading practices were selected to explain how program and project management standards apply differently, and how both set of standards relate to the lifecycle of a program or project. We then compared the definition of these 10 PMI program and 10 PMI project management standards to the definition of OMB\u2019s initial 15 program and project standards released for PMIAA implementation. In addition, OMB\u2019s initial standards were compared to PMI leading practices that distinguish the relationship between programs and projects and leading practices on applying standards across the life cycle of a program or project. We also applied leading practices we identified from our previous work on data governance standards to assess the governance process OMB used to develop, maintain, and monitor program management standards. Our past work identified common key practices for establishing effective data governance structures. This work selected a range of organizations, including domestic and international standards-setting organizations, industry groups or associations, and federal agencies, to ensure we had comprehensive perspectives of data governance key practices across several domains. Two analysts compared the five key practices on the data governance structures to OMB plans and documented practices. We assessed the reliability of OPM\u2019s EHRI data through electronic testing to identify missing data, out of range values, and logical inconsistencies for employees classified as 0340s. We believe the EHRI data we used are sufficiently reliable for the purpose of this report. To examine the extent to which OMB is using or planning to use portfolio reviews to address our High-Risk-List, we reviewed documentation from OMB and 24 CFO Act Agencies. As part of our questionnaire, we asked 24 CFO Act agencies to provide any of our High-Risk List summary and detailed analyses that the agencies were required to submit to OMB as part of the 2018 strategic review process. We analyzed this information to determine the extent to which agencies provided information to OMB during their 2018 strategic review process. We also selected criteria from the Standards for Internal Control in the Federal Government on maintaining documentation of the internal control system to assess steps that OMB had taken related to its responsibilities for conducting high-risk portfolio reviews and the management of the Program Management Policy Council. Specifically, we selected information and communication which states that management should externally communicate the necessary quality information that an entity needs to achieve its objectives. We conducted this performance audit from June 2018 to December 2019 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. Yvonne D. Jones, (202) 512-6806, or jonesy@gao.gov. In addition to the contact named above, William Reinsberg (Assistant Director), Carole J. Cimitile (Analyst in Charge), Jacqueline Chapin, Martin J. De Alteriis, Emily Gamelin, Jaeyung Kim, Matthew L. McKnight, Robert Robinson, Dylan Stagner, Andrew J. Stephens, and John Villecco made key contributions to this report.", "summary": "PMIAA requires OMB to adopt program management standards and guidelines government-wide; OPM is to establish new\u2014or revise existing\u2014occupational standards for program and project management. PMIAA includes a provision for GAO, no later than 3 years after the enactment of the act, to issue a report examining the implementation and effectiveness of certain provisions of the act on federal program and project management. This report (1) describes steps taken by OMB, OPM, and agencies to implement PMIAA; (2) assesses OMB's efforts to address issues on GAO's High-Risk List using PMIAA; and (3) examines the extent to which OMB provided methods for agencies to measure and assess the results of PMIAA. GAO reviewed documents from and conducted interviews with OMB and OPM. GAO surveyed all 24 CFO Act agencies, and selected five agencies to illustrate implementation efforts. GAO also interviewed subject matter specialists from academia and the private sector regarding their views on how program and project management practices applied to PMIAA. The Office of Management and Budget (OMB) has begun to implement all requirements of the Program Management Improvement Accountabilitiy Act of 2016 (PMIAA), but further efforts are needed to fully implement the law. OMB released its 5-year strategic plan for PMIAA and developed program management standards. However, the standards are not detailed compared with accepted program and project management standards, and OMB's governance structure is insufficient for developing and maintaining these standards over time. In 2019, OMB conducted ten reviews of agency program portfolios\u2014organized groupings of programs whose coordination in implementation enables agencies to achieve their objectives. Each review addressed one or two portfolios per agency. Further, OMB's required portfolio reviews of high-risk areas were limited to only five out of 35 areas on GAO's High-Risk List. OMB could establish measures to track agencies' progress. Although not required by PMIAA, this is a good practice for demonstrating improvement. As required by PMIAA, the Office of Personnel Management (OPM) developed competencies for program and project managers and updated the program management job series. Further, OPM is developing a career path for program and project managers by the end of 2019. OPM also plans to create a unique job identifier code in 2020 so that agencies can more completely identify their program management workforce. The Program Management Policy Council (PMPC), established by PMIAA and chaired by OMB's Deputy Director for Management, met for the first time in September 2018 and met twice in 2019 to discuss PMIAA implementation with Chief Financial Officers (CFO) Act agencies. All CFO Act agencies designated a Program Management Improvement Officer to participate in the PMPC. However, the PMPC has neither addressed GAO high-risk areas nor advised OMB on how to address high-risk areas, as required by the PMIAA. GAO is making eight recommendations that OMB further develop the standards to include more detail, create a governance structure for program management standards, hold meetings on all High-Risk List areas, and establish measures to track agencies' progress in program management. OMB neither agreed nor disagreed with the recommendations and stated that it would consider them when making future updates to its program management policies and guidance."}
